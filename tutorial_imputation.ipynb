{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62252164",
   "metadata": {},
   "source": [
    "#### Imports and Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163946ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "\n",
    "# Custom project modules\n",
    "# Ensure your current directory or PYTHONPATH includes the 'src' folder\n",
    "from src.data import GenotypeEncoder, ImputationDataset\n",
    "from src.model import EvoFill\n",
    "from src.tensor2vcf import make_imputed_vcfgz_from_prob\n",
    "\n",
    "print(f\"Using Device: {'cuda' if torch.cuda.is_available() else 'cpu'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71167001",
   "metadata": {},
   "source": [
    "#### Path Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ea983a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define Workspace\n",
    "WORK_DIR = Path(\"<path/to/output_directory>\")\n",
    "MASK_DIR = Path(\"<path/to/data/masked_vcf>\")\n",
    "\n",
    "# 2. Define Model and Metadata Files\n",
    "MODEL_BIN = Path(\"<path/to/models/hg38_chr22_v1.0.bin>\")\n",
    "MODEL_META = Path(\"<path/to/models/model_meta.json>\")\n",
    "TRAIN_META = Path(\"<path/to/train/gt_enc_meta.json>\")\n",
    "\n",
    "# Initialize Directories\n",
    "WORK_DIR.mkdir(parents=True, exist_ok=True)\n",
    "(WORK_DIR / \"impute_out\").mkdir(exist_ok=True)\n",
    "\n",
    "# Set working directory for the session\n",
    "os.chdir(WORK_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658dd634",
   "metadata": {},
   "source": [
    "#### Load Pre-trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068865e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(meta_path, bin_path, device):\n",
    "    \"\"\"Initializes EvoFill and loads weights.\"\"\"\n",
    "    print(f\"[INIT] Loading metadata: {meta_path.name}\")\n",
    "    with open(meta_path, 'r') as f:\n",
    "        meta = json.load(f)\n",
    "    \n",
    "    model = EvoFill(\n",
    "        n_alleles=int(meta[\"alleles\"]),\n",
    "        total_sites=int(meta[\"total_sites\"]),\n",
    "        chunk_size=int(meta[\"chunk_size\"]),\n",
    "        chunk_overlap=int(meta[\"overlap\"]),\n",
    "        d_model=int(meta[\"d_model\"]),\n",
    "        d_state=int(meta[\"d_state\"]),\n",
    "        headdim=int(meta[\"headdim\"]),\n",
    "        bimamba_layers=int(meta[\"bimamba_layers\"]),\n",
    "        stack_mamba_layers=int(meta[\"stack_mamba_layers\"]),\n",
    "    ).to(device)\n",
    "\n",
    "    print(f\"[INIT] Loading weights: {bin_path.name}\")\n",
    "    state_dict = torch.load(bin_path, map_location=\"cpu\")\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.eval()\n",
    "    \n",
    "    return model, meta\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, model_meta = load_model(MODEL_META, MODEL_BIN, device)\n",
    "print(f\"\\n[OK] Model '{model_meta.get('model_name')}' is ready for inference.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd932ac",
   "metadata": {},
   "source": [
    "#### Define Inference Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64f49ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_mask_vcf(model, mask_vcf_path, out_dir, train_meta_path, device, digits=4):\n",
    "    mask_vcf_path = Path(mask_vcf_path)\n",
    "    \n",
    "    # --- Step 1: Encoding --- \n",
    "    # The impute_in folders will be generated under the WORK_DIR.\n",
    "    gt_enc = GenotypeEncoder(\n",
    "        phased=False, gts012=False, save2disk=True,\n",
    "        save_dir=out_dir / \"impute_in\"\n",
    "    )\n",
    "    gt_enc = gt_enc.encode_ref(\n",
    "        ref_meta_json=str(train_meta_path),\n",
    "        vcf_path=str(mask_vcf_path)\n",
    "    )\n",
    "\n",
    "    # --- Step 2: Dataset Loading ---\n",
    "    dataset = ImputationDataset(x_gts_sparse=gt_enc.X_gt, seq_depth=gt_enc.seq_depth)\n",
    "    \n",
    "    def collate_fn(batch):\n",
    "        return torch.stack([b[0] for b in batch]), [b[1] for b in batch]\n",
    "\n",
    "    loader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=1, shuffle=False, num_workers=4,\n",
    "        pin_memory=True, collate_fn=collate_fn\n",
    "    )\n",
    "\n",
    "    # --- Step 3: Inference ---\n",
    "    y_prob, y_mask = [], []\n",
    "    with torch.no_grad():\n",
    "        for x_onehot, _ in tqdm(loader, desc=f\"Imputing {mask_vcf_path.name}\", leave=False):\n",
    "            x_onehot = x_onehot.to(device)\n",
    "            _, prob, _ = model(x_onehot)\n",
    "            miss_mask = x_onehot[..., -1].bool()\n",
    "            y_prob.append(prob.cpu())\n",
    "            y_mask.append(miss_mask.cpu())\n",
    "\n",
    "    y_prob = torch.cat(y_prob).numpy()\n",
    "    y_mask = torch.cat(y_mask).numpy()\n",
    "\n",
    "    # Save intermediate results \n",
    "    # The impute_out folders will be generated under the WORK_DIR.\n",
    "\n",
    "    prob_path = out_dir / \"impute_out\" / f\"{mask_vcf_path.stem}_prob.npy\"\n",
    "    mask_path = out_dir / \"impute_out\" / f\"{mask_vcf_path.stem}_mask.npy\"\n",
    "    np.save(prob_path, y_prob)\n",
    "    np.save(mask_path, y_mask)\n",
    "\n",
    "    # --- Step 4: VCF Reconstruction ---\n",
    "    out_vcfgz = out_dir / f\"{mask_vcf_path.stem}_imputed_Evofill.vcf.gz\"\n",
    "    make_imputed_vcfgz_from_prob(\n",
    "        prob_npy=str(prob_path),\n",
    "        mask_vcf_gz=str(mask_vcf_path),\n",
    "        out_vcfgz=str(out_vcfgz),\n",
    "        digits=digits\n",
    "    )\n",
    "    return out_vcfgz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef22edd",
   "metadata": {},
   "source": [
    "#### Run Batch Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b03891b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scan for all VCF files in the target directory\n",
    "mask_files = sorted(MASK_DIR.glob(\"*.vcf.gz\"))\n",
    "print(f\"[INFO] Found {len(mask_files)} files to process.\\n\")\n",
    "\n",
    "results = []\n",
    "for f in mask_files:\n",
    "    print(f\"--- Processing: {f.name} ---\")\n",
    "    try:\n",
    "        final_vcf = process_mask_vcf(model, f, WORK_DIR, TRAIN_META, device)\n",
    "        results.append(final_vcf)\n",
    "        print(f\"[SUCCESS] Saved to: {final_vcf.name}\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Failed to process {f.name}: {e}\\n\")\n",
    "\n",
    "\n",
    "print(\"INFERENCE COMPLETE\")\n",
    "for r in results:\n",
    "    print(f\"- {r}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
