{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "928e399c",
   "metadata": {},
   "source": [
    "# EvoFill working demo\n",
    "\n",
    "ver 4.   new imputation loss with evo loss\n",
    "\n",
    "ver 4.1  long range modules integrated in stage1 training\n",
    "\n",
    "ver 4.2  stage 3 fine tuning with under-reprensted population samples.\n",
    "\n",
    "last update: 2025/11/13"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa78c2a2",
   "metadata": {},
   "source": [
    "## Content\n",
    "- [0. Dependency](#0.-Dependency)  \n",
    "- [1. Genotype(.vcf) encoding](#1.-Genotype(.vcf)-encoding)  \n",
    "- [2. Training a new model](#2.-Training-a-new-model)  \n",
    "  - [2.1 Dataloader](#2.1-Dataloader)  \n",
    "  - [2.2 Model initialization](#2.2-Model-initialization)  \n",
    "  - [2.3 stage 1: Chunk Module Training](#2.3-stage-1:-Chunk-Module-Training)  \n",
    "  - [2.4 stage 2: Ultra-Long-Range LD Module Training](#2.4-stage-2:-Ultra-Long-Range-LD-Module-Training)  \n",
    "  - [2.5 stage 3:](#2.5-)\n",
    "- [3. Imputation using trained model](#3.-Imputation-using-trained-model)  \n",
    "  - [3.1 Load the trained model](#3.1-Load-the-trained-model)  \n",
    "  - [3.2 Encode .vcf file need be impute](#3.2-Encode-.vcf-file-need-be-impute)  \n",
    "  - [3.3 Inferring](#3.3-Inferring)  \n",
    "  - [3.4 Evaluating the imputation results](#3.4-Evaluating-the-imputation-results)  \n",
    "  - [3.5 Saving to .vcf](#3.5-Saving-to-.vcf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f454114",
   "metadata": {},
   "source": [
    "In jupyter notebook, we use single GPU here for demo.\n",
    "\n",
    "For parallel GPU training, please use other framework with `./train.py`, like `torch run --nproc_per_node=8 train.py` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9efe343c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" \n",
    "os.chdir('/mnt/qmtang/EvoFill/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed77817",
   "metadata": {},
   "source": [
    "## 0. Dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23548ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python ver:   3.10.19 | packaged by conda-forge | (main, Oct 13 2025, 14:08:27) [GCC 14.3.0]\n",
      "Pytorch ver:  2.8.0+cu129\n",
      "Mamba ver:    2.2.5\n",
      "GPU in use:   NVIDIA H100 PCIe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import torch\n",
    "import mamba_ssm\n",
    "from tqdm import tqdm\n",
    "from itertools import combinations\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW, SparseAdam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print('Python ver:  ', sys.version)\n",
    "print('Pytorch ver: ', torch.__version__)\n",
    "print('Mamba ver:   ', mamba_ssm.__version__)\n",
    "print('GPU in use:  ', torch.cuda.get_device_name(torch.cuda.current_device()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca64e47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import GenotypeEncoder, GenomicDataset, GenomicDataset_Missing, ImputationDataset\n",
    "from src.model import EvoFill\n",
    "from src.loss import ImputationLoss, ImputationLoss_Missing\n",
    "from src.utils import create_directories, set_seed, precompute_maf, metrics_by_maf, print_maf_stat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c4b1516",
   "metadata": {},
   "outputs": [],
   "source": [
    "work_dir = Path('/mnt/qmtang/EvoFill_data/20251107_ver4')\n",
    "create_directories(work_dir)\n",
    "os.chdir(work_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7064af",
   "metadata": {},
   "source": [
    "## 1. Genotype(.vcf) encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33ef302",
   "metadata": {},
   "source": [
    "option 1. with extra evolutionary information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d332f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DATA] 总计 99,314 个位点  \n",
      "[DATA] EvoMat shape: (2236, 2236)\n",
      "[DATA] 结果已写入 /mnt/qmtang/EvoFill_data/20251107_ver4/pre_train\n",
      "[DATA] 位点矩阵 = (2236, 99314)，稀疏度 = 28.19%\n",
      "[DATA] 位点字典 = {'0|0': 0, '0|1': 1, '1|1': 2, '.|.': 3}，字典深度 = 4\n",
      "[DATA] 2,236 Samples\n",
      "[DATA] 99,314 Variants Sites\n",
      "[DATA] 4 seq_depth\n"
     ]
    }
   ],
   "source": [
    "gt_enc = GenotypeEncoder(phased = False, gts012 = False, \n",
    "                         save2disk = True, save_dir = Path(work_dir / \"pre_train\"))\n",
    "\n",
    "gt_enc = gt_enc.encode_new(vcf_path = Path(work_dir / \"pre_train\" / \"major_pops.vcf.gz\"),\n",
    "                           evo_mat = Path(work_dir / \"pre_train\" / \"evo_mat_major_pops.tsv\"))\n",
    "\n",
    "print(f\"[DATA] {gt_enc.n_samples:,} Samples\")\n",
    "print(f\"[DATA] {gt_enc.n_variants:,} Variants Sites\")\n",
    "print(f\"[DATA] {gt_enc.seq_depth} seq_depth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddf1311",
   "metadata": {},
   "source": [
    "option 2. no extra evolutionary information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5b160c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DATA] 总计 99,314 个位点  \n",
      "[DATA] 结果已写入 /mnt/qmtang/EvoFill_data/20251110_ver4/\n",
      "[DATA] 位点矩阵 = (2236, 99314)，稀疏度 = 28.19%\n",
      "[DATA] 位点字典 = {'0|0': 0, '0|1': 1, '1|1': 2, '.|.': 3}，字典深度 = 4\n",
      "[DATA] 2,236 Samples\n",
      "[DATA] 99,314 Variants Sites\n",
      "[DATA] 4 seq_depth\n"
     ]
    }
   ],
   "source": [
    "gt_enc = GenotypeEncoder(phased = False, gts012 = False, \n",
    "                         save2disk = True, save_dir = Path(work_dir / \"pre_train\"))\n",
    "\n",
    "gt_enc = gt_enc.encode_new(vcf_path = Path(work_dir / \"pre_train\" / \"major_pops.vcf.gz\"),\n",
    "                           evo_mat = None)\n",
    "\n",
    "print(f\"[DATA] {gt_enc.n_samples:,} Samples\")\n",
    "print(f\"[DATA] {gt_enc.n_variants:,} Variants Sites\")\n",
    "print(f\"[DATA] {gt_enc.seq_depth} seq_depth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6e5478",
   "metadata": {},
   "source": [
    "## 2. Training a new model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb250f1",
   "metadata": {},
   "source": [
    "Choose a path which including GenotypeEncoder processed files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebb7acb",
   "metadata": {},
   "source": [
    "### 2.1 Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4404ffa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2,236 samples, 99,314 variants, 4 seq-depth.\n",
      "2,108 samples in train\n",
      "128 samples in test\n"
     ]
    }
   ],
   "source": [
    "test_n_samples = 128\n",
    "batch_size    = 16\n",
    "max_mr        = 0.7\n",
    "min_mr        = 0.3\n",
    "\n",
    "gt_enc = GenotypeEncoder.loadfromdisk(Path(work_dir / \"pre_train\"))\n",
    "print(f'{gt_enc.n_samples:,} samples, {gt_enc.n_variants:,} variants, {gt_enc.seq_depth} seq-depth.')\n",
    "\n",
    "x_train_indices, x_test_indices = train_test_split(\n",
    "    range(gt_enc.n_samples),\n",
    "    test_size=test_n_samples,\n",
    "    random_state=3047,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "print(f\"{len(x_train_indices):,} samples in train\")\n",
    "print(f\"{len(x_test_indices):,} samples in test\")\n",
    "# print(f\"evo_mat: {gt_enc.evo_mat.shape}\")\n",
    "\n",
    "train_dataset = GenomicDataset(\n",
    "    gt_enc.X_gt,\n",
    "    evo_mat=gt_enc.evo_mat,\n",
    "    seq_depth=gt_enc.seq_depth,\n",
    "    mask=True,\n",
    "    masking_rates=(min_mr, max_mr),\n",
    "    indices=x_train_indices\n",
    ")\n",
    "\n",
    "test_dataset = GenomicDataset(\n",
    "    gt_enc.X_gt,\n",
    "    evo_mat=gt_enc.evo_mat,\n",
    "    seq_depth=gt_enc.seq_depth,\n",
    "    mask=True,\n",
    "    masking_rates=(min_mr, max_mr),\n",
    "    indices=x_test_indices\n",
    ")\n",
    "\n",
    "def collate_fn(batch):\n",
    "    x_onehot = torch.stack([item[0] for item in batch])\n",
    "    y_onehot = torch.stack([item[1] for item in batch])\n",
    "    real_idx_list = [item[2] for item in batch]\n",
    "\n",
    "    # 提取 evo_mat 子矩阵\n",
    "    if train_dataset.evo_mat is not None:\n",
    "        evo_mat_batch = train_dataset.evo_mat[np.ix_(real_idx_list, real_idx_list)]\n",
    "        evo_mat_batch = torch.FloatTensor(evo_mat_batch)\n",
    "    else:\n",
    "        evo_mat_batch = torch.empty(0)\n",
    "\n",
    "    return x_onehot, y_onehot, evo_mat_batch\n",
    "    \n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2c3f8a",
   "metadata": {},
   "source": [
    "### 2.2 Model initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fd90485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "model[hg19_chr22trim] would have 4 chunks.\n"
     ]
    }
   ],
   "source": [
    "model_name  = 'hg19_chr22trim'\n",
    "total_sites = gt_enc.n_variants\n",
    "alleles     = gt_enc.seq_depth\n",
    "chunk_size  = 32768\n",
    "overlap     = 1024\n",
    "d_model     = 64\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# Setup device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.empty_cache()\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = EvoFill(d_model, alleles, total_sites, chunk_size, overlap).to(device)\n",
    "print(f\"model[{model_name}] would have {model.n_chunks} chunks.\")\n",
    "\n",
    "criterion = ImputationLoss(use_r2=True, use_evo=True, r2_weight=1, evo_weight=4, evo_lambda=10)\n",
    "# criterion = ImputationLoss(use_r2=True, use_evo=False)\n",
    "\n",
    "meta = {\n",
    "    \"model_name\": model_name,\n",
    "    \"total_sites\": total_sites,\n",
    "    \"alleles\": alleles,\n",
    "    \"chunk_size\": chunk_size,\n",
    "    \"overlap\": overlap,\n",
    "    \"d_model\": d_model\n",
    "}\n",
    "save_path = os.path.join(Path(work_dir / \"models\"), \"model_meta.json\")\n",
    "with open(save_path, \"w\") as f:\n",
    "    json.dump(meta, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233acee1",
   "metadata": {},
   "source": [
    "### 2.3 stage 1: Chunk Module Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bba6dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 1/4, Epoch 1/100: 100%|██████████| 132/132 [01:44<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/4, Epoch 1/100, Total Loss, Train = 170168.9, Val = 91773.3, LR: 1.00e-03\n",
      "        Train, ce: 170168.9, r2: -8356.9, evo: 20506.9\n",
      "        Val  , ce: 91773.3, r2: -10818.7, evo: 19573.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 1/4, Epoch 2/100: 100%|██████████| 132/132 [01:09<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/4, Epoch 2/100, Total Loss, Train = 78159.1, Val = 66247.0, LR: 1.00e-03\n",
      "        Train, ce: 78159.1, r2: -11029.0, evo: 18623.2\n",
      "        Val  , ce: 66247.0, r2: -11783.8, evo: 15786.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 1/4, Epoch 3/100: 100%|██████████| 132/132 [01:10<00:00,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/4, Epoch 3/100, Total Loss, Train = 63727.7, Val = 62764.0, LR: 1.00e-03\n",
      "        Train, ce: 63727.7, r2: -11627.8, evo: 16587.0\n",
      "        Val  , ce: 62764.0, r2: -12092.8, evo: 14085.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 1/4, Epoch 4/100: 100%|██████████| 132/132 [01:11<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/4, Epoch 4/100, Total Loss, Train = 56631.2, Val = 53795.7, LR: 1.00e-03\n",
      "        Train, ce: 56631.2, r2: -11866.9, evo: 15397.9\n",
      "        Val  , ce: 53795.7, r2: -12344.6, evo: 13168.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 1/4, Epoch 5/100: 100%|██████████| 132/132 [01:09<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/4, Epoch 5/100, Total Loss, Train = 51525.9, Val = 50172.6, LR: 1.00e-03\n",
      "        Train, ce: 51525.9, r2: -12095.0, evo: 14443.2\n",
      "        Val  , ce: 50172.6, r2: -12584.9, evo: 14575.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 1/4, Epoch 6/100: 100%|██████████| 132/132 [01:10<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/4, Epoch 6/100, Total Loss, Train = 48550.5, Val = 47136.6, LR: 1.00e-03\n",
      "        Train, ce: 48550.5, r2: -12193.9, evo: 13843.2\n",
      "        Val  , ce: 47136.6, r2: -12581.9, evo: 13128.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 1/4, Epoch 7/100: 100%|██████████| 132/132 [01:10<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/4, Epoch 7/100, Total Loss, Train = 45062.8, Val = 49123.1, LR: 1.00e-03\n",
      "        Train, ce: 45062.8, r2: -12300.4, evo: 13201.4\n",
      "        Val  , ce: 49123.1, r2: -12708.4, evo: 11923.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 1/4, Epoch 8/100: 100%|██████████| 132/132 [01:10<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/4, Epoch 8/100, Total Loss, Train = 42822.0, Val = 40542.0, LR: 1.00e-03\n",
      "        Train, ce: 42822.0, r2: -12397.0, evo: 12717.6\n",
      "        Val  , ce: 40542.0, r2: -12862.7, evo: 12651.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 1/4, Epoch 9/100: 100%|██████████| 132/132 [01:10<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/4, Epoch 9/100, Total Loss, Train = 41126.7, Val = 39755.2, LR: 1.00e-03\n",
      "        Train, ce: 41126.7, r2: -12485.3, evo: 12407.4\n",
      "        Val  , ce: 39755.2, r2: -12860.7, evo: 11628.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 1/4, Epoch 10/100: 100%|██████████| 132/132 [01:11<00:00,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/4, Epoch 10/100, Total Loss, Train = 39622.1, Val = 41968.3, LR: 1.00e-03\n",
      "        Train, ce: 39622.1, r2: -12526.8, evo: 12106.9\n",
      "        Val  , ce: 41968.3, r2: -12951.7, evo: 11494.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 1/4, Epoch 11/100: 100%|██████████| 132/132 [01:10<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/4, Epoch 11/100, Total Loss, Train = 38179.9, Val = 37982.1, LR: 1.00e-03\n",
      "        Train, ce: 38179.9, r2: -12567.1, evo: 11796.1\n",
      "        Val  , ce: 37982.1, r2: -13016.1, evo: 10898.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 1/4, Epoch 12/100: 100%|██████████| 132/132 [01:10<00:00,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/4, Epoch 12/100, Total Loss, Train = 37036.7, Val = 33193.1, LR: 1.00e-03\n",
      "        Train, ce: 37036.7, r2: -12636.9, evo: 11556.7\n",
      "        Val  , ce: 33193.1, r2: -13104.0, evo: 10495.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 1/4, Epoch 13/100: 100%|██████████| 132/132 [01:10<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/4, Epoch 13/100, Total Loss, Train = 35963.6, Val = 36950.4, LR: 1.00e-03\n",
      "        Train, ce: 35963.6, r2: -12637.1, evo: 11323.3\n",
      "        Val  , ce: 36950.4, r2: -13084.7, evo: 11767.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 1/4, Epoch 14/100: 100%|██████████| 132/132 [01:10<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/4, Epoch 14/100, Total Loss, Train = 35045.5, Val = 33393.2, LR: 1.00e-03\n",
      "        Train, ce: 35045.5, r2: -12676.5, evo: 11147.6\n",
      "        Val  , ce: 33393.2, r2: -13115.4, evo: 10424.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 1/4, Epoch 15/100: 100%|██████████| 132/132 [01:10<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/4, Epoch 15/100, Total Loss, Train = 34044.2, Val = 34036.0, LR: 1.00e-03\n",
      "        Train, ce: 34044.2, r2: -12741.7, evo: 10916.0\n",
      "        Val  , ce: 34036.0, r2: -13061.5, evo: 11010.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 1/4, Epoch 16/100: 100%|██████████| 132/132 [01:09<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/4, Epoch 16/100, Total Loss, Train = 33233.6, Val = 31978.2, LR: 1.00e-03\n",
      "        Train, ce: 33233.6, r2: -12745.8, evo: 10748.4\n",
      "        Val  , ce: 31978.2, r2: -13217.2, evo: 11108.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 1/4, Epoch 17/100: 100%|██████████| 132/132 [01:10<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/4, Epoch 17/100, Total Loss, Train = 32216.4, Val = 33772.2, LR: 1.00e-03\n",
      "        Train, ce: 32216.4, r2: -12786.8, evo: 10523.2\n",
      "        Val  , ce: 33772.2, r2: -13136.1, evo: 9535.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 1/4, Epoch 18/100: 100%|██████████| 132/132 [01:09<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/4, Epoch 18/100, Total Loss, Train = 31794.8, Val = 31105.5, LR: 1.00e-03\n",
      "        Train, ce: 31794.8, r2: -12769.1, evo: 10430.8\n",
      "        Val  , ce: 31105.5, r2: -13235.9, evo: 10520.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 1/4, Epoch 19/100: 100%|██████████| 132/132 [01:10<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/4, Epoch 19/100, Total Loss, Train = 30945.1, Val = 30810.7, LR: 1.00e-03\n",
      "        Train, ce: 30945.1, r2: -12783.8, evo: 10253.0\n",
      "        Val  , ce: 30810.7, r2: -13183.4, evo: 10436.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 1/4, Epoch 20/100: 100%|██████████| 132/132 [01:10<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/4, Epoch 20/100, Total Loss, Train = 30227.3, Val = 27421.6, LR: 1.00e-03\n",
      "        Train, ce: 30227.3, r2: -12840.2, evo: 10098.0\n",
      "        Val  , ce: 27421.6, r2: -13258.8, evo: 8944.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 1/4, Epoch 21/100: 100%|██████████| 132/132 [01:11<00:00,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/4, Epoch 21/100, Total Loss, Train = 29891.5, Val = 28463.6, LR: 1.00e-03\n",
      "        Train, ce: 29891.5, r2: -12841.9, evo: 10000.0\n",
      "        Val  , ce: 28463.6, r2: -13200.8, evo: 9162.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 1/4, Epoch 22/100: 100%|██████████| 132/132 [01:10<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/4, Epoch 22/100, Total Loss, Train = 29424.8, Val = 29185.7, LR: 1.00e-03\n",
      "        Train, ce: 29424.8, r2: -12881.5, evo: 9917.1\n",
      "        Val  , ce: 29185.7, r2: -13307.9, evo: 10184.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 1/4, Epoch 23/100: 100%|██████████| 132/132 [01:10<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/4, Epoch 23/100, Total Loss, Train = 28265.1, Val = 29257.5, LR: 1.00e-03\n",
      "        Train, ce: 28265.1, r2: -12902.1, evo: 9669.4\n",
      "        Val  , ce: 29257.5, r2: -13210.0, evo: 10191.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 1/4, Epoch 24/100: 100%|██████████| 132/132 [01:10<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/4, Epoch 24/100, Total Loss, Train = 28565.7, Val = 25880.7, LR: 1.00e-03\n",
      "        Train, ce: 28565.7, r2: -12889.8, evo: 9736.1\n",
      "        Val  , ce: 25880.7, r2: -13357.2, evo: 9409.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 1/4, Epoch 25/100: 100%|██████████| 132/132 [01:10<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/4, Epoch 25/100, Total Loss, Train = 27559.5, Val = 26757.9, LR: 1.00e-03\n",
      "        Train, ce: 27559.5, r2: -12927.2, evo: 9506.8\n",
      "        Val  , ce: 26757.9, r2: -13347.2, evo: 9299.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 1/4, Epoch 26/100: 100%|██████████| 132/132 [01:09<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/4, Epoch 26/100, Total Loss, Train = 27623.2, Val = 26087.7, LR: 1.00e-03\n",
      "        Train, ce: 27623.2, r2: -12897.1, evo: 9522.1\n",
      "        Val  , ce: 26087.7, r2: -13288.6, evo: 8739.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 1/4, Epoch 27/100: 100%|██████████| 132/132 [01:10<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/4, Epoch 27/100, Total Loss, Train = 27359.9, Val = 25483.6, LR: 1.00e-03\n",
      "        Train, ce: 27359.9, r2: -12917.7, evo: 9464.7\n",
      "        Val  , ce: 25483.6, r2: -13322.5, evo: 8199.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 1/4, Epoch 28/100: 100%|██████████| 132/132 [01:10<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/4, Epoch 28/100, Total Loss, Train = 26509.6, Val = 25699.5, LR: 1.00e-03\n",
      "        Train, ce: 26509.6, r2: -12991.3, evo: 9275.7\n",
      "        Val  , ce: 25699.5, r2: -13393.6, evo: 8619.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 1/4, Epoch 29/100: 100%|██████████| 132/132 [01:10<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/4, Epoch 29/100, Total Loss, Train = 25965.6, Val = 24639.7, LR: 1.00e-03\n",
      "        Train, ce: 25965.6, r2: -12952.9, evo: 9159.3\n",
      "        Val  , ce: 24639.7, r2: -13310.1, evo: 8155.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 1/4, Epoch 30/100: 100%|██████████| 132/132 [01:10<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/4, Epoch 30/100, Total Loss, Train = 25678.8, Val = 24185.3, LR: 1.00e-03\n",
      "        Train, ce: 25678.8, r2: -12944.7, evo: 9095.0\n",
      "        Val  , ce: 24185.3, r2: -13343.8, evo: 7620.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 1/4, Epoch 31/100: 100%|██████████| 132/132 [01:10<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/4, Epoch 31/100, Total Loss, Train = 25461.7, Val = 23995.9, LR: 1.00e-03\n",
      "        Train, ce: 25461.7, r2: -12963.9, evo: 9060.5\n",
      "        Val  , ce: 23995.9, r2: -13428.9, evo: 8452.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 1/4, Epoch 32/100: 100%|██████████| 132/132 [01:10<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/4, Epoch 32/100, Total Loss, Train = 25278.4, Val = 23361.2, LR: 1.00e-03\n",
      "        Train, ce: 25278.4, r2: -12987.9, evo: 9015.4\n",
      "        Val  , ce: 23361.2, r2: -13423.3, evo: 8625.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 1/4, Epoch 33/100:  27%|██▋       | 36/132 [00:21<00:56,  1.69it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[8], line 75\u001b[0m\n",
      "\u001b[1;32m     72\u001b[0m optim_dense\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# 前向传播\u001b[39;00m\n",
      "\u001b[0;32m---> 75\u001b[0m logits, prob, mask_idx \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcid\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m     76\u001b[0m loss, logs \u001b[38;5;241m=\u001b[39m criterion(logits[:, mask_idx], prob[:, mask_idx], target[:, mask_idx], evo_mat)\n",
      "\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# 反向传播\u001b[39;00m\n",
      "\n",
      "File \u001b[0;32m~/miniconda3/envs/mamba/lib/python3.10/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n",
      "\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/miniconda3/envs/mamba/lib/python3.10/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n",
      "\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n",
      "\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n",
      "\u001b[1;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n",
      "\u001b[1;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n",
      "\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "\n",
      "File \u001b[0;32m/mnt/qmtang/EvoFill/src/model.py:475\u001b[0m, in \u001b[0;36mEvoFill.forward\u001b[0;34m(self, x, chunk_id)\u001b[0m\n",
      "\u001b[1;32m    472\u001b[0m z_full  \u001b[38;5;241m=\u001b[39m z_acc \u001b[38;5;241m/\u001b[39m cnt_acc\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)     \u001b[38;5;66;03m# (B, L, 2*d_model)\u001b[39;00m\n",
      "\u001b[1;32m    474\u001b[0m \u001b[38;5;66;03m# 3. 全局输出\u001b[39;00m\n",
      "\u001b[0;32m--> 475\u001b[0m logits  \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglobal_out\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz_full\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m                     \u001b[38;5;66;03m# (B, L, n_alleles-1)\u001b[39;00m\n",
      "\u001b[1;32m    477\u001b[0m \u001b[38;5;66;03m# 4. 返回并集区域\u001b[39;00m\n",
      "\u001b[1;32m    478\u001b[0m prob \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msoftmax(logits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\n",
      "File \u001b[0;32m~/miniconda3/envs/mamba/lib/python3.10/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n",
      "\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/miniconda3/envs/mamba/lib/python3.10/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n",
      "\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n",
      "\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n",
      "\u001b[1;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n",
      "\u001b[1;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n",
      "\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "\n",
      "File \u001b[0;32m/mnt/qmtang/EvoFill/src/model.py:368\u001b[0m, in \u001b[0;36mGlobalOut.forward\u001b[0;34m(self, x, mask)\u001b[0m\n",
      "\u001b[1;32m    366\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# (B, 2*d_model, L)\u001b[39;00m\n",
      "\u001b[1;32m    367\u001b[0m device \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mdevice\n",
      "\u001b[0;32m--> 368\u001b[0m idx \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]                \u001b[38;5;66;03m# 有效坐标 M\u001b[39;00m\n",
      "\u001b[1;32m    369\u001b[0m n \u001b[38;5;241m=\u001b[39m idx\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;32m    370\u001b[0m out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfull((x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw2\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]), \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m'\u001b[39m),\n",
      "\u001b[1;32m    371\u001b[0m                  device\u001b[38;5;241m=\u001b[39mdevice, dtype\u001b[38;5;241m=\u001b[39mx\u001b[38;5;241m.\u001b[39mdtype)\n",
      "\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "verbose            = False\n",
    "max_epochs         = 100\n",
    "lr                 = 0.001\n",
    "weight_decay       = 1e-5\n",
    "earlystop_patience = 11\n",
    "scheduler_factor   = 0.5\n",
    "scheduler_patience = 5\n",
    "scheduler_min_lr   = 1e-8\n",
    "\n",
    "\n",
    "for cid in range(model.n_chunks):\n",
    "    chunk_mask = model.chunk_masks[cid].cpu()\n",
    "    chunk_maf, chunk_bin_cnt = precompute_maf(gt_enc.X_gt[:,chunk_mask.bool().cpu().numpy()].toarray(),  mask_int=gt_enc.seq_depth)\n",
    "    if verbose:\n",
    "        print(f\"=== Chunk {cid + 1} STAT ===\")\n",
    "        maf_df = pd.DataFrame({\n",
    "            'MAF_bin': ['(0.00, 0.05)', '(0.05, 0.10)', '(0.10, 0.20)',\n",
    "                        '(0.20, 0.30)', '(0.30, 0.40)', '(0.40, 0.50)'],\n",
    "            'Counts':  [f\"{c}\" for c in chunk_bin_cnt],\n",
    "        })\n",
    "        print(maf_df.to_string(index=False))\n",
    "\n",
    "    # 收集所有稀疏参数（主要是嵌入层）\n",
    "    sparse_params = []\n",
    "    dense_params = []\n",
    "    # 当前chunk的模块参数（密集）\n",
    "    dense_params.extend(model.chunk_modules[cid].parameters())\n",
    "    \n",
    "    # 全局输出层的卷积参数（密集）\n",
    "    dense_params.extend([model.global_out.w1, model.global_out.b1])\n",
    "    dense_params.extend([model.global_out.w2, model.global_out.b2])\n",
    "    # ULR默认启用\n",
    "    if hasattr(model.global_out, 'ulr_mamba'):\n",
    "        for name, param in model.global_out.ulr_mamba.named_parameters():\n",
    "            if 'idx_embed' in name:\n",
    "                sparse_params.append(param)\n",
    "            else:\n",
    "                dense_params.append(param)\n",
    "    \n",
    "    # 创建分离优化器\n",
    "    optim_sparse = SparseAdam(sparse_params, lr=lr) if sparse_params else None\n",
    "    optim_dense = AdamW(dense_params, lr=lr, weight_decay=weight_decay, betas=(0.9, 0.999))\n",
    "    \n",
    "    # 学习率调度器\n",
    "    scheduler_sparse = ReduceLROnPlateau(optim_sparse, mode='min', factor=scheduler_factor, \n",
    "                        patience=scheduler_patience, min_lr=scheduler_min_lr) if optim_sparse else None\n",
    "    scheduler_dense = ReduceLROnPlateau(optim_dense, mode='min', factor=scheduler_factor, \n",
    "                        patience=scheduler_patience, min_lr=scheduler_min_lr)\n",
    "    \n",
    "    best_loss = float('inf')\n",
    "    patience = earlystop_patience\n",
    "    patience_counter = 0\n",
    "    is_early_stopped = False\n",
    "    train_logs_sum = None\n",
    "    test_logs_sum   = None\n",
    "    for epoch in range(max_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_prob, train_gts, train_mask = [], [], []\n",
    "\n",
    "        train_pbar = tqdm(train_loader, desc=f'Chunk {cid + 1}/{model.n_chunks}, Epoch {epoch + 1}/{max_epochs}',) # leave=False\n",
    "        for batch_idx, (x, target, evo_mat) in enumerate(train_pbar):\n",
    "            x,  target = x.to(device), target.to(device)\n",
    "            if evo_mat.numel() == 0:\n",
    "                evo_mat = None\n",
    "            else:\n",
    "                evo_mat = evo_mat.to(device)\n",
    "\n",
    "            # 清零梯度\n",
    "            if optim_sparse:\n",
    "                optim_sparse.zero_grad()\n",
    "            optim_dense.zero_grad()\n",
    "            \n",
    "            # 前向传播\n",
    "            logits, prob, mask_idx = model(x, cid)\n",
    "            loss, logs = criterion(logits[:, mask_idx], prob[:, mask_idx], target[:, mask_idx], evo_mat)\n",
    "            \n",
    "            # 反向传播\n",
    "            loss.backward()\n",
    "            \n",
    "            # 更新参数\n",
    "            if optim_sparse:\n",
    "                optim_sparse.step()\n",
    "            optim_dense.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            if train_logs_sum is None:          # 第一次初始化\n",
    "                train_logs_sum = {k: 0.0 for k in logs}\n",
    "            for k, v in logs.items():\n",
    "                train_logs_sum[k] += v\n",
    "            # train_pbar.set_postfix({'loss': loss.item(), 'ce':logs['ce'], 'r2':logs['r2'], 'evo':logs['evo']})\n",
    "\n",
    "            # === 收集训练结果 ===\n",
    "            miss_mask = x[:, mask_idx][..., -1].bool()         # 只关心被 mask 的位点\n",
    "            train_prob.append(prob[:, mask_idx].detach())\n",
    "            train_gts.append(target[:,mask_idx].detach())\n",
    "            train_mask.append(miss_mask)\n",
    "\n",
    "        # 训练集 MAF-acc\n",
    "        train_prob = torch.cat(train_prob, dim=0)\n",
    "        train_gts  = torch.cat(train_gts,    dim=0)\n",
    "        train_mask = torch.cat(train_mask,   dim=0)\n",
    "\n",
    "        # ----------- 验证循环同理 ------------\n",
    "        model.eval()\n",
    "        test_loss = 0.0\n",
    "        test_prob, test_gts = [], []\n",
    "        if test_logs_sum is None:\n",
    "            test_logs_sum = {k: 0.0 for k in train_logs_sum}\n",
    "        with torch.no_grad():\n",
    "            for x, target, evo_mat in test_loader:\n",
    "                x,  target = x.to(device), target.to(device)\n",
    "                if evo_mat.numel() == 0:\n",
    "                    evo_mat = None\n",
    "                else:\n",
    "                    evo_mat = evo_mat.to(device)\n",
    "                logits, prob, mask_idx = model(x, cid)\n",
    "                loss, logs = criterion(logits[:, mask_idx], prob[:, mask_idx], target[:,mask_idx], evo_mat) \n",
    "                test_loss += loss.item()\n",
    "                for k, v in logs.items():\n",
    "                    test_logs_sum[k] += v\n",
    "                test_prob.append(prob[:, mask_idx].detach())\n",
    "                test_gts.append(target[:,mask_idx].detach())\n",
    "\n",
    "        test_prob = torch.cat(test_prob, dim=0)\n",
    "        test_gts    = torch.cat(test_gts,    dim=0)\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        avg_test_loss   = test_loss   / len(test_loader)\n",
    "        avg_train_logs = {k: v / len(train_loader) for k, v in train_logs_sum.items()}\n",
    "        avg_test_logs = {k: v / len(test_loader) for k, v in test_logs_sum.items()}\n",
    "        \n",
    "        # 更新学习率\n",
    "        if scheduler_sparse:\n",
    "            scheduler_sparse.step(avg_test_loss)\n",
    "        scheduler_dense.step(avg_test_loss)\n",
    "        \n",
    "        current_denselr = optim_dense.param_groups[0]['lr']\n",
    "        current_sparselr = optim_sparse.param_groups[0]['lr'] if optim_sparse else 0\n",
    "\n",
    "        log_str = (f'Chunk {cid + 1}/{model.n_chunks}, '\n",
    "            f'Epoch {epoch + 1}/{max_epochs}, '\n",
    "            f'Total Loss, Train = {avg_train_loss:.1f}, '\n",
    "            f'Test = {avg_test_loss:.1f}, '\n",
    "            f'LR: {current_denselr:.2e}')\n",
    "\n",
    "        log_str += '\\n        Train'\n",
    "        for k, v in avg_train_logs.items():\n",
    "            log_str += f', {k}: {v:.1f}'\n",
    "        log_str += '\\n        Test '\n",
    "        for k, v in avg_test_logs.items():\n",
    "            log_str += f', {k}: {v:.1f}'\n",
    "        print(log_str)\n",
    "\n",
    "        # 清空累加器，供下一个 epoch 使用\n",
    "        train_logs_sum = {k: 0.0 for k in train_logs_sum}\n",
    "        test_logs_sum   = {k: 0.0 for k in test_logs_sum}\n",
    "        \n",
    "        # Early stopping\n",
    "        if avg_test_loss < best_loss:\n",
    "            best_loss = avg_test_loss\n",
    "            patience_counter = 0\n",
    "            # 只存当前 chunk 专家 + 全局层\n",
    "            ckpt = {\n",
    "                'chunk_id': cid,\n",
    "                'chunk_embed_state': model.chunk_embeds[cid].state_dict(),\n",
    "                'chunk_module_state': model.chunk_modules[cid].state_dict(),\n",
    "                'global_out_state': model.global_out.state_dict(),\n",
    "                'best_val_loss': best_loss,\n",
    "            }\n",
    "            torch.save(ckpt, f'{work_dir}/models/{model_name}_chunk[{cid}].pth')\n",
    "            predres_with_bestloss = (train_prob, train_gts, test_prob, test_gts)\n",
    "            if verbose:\n",
    "                train_bins_metrics = metrics_by_maf(train_prob, train_gts, hap_map = gt_enc.hap_map, maf_vec = chunk_maf, mask=train_mask)\n",
    "                test_bins_metrics   = metrics_by_maf(test_prob,  test_gts, hap_map = gt_enc.hap_map, maf_vec = chunk_maf, mask=None)\n",
    "                print_maf_stat_df(chunk_bin_cnt,\n",
    "                      {\"train\": train_bins_metrics,\n",
    "                       \"test\":  test_bins_metrics})\n",
    "                print(f'  --> updated {model_name}_chunk[{cid}].pth')\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= earlystop_patience:\n",
    "                is_early_stopped = True\n",
    "                print(f'Chunk {cid + 1}/{model.n_chunks}, Early stopping triggered')\n",
    "                train_prob, train_gts, test_prob, test_gts = predres_with_bestloss\n",
    "                train_bins_metrics = metrics_by_maf(train_prob, train_gts, hap_map = gt_enc.hap_map, maf_vec = chunk_maf, mask=train_mask)\n",
    "                test_bins_metrics   = metrics_by_maf(test_prob,   test_gts, hap_map = gt_enc.hap_map, maf_vec = chunk_maf, mask=None)\n",
    "                print_maf_stat_df(chunk_bin_cnt,\n",
    "                      {\"train\": train_bins_metrics,\n",
    "                       \"test\":   test_bins_metrics})\n",
    "                break\n",
    "\n",
    "    if not is_early_stopped:\n",
    "        train_bins_metrics = metrics_by_maf(train_prob, train_gts, hap_map = gt_enc.hap_map, maf_vec = chunk_maf, mask=train_mask)\n",
    "        test_bins_metrics   = metrics_by_maf(test_prob,   test_gts, hap_map = gt_enc.hap_map, maf_vec = chunk_maf, mask=None)\n",
    "        print_maf_stat_df(chunk_bin_cnt,\n",
    "                      {\"train\": train_bins_metrics,\n",
    "                       \"test\":   test_bins_metrics})\n",
    "\n",
    "    # 清理优化器\n",
    "    del optim_sparse, optim_dense\n",
    "    if scheduler_sparse:\n",
    "        del scheduler_sparse\n",
    "    del scheduler_dense\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# ---------------- 全部 chunk 训练完成 -> 保存完整模型 ----------------\n",
    "final_ckpt = {\n",
    "    'model_state': model.state_dict(),\n",
    "    'n_chunks': model.n_chunks,\n",
    "    'chunk_size': model.chunk_size,\n",
    "    'chunk_overlap': model.chunk_overlap,\n",
    "}\n",
    "torch.save(final_ckpt, f'{work_dir}/models/{model_name}_stage1.pth')\n",
    "print(f'==> STAGE1 (Chunk Module) training finished: {work_dir}/models/{model_name}_stage1.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c31c2bd",
   "metadata": {},
   "source": [
    "### 2.4 stage 2: Ultra-Long-Range LD Module Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e507273",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs_per_pair = 100\n",
    "lr                 = 5e-4\n",
    "weight_decay       = 1e-5\n",
    "earlystop_patience = 15\n",
    "batch_size         = 8\n",
    "verbose            = True\n",
    "\n",
    "criterion = ImputationLoss(use_r2=True, use_evo=True, r2_weight=1, evo_weight=4, evo_lambda=10)\n",
    "\n",
    "# ----------- 逐个 chunk 加载权重-----------\n",
    "# for cid in range(model.n_chunks):\n",
    "#     chunk_file = f'{work_dir}/models/{model_name}_chunk_{cid}.pth'\n",
    "#     ckpt = torch.load(chunk_file, map_location='cpu')\n",
    "#     model.chunk_embeds[cid].load_state_dict(ckpt['chunk_embed_state'])\n",
    "#     model.chunk_modules[cid].load_state_dict(ckpt['chunk_module_state'])\n",
    "\n",
    "# ----------- 加载第一阶段完整权重-----------\n",
    "ckpt = torch.load(f'{work_dir}/models/{model_name}_stage1.pth', map_location='cpu')\n",
    "model.load_state_dict(ckpt['model_state'])\n",
    "\n",
    "model.eval()        # chunk 专家冻结（requires_grad=False）\n",
    "\n",
    "# 收集所有稀疏参数（主要是嵌入层）\n",
    "sparse_params = []\n",
    "dense_params = []\n",
    "# 全局输出层的卷积参数（密集）\n",
    "dense_params.extend([model.global_out.w1, model.global_out.b1])\n",
    "dense_params.extend([model.global_out.w2, model.global_out.b2])\n",
    "# ULR默认启用\n",
    "if hasattr(model.global_out, 'ulr_mamba'):\n",
    "    for name, param in model.global_out.ulr_mamba.named_parameters():\n",
    "        if 'idx_embed' in name:\n",
    "            sparse_params.append(param)\n",
    "        else:\n",
    "            dense_params.append(param)\n",
    "\n",
    "# 创建分离优化器\n",
    "optim_sparse = SparseAdam(sparse_params, lr=lr) if sparse_params else None\n",
    "optim_dense = AdamW(dense_params, lr=lr, weight_decay=weight_decay, betas=(0.9, 0.999))\n",
    "\n",
    "# 学习率调度器\n",
    "scheduler_sparse = ReduceLROnPlateau(optim_sparse, mode='min', factor=0.5, patience=5, min_lr=1e-9) if optim_sparse else None\n",
    "scheduler_dense = ReduceLROnPlateau(optim_dense, mode='min', factor=0.5, patience=5, min_lr=1e-9)\n",
    "\n",
    "pair_list = list(combinations(range(model.n_chunks), 2))\n",
    "np.random.shuffle(pair_list)          # 打乱\n",
    "total_pairs = len(pair_list)\n",
    "\n",
    "for pair_idx, (cid1, cid2) in enumerate(pair_list, 1):\n",
    "    # ====== 构造并集 mask ======\n",
    "    union_mask = (model.chunk_masks[cid1] + model.chunk_masks[cid2]).clamp(max=1).bool()\n",
    "    train_logs_sum = None\n",
    "    val_logs_sum   = None\n",
    "    \n",
    "    # 并集 MAF\n",
    "    union_maf, union_bin_cnt = precompute_maf(\n",
    "        gt_enc.X_gt[:, union_mask.cpu().numpy()].toarray(),\n",
    "        mask_int=gt_enc.seq_depth\n",
    "    )\n",
    "\n",
    "    # ====== 早停变量 ======\n",
    "    best_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    is_early_stopped = False\n",
    "\n",
    "    # ====== 训练循环 ======\n",
    "    for epoch in range(max_epochs_per_pair):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_prob, train_gts, train_mask = [], [], []\n",
    "\n",
    "        pbar = tqdm(train_loader,\n",
    "                    desc=f'Comb {pair_idx}/{total_pairs}  '\n",
    "                         f'{cid1+1}-{cid2+1}  Epoch {epoch+1}/{max_epochs_per_pair}',\n",
    "                    leave=False)\n",
    "        for x, target, evo_mat in pbar:\n",
    "            x,  target = x.to(device), target.to(device)\n",
    "            if evo_mat.numel() == 0:\n",
    "                evo_mat = None\n",
    "            else:\n",
    "                evo_mat = evo_mat.to(device)\n",
    "\n",
    "            optim_sparse.zero_grad()\n",
    "            optim_dense.zero_grad()\n",
    "\n",
    "            logits, prob, mask_idx = model(x, [cid1, cid2])\n",
    "            loss, logs = criterion(logits[:, mask_idx], prob[:, mask_idx], target[:,mask_idx], evo_mat) \n",
    "            loss.backward()\n",
    "\n",
    "            optim_sparse.step()   # 只更新嵌入表\n",
    "            optim_dense.step()    # 更新其余所有参数\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            if train_logs_sum is None:          # 第一次初始化\n",
    "                train_logs_sum = {k: 0.0 for k in logs}\n",
    "            for k, v in logs.items():\n",
    "                train_logs_sum[k] += v\n",
    "            # pbar.set_postfix({'loss': loss.item(), 'ce':logs['ce'], 'r2':logs['r2'], 'evo':logs['evo']})\n",
    "\n",
    "            # 收集指标\n",
    "            miss_mask = x[:,union_mask][..., -1].bool()\n",
    "            train_prob.append(prob[:, mask_idx].detach())\n",
    "            train_gts.append(target[:,mask_idx].detach())\n",
    "            train_mask.append(miss_mask)\n",
    "\n",
    "        # 训练集 MAF\n",
    "        train_prob = torch.cat(train_prob, dim=0)\n",
    "        train_gts  = torch.cat(train_gts,    dim=0)\n",
    "        train_mask = torch.cat(train_mask,   dim=0)\n",
    "\n",
    "        # ----------- 验证 -----------\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_prob, val_gts = [], []\n",
    "        with torch.no_grad():\n",
    "            if val_logs_sum is None:\n",
    "                val_logs_sum = {k: 0.0 for k in train_logs_sum}\n",
    "            for x, target, evo_mat in test_loader:\n",
    "                x = x.to(device)\n",
    "                target = target.to(device)\n",
    "                evo_mat = evo_mat.to(device) if evo_mat.numel() else None\n",
    "                logits, prob, mask_idx = model(x, [cid1, cid2])\n",
    "                loss, logs = criterion(logits[:, mask_idx], prob[:, mask_idx], target[:,mask_idx], evo_mat)\n",
    "                val_loss += loss.item()\n",
    "                for k, v in logs.items():\n",
    "                    val_logs_sum[k] += v\n",
    "                val_prob.append(prob[:,mask_idx])\n",
    "                val_gts.append(target[:,mask_idx])\n",
    "\n",
    "        val_prob = torch.cat(val_prob, dim=0)\n",
    "        val_gts  = torch.cat(val_gts,    dim=0)\n",
    "\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        avg_val_loss   = val_loss   / len(test_loader)\n",
    "        avg_train_logs = {k: v / len(train_loader) for k, v in train_logs_sum.items()}\n",
    "        avg_val_logs = {k: v / len(test_loader) for k, v in val_logs_sum.items()}\n",
    "        \n",
    "        scheduler_sparse.step(val_loss)\n",
    "        scheduler_dense.step(val_loss)\n",
    "\n",
    "        current_denselr = optim_dense.param_groups[0]['lr']\n",
    "        current_sparselr = optim_sparse.param_groups[0]['lr']\n",
    "\n",
    "        log_str = (f'Comb {pair_idx}/{total_pairs}  '\n",
    "            f'{cid1+1}-{cid2+1}  Epoch {epoch+1}/{max_epochs_per_pair} '\n",
    "            f'Total Loss, Train = {avg_train_loss:.1f}, '\n",
    "            f'Val = {avg_val_loss:.1f}, '\n",
    "            f'dense LR: {current_denselr:.2e}, '\n",
    "            f'sparse LR: {current_sparselr:.2e}')\n",
    "        log_str += '\\n        Train'\n",
    "        for k, v in avg_train_logs.items():\n",
    "            log_str += f', {k}: {v:.1f}'\n",
    "        log_str += '\\n        Val  '\n",
    "        for k, v in avg_val_logs.items():\n",
    "            log_str += f', {k}: {v:.1f}'\n",
    "        print(log_str)\n",
    "        # 清空累加器，供下一个 epoch 使用\n",
    "        train_logs_sum = {k: 0.0 for k in train_logs_sum}\n",
    "        val_logs_sum   = {k: 0.0 for k in val_logs_sum}\n",
    "        # 早停\n",
    "        if avg_val_loss < best_loss:\n",
    "            best_loss = avg_val_loss\n",
    "            patience_counter = 0\n",
    "            torch.save({\n",
    "                'comb': (cid1, cid2),\n",
    "                'global_out': model.global_out.state_dict(),\n",
    "                'best_val_loss': best_loss,\n",
    "                'epoch': epoch,\n",
    "            }, f'{work_dir}/models/{model_name}_chunk[{cid1}-{cid2}].pth')\n",
    "            # MAF 表格\n",
    "            predres_with_bestloss = (train_prob, train_gts, val_prob, val_gts)\n",
    "            if verbose:\n",
    "                train_bins_metrics = metrics_by_maf(train_prob, train_gts, gt_enc.hap_map, union_maf, mask=train_mask)\n",
    "                val_bins_metrics   = metrics_by_maf(val_prob,   val_gts, gt_enc.hap_map, union_maf, mask=None)\n",
    "                print_maf_stat_df(chunk_bin_cnt,\n",
    "                      {\"train\": train_bins_metrics,\n",
    "                       \"val\":   val_bins_metrics})\n",
    "                print(f'  --> updated {model_name}_chunk[{cid1+1}-{cid2+1}].pth')\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= earlystop_patience:\n",
    "                is_early_stopped = True\n",
    "                print(f'Pair {cid1+1}-{cid2+1} early stopping')\n",
    "                train_prob, train_gts, val_prob, val_gts = predres_with_bestloss\n",
    "                train_bins_metrics = metrics_by_maf(train_prob, train_gts, gt_enc.hap_map, union_maf, mask=train_mask)\n",
    "                val_bins_metrics   = metrics_by_maf(val_prob,   val_gts, gt_enc.hap_map, union_maf, mask=None)\n",
    "                print_maf_stat_df(chunk_bin_cnt,\n",
    "                      {\"train\": train_bins_metrics,\n",
    "                       \"val\":   val_bins_metrics})\n",
    "                break\n",
    "            \n",
    "    if not is_early_stopped:\n",
    "        predres_with_bestloss = (train_prob, train_gts, val_prob, val_gts)\n",
    "        train_bins_metrics = metrics_by_maf(train_prob, train_gts, gt_enc.hap_map, union_maf, mask=train_mask)\n",
    "        val_bins_metrics   = metrics_by_maf(val_prob,   val_gts, gt_enc.hap_map, union_maf, mask=None)\n",
    "        print_maf_stat_df(chunk_bin_cnt,\n",
    "                      {\"train\": train_bins_metrics,\n",
    "                       \"val\":   val_bins_metrics})\n",
    "\n",
    "    # del optimizer, scheduler\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# ----------- 全部 pair 结束 -> 保存最终模型 -----------\n",
    "torch.save({\n",
    "    'model_state': model.state_dict(),\n",
    "    'ulr_enabled': True,\n",
    "}, f'{work_dir}/models/{model_name}_stage2_final.pth')\n",
    "print(f'==> STAGE2 training finished: {work_dir}/models/{model_name}_stage2_final.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca99878",
   "metadata": {},
   "source": [
    "### 2.5 stage 3: fine tuning with URP samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd0498be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DATA] 总计 99,314 个位点  \n",
      "[DATA] EvoMat shape: (16, 16)\n",
      "[DATA] 位点矩阵 = (16, 99314)，稀疏度 = 27.35%，缺失率 = 0.00%\n",
      "[DATA] 位点字典 = {'0|0': 0, '0|1': 1, '1|1': 2, '.|.': 3}，字典深度 = 4\n",
      "[URP] 16 samples, 99314 variants\n"
     ]
    }
   ],
   "source": [
    "# %%  载入 URP 微调数据\n",
    "gt_enc_urp = GenotypeEncoder(phased=False, gts012=False, save2disk=False)\n",
    "gt_enc_urp = gt_enc_urp.encode_ref(\n",
    "        ref_meta_json = work_dir/\"pre_train\"/\"gt_enc_meta.json\",   # 与 Stage1 同构\n",
    "        vcf_path      = work_dir/\"urp_finetune\"/\"minor_pops.10pct.vcf.gz\",\n",
    "        evo_mat       = work_dir/\"urp_finetune\"/\"evo_mat_minor_pops.10pct.tsv\")\n",
    "\n",
    "print(f'[URP] {gt_enc_urp.n_samples} samples, {gt_enc_urp.n_variants} variants')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62237762",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "# %%  Stage-3 超参与配置\n",
    "model_name  = 'hg19_chr22trim'\n",
    "stage3_tag       = 'stage3'\n",
    "max_epochs       = 50\n",
    "warmup_epochs    = 3\n",
    "lr_dense         = 1e-4          # GlobalOut 中稠密参数\n",
    "lr_sparse        = 5e-5          # ULR 中的 idx_embed\n",
    "weight_decay     = 1e-4\n",
    "earlystop_pat    = 9\n",
    "mask_rate_range  = (0.2, 0.6)    # 数据增强：随机缺失率\n",
    "k_fold           = 5             # 交叉验证\n",
    "batch_size       = 4             # 样本少，用小 batch\n",
    "accumulate_grad  = 2             # 梯度累加，等效 batch=8\n",
    "\n",
    "# %%  重新建立「微调」Dataset / Loader\n",
    "urp_dataset = GenomicDataset(\n",
    "        gt_enc_urp.X_gt,\n",
    "        evo_mat      = gt_enc_urp.evo_mat,\n",
    "        seq_depth    = gt_enc_urp.seq_depth,\n",
    "        mask         = True,\n",
    "        masking_rates= mask_rate_range,\n",
    "        indices      = None)               # 全部用于微调\n",
    "\n",
    "def collate_fn(batch):\n",
    "    x = torch.stack([b[0] for b in batch])\n",
    "    y = torch.stack([b[1] for b in batch])\n",
    "    idx = [b[2] for b in batch]\n",
    "    if gt_enc_urp.evo_mat is not None:\n",
    "        evo = gt_enc_urp.evo_mat[np.ix_(idx, idx)]\n",
    "        evo = torch.FloatTensor(evo)\n",
    "    else:\n",
    "        evo = torch.empty(0)\n",
    "    return x, y, evo\n",
    "\n",
    "urp_loader = DataLoader(urp_dataset, batch_size=batch_size,\n",
    "                        shuffle=True, num_workers=4,\n",
    "                        pin_memory=True, collate_fn=collate_fn)\n",
    "\n",
    "# 1. 准备 URP 数据\n",
    "urp_idx = np.arange(gt_enc_urp.n_samples)\n",
    "kf = KFold(n_splits=k_fold, shuffle=True, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6a16f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Stage3] Stage-2 weights loaded.\n",
      "Epoch 1: avg_val_loss=68964.580, lr_dense=0.0e+00\n",
      "Epoch 2: avg_val_loss=60720.118, lr_dense=3.3e-05\n",
      "Epoch 3: avg_val_loss=49563.400, lr_dense=6.7e-05\n",
      "Epoch 4: avg_val_loss=43253.447, lr_dense=1.0e-04\n",
      "Epoch 5: avg_val_loss=41547.148, lr_dense=1.0e-04\n",
      "Epoch 6: avg_val_loss=34705.204, lr_dense=1.0e-04\n",
      "Epoch 7: avg_val_loss=34851.017, lr_dense=9.9e-05\n",
      "Epoch 8: avg_val_loss=31193.683, lr_dense=9.8e-05\n",
      "Epoch 9: avg_val_loss=25390.002, lr_dense=9.7e-05\n",
      "Epoch 10: avg_val_loss=32677.517, lr_dense=9.6e-05\n",
      "Epoch 11: avg_val_loss=29019.098, lr_dense=9.5e-05\n",
      "Epoch 12: avg_val_loss=25310.655, lr_dense=9.3e-05\n",
      "Epoch 13: avg_val_loss=30964.865, lr_dense=9.1e-05\n",
      "Epoch 14: avg_val_loss=22583.397, lr_dense=8.9e-05\n",
      "Epoch 15: avg_val_loss=26063.507, lr_dense=8.7e-05\n",
      "Epoch 16: avg_val_loss=21442.901, lr_dense=8.5e-05\n",
      "Epoch 17: avg_val_loss=25226.832, lr_dense=8.2e-05\n",
      "Epoch 18: avg_val_loss=21774.188, lr_dense=8.0e-05\n",
      "Epoch 19: avg_val_loss=22828.542, lr_dense=7.7e-05\n",
      "Epoch 20: avg_val_loss=24742.759, lr_dense=7.4e-05\n",
      "Epoch 21: avg_val_loss=23651.618, lr_dense=7.1e-05\n",
      "Epoch 22: avg_val_loss=18767.613, lr_dense=6.8e-05\n",
      "Epoch 23: avg_val_loss=17076.952, lr_dense=6.5e-05\n",
      "Epoch 24: avg_val_loss=19388.626, lr_dense=6.2e-05\n",
      "Epoch 25: avg_val_loss=18005.484, lr_dense=5.8e-05\n",
      "Epoch 26: avg_val_loss=20153.156, lr_dense=5.5e-05\n",
      "Epoch 27: avg_val_loss=18616.133, lr_dense=5.2e-05\n",
      "Epoch 28: avg_val_loss=22284.545, lr_dense=4.8e-05\n",
      "Epoch 29: avg_val_loss=15514.380, lr_dense=4.5e-05\n",
      "Epoch 30: avg_val_loss=20566.186, lr_dense=4.2e-05\n",
      "Epoch 31: avg_val_loss=19128.202, lr_dense=3.8e-05\n",
      "Epoch 32: avg_val_loss=20435.949, lr_dense=3.5e-05\n",
      "Epoch 33: avg_val_loss=18375.392, lr_dense=3.2e-05\n",
      "Epoch 34: avg_val_loss=16949.377, lr_dense=2.9e-05\n",
      "Epoch 35: avg_val_loss=16244.510, lr_dense=2.6e-05\n",
      "Epoch 36: avg_val_loss=18029.811, lr_dense=2.3e-05\n",
      "Epoch 37: avg_val_loss=16218.810, lr_dense=2.0e-05\n",
      "Epoch 38: avg_val_loss=15077.565, lr_dense=1.8e-05\n",
      "Epoch 39: avg_val_loss=15867.217, lr_dense=1.5e-05\n",
      "Epoch 40: avg_val_loss=18540.564, lr_dense=1.3e-05\n",
      "Epoch 41: avg_val_loss=17621.958, lr_dense=1.1e-05\n",
      "Epoch 42: avg_val_loss=14552.724, lr_dense=8.8e-06\n",
      "Epoch 43: avg_val_loss=17220.939, lr_dense=7.0e-06\n",
      "Epoch 44: avg_val_loss=15995.278, lr_dense=5.4e-06\n",
      "Epoch 45: avg_val_loss=14565.957, lr_dense=4.0e-06\n",
      "Epoch 46: avg_val_loss=15530.843, lr_dense=2.8e-06\n",
      "Epoch 47: avg_val_loss=17135.007, lr_dense=1.8e-06\n",
      "Epoch 48: avg_val_loss=15153.898, lr_dense=1.0e-06\n",
      "Epoch 49: avg_val_loss=13754.592, lr_dense=4.5e-07\n",
      "Epoch 50: avg_val_loss=19393.079, lr_dense=1.1e-07\n",
      "==> Stage-3 KFold-loss fine-tuning finished. Best avg_val_loss=13754.592\n"
     ]
    }
   ],
   "source": [
    "# %%  载入 Stage-2 最终权重\n",
    "ckpt = torch.load(f'{work_dir}/models/{model_name}_stage1.pth', map_location='cpu')\n",
    "model.load_state_dict(ckpt['model_state'])\n",
    "print('[Stage3] Stage-2 weights loaded.')\n",
    "\n",
    "# %%  参数分组 & 优化器\n",
    "for p in model.parameters():                # 先全部冻结\n",
    "    p.requires_grad = False\n",
    "\n",
    "# 只解冻需要的部分\n",
    "trainable_dense, trainable_sparse = [], []\n",
    "# 1. GlobalOut 全部\n",
    "for name, p in model.global_out.named_parameters():\n",
    "    if 'idx_embed' in name:\n",
    "        trainable_sparse.append(p)\n",
    "    else:\n",
    "        trainable_dense.append(p)\n",
    "# 2. Chunk-Embedding（可选，若显存紧张可留冻）\n",
    "for emb in model.chunk_embeds:\n",
    "    for p in emb.parameters():\n",
    "        trainable_dense.append(p)\n",
    "\n",
    "for p in trainable_dense+trainable_sparse:\n",
    "    p.requires_grad = True\n",
    "\n",
    "opt_dense  = AdamW(trainable_dense,  lr=lr_dense,\n",
    "                   weight_decay=weight_decay, betas=(0.9, 0.999))\n",
    "opt_sparse = SparseAdam(trainable_sparse, lr=lr_sparse)\n",
    "\n",
    "# 余弦退火 + 热身\n",
    "def lr_lambda(epoch):\n",
    "    if epoch < warmup_epochs:\n",
    "        return epoch / warmup_epochs\n",
    "    return 0.5*(1+np.cos(np.pi*(epoch-warmup_epochs)/(max_epochs-warmup_epochs)))\n",
    "\n",
    "sched_dense  = torch.optim.lr_scheduler.LambdaLR(opt_dense,  lr_lambda)\n",
    "sched_sparse = torch.optim.lr_scheduler.LambdaLR(opt_sparse, lr_lambda)\n",
    "\n",
    "# %%  训练循环\n",
    "criterion = ImputationLoss(use_r2=True, use_evo=True,\n",
    "                           r2_weight=1, evo_weight=4, evo_lambda=10)\n",
    "\n",
    "best_avg_val_loss, patience_counter = np.inf, 0\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    model.train()\n",
    "    fold_val_loss = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(urp_idx)):\n",
    "        # ---- 当前折数据 ----\n",
    "        train_dataset = GenomicDataset(\n",
    "                gt_enc_urp.X_gt, evo_mat=gt_enc_urp.evo_mat,\n",
    "                seq_depth=gt_enc_urp.seq_depth, mask=True,\n",
    "                masking_rates=(0.2, 0.6), indices=train_idx)\n",
    "        val_dataset   = GenomicDataset(\n",
    "                gt_enc_urp.X_gt, evo_mat=gt_enc_urp.evo_mat,\n",
    "                seq_depth=gt_enc_urp.seq_depth, mask=True,\n",
    "                masking_rates=(0.2, 0.6), indices=val_idx)\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size=8,\n",
    "                                  shuffle=True, num_workers=2,\n",
    "                                  collate_fn=collate_fn, pin_memory=True)\n",
    "        val_loader   = DataLoader(val_dataset, batch_size=8,\n",
    "                                  shuffle=False, num_workers=2,\n",
    "                                  collate_fn=collate_fn, pin_memory=True)\n",
    "\n",
    "        # ---- 训练 ----\n",
    "        for step, (x, y, evo) in enumerate(train_loader):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            evo  = evo.to(device) if evo.numel() else None\n",
    "\n",
    "            logits, prob, mask_idx = model(x)\n",
    "            loss, _ = criterion(logits[:, mask_idx], prob[:, mask_idx],\n",
    "                                y[:, mask_idx], evo)\n",
    "            loss.backward()\n",
    "\n",
    "            if (step+1) % accumulate_grad == 0 or (step+1) == len(train_loader):\n",
    "                opt_dense.step(); opt_sparse.step()\n",
    "                opt_dense.zero_grad(set_to_none=True); opt_sparse.zero_grad(set_to_none=True)\n",
    "\n",
    "        # ---- 验证 ----\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for x, y, evo in val_loader:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                evo  = evo.to(device) if evo.numel() else None\n",
    "                logits, prob, mask_idx = model(x)\n",
    "                loss, _ = criterion(logits[:, mask_idx], prob[:, mask_idx],\n",
    "                                    y[:, mask_idx], evo)\n",
    "                val_loss += loss.item()\n",
    "        fold_val_loss.append(val_loss / len(val_loader))\n",
    "\n",
    "    # ---- epoch 级日志 & 调度 ----\n",
    "    avg_val_loss = np.mean(fold_val_loss)\n",
    "    print(f'Epoch {epoch+1}: avg_val_loss={avg_val_loss:.3f}, '\n",
    "          f'lr_dense={opt_dense.param_groups[0][\"lr\"]:.1e}')\n",
    "    sched_dense.step(); sched_sparse.step()\n",
    "\n",
    "    # ---- 早停 ----\n",
    "    if avg_val_loss < best_avg_val_loss:\n",
    "        best_avg_val_loss = avg_val_loss\n",
    "        patience_counter = 0\n",
    "        torch.save({'model_state': model.state_dict(),\n",
    "                    'epoch': epoch,\n",
    "                    'avg_val_loss': avg_val_loss},\n",
    "                   f'{work_dir}/models/{model_name}_{stage3_tag}_best.pth')\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= earlystop_pat:\n",
    "            print('Early stopping triggered.')\n",
    "            break\n",
    "\n",
    "torch.save({'model_state': model.state_dict(),\n",
    "            'stage3_tag': stage3_tag},\n",
    "           f'{work_dir}/models/{model_name}_{stage3_tag}_final.pth')\n",
    "print(f'==> Stage-3 KFold-loss fine-tuning finished. Best avg_val_loss={best_avg_val_loss:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b718f797",
   "metadata": {},
   "source": [
    "## 3. Imputation using trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4034fdcb",
   "metadata": {},
   "source": [
    "### 3.1 Load the trained model\n",
    "\n",
    "Choose a path where including `<work_dir>/model` and have trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4c2e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Work Dir: /mnt/qmtang/EvoFill_data/20251107_ver4\n",
      "[INF] Model[hg19_chr22trim] loaded.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Work Dir: {work_dir}\")\n",
    "\n",
    "# ---- 1. 加载模型 ----\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "json_path = f\"{work_dir}/models/model_meta.json\"\n",
    "meta = json.load(open(json_path))\n",
    "model = EvoFill(\n",
    "    d_model=int(meta[\"d_model\"]),\n",
    "    n_alleles=int(meta[\"alleles\"]),\n",
    "    total_sites=int(meta[\"total_sites\"]),\n",
    "    chunk_size=int(meta[\"chunk_size\"]),\n",
    "    chunk_overlap=int(meta[\"overlap\"])\n",
    ").to(device)\n",
    "\n",
    "# ckpt = torch.load(f'{work_dir}/models/{meta[\"model_name\"]}_stage1.pth', map_location=device)\n",
    "# ckpt = torch.load(f'{work_dir}/models/{meta[\"model_name\"]}_stage2_best.pth', map_location=device)\n",
    "ckpt = torch.load(f'{work_dir}/models/{meta[\"model_name\"]}_stage3_best.pth', map_location=device)\n",
    "model.load_state_dict(ckpt['model_state'])\n",
    "model.eval()\n",
    "print(f'[INF] Model[{meta[\"model_name\"]}] loaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5542df7b",
   "metadata": {},
   "source": [
    "### 3.2 Encode .vcf file need be impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55e661be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DATA] 总计 99,314 个位点  \n",
      "[DATA] 位点矩阵 = (152, 99314)，稀疏度 = 63.43%，缺失率 = 50.01%\n",
      "[DATA] 位点字典 = {'0|0': 0, '0|1': 1, '1|1': 2, '.|.': 3}，字典深度 = 4\n",
      "[INFER] 152 samples, 99314 variants\n",
      "[ImputationDataset] 152 samples, missing rate = 50.01%\n"
     ]
    }
   ],
   "source": [
    "gt_enc_imp = GenotypeEncoder(phased=False, gts012=False, save2disk=False)\n",
    "gt_enc_imp = gt_enc_imp.encode_ref(\n",
    "        ref_meta_json = work_dir/\"pre_train\"/\"gt_enc_meta.json\",   # 与 Stage1 同构\n",
    "        vcf_path      = work_dir/\"impute_in\"/\"minor_pops.90pct.masked50p.vcf.gz\" )\n",
    "\n",
    "print(f'[INFER] {gt_enc_imp.n_samples} samples, {gt_enc_imp.n_variants} variants')\n",
    "\n",
    "# ---- 2. 构建推理 Dataset / Loader ----\n",
    "imp_dataset = ImputationDataset(\n",
    "    x_gts_sparse=gt_enc_imp.X_gt,\n",
    "    seq_depth=gt_enc_imp.seq_depth,\n",
    "    indices=None                 # 可传入指定样本索引\n",
    ")\n",
    "imp_dataset.print_missing_stat()          # 查看原始缺失比例\n",
    "\n",
    "def collate_fn(batch):\n",
    "    x_onehot = torch.stack([item[0] for item in batch])\n",
    "    real_idx_list = [item[1] for item in batch]\n",
    "    return x_onehot, real_idx_list   # 无 y\n",
    "\n",
    "imp_loader = torch.utils.data.DataLoader(\n",
    "    imp_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809730fd",
   "metadata": {},
   "source": [
    "### 3.3 Inferring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34d5223c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Imputing: 100%|██████████| 3/3 [00:20<00:00,  6.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INF] 概率矩阵已保存 → /mnt/qmtang/EvoFill_data/20251107_ver4/impute_out/impute_prob.npy with shape = (152, 99314, 3) \n"
     ]
    }
   ],
   "source": [
    "y_prob = []\n",
    "y_mask = []\n",
    "with torch.no_grad():\n",
    "    for x_onehot, real_idx in tqdm(imp_loader, desc='Imputing'):\n",
    "        x_onehot = x_onehot.to(device)\n",
    "        _, prob, _ = model(x_onehot)\n",
    "        miss_mask = x_onehot[..., -1].bool()\n",
    "        y_prob.append(prob)\n",
    "        y_mask.append(miss_mask)\n",
    "y_prob = torch.cat(y_prob, dim=0).cpu().numpy()\n",
    "y_mask = torch.cat(y_mask, dim=0).cpu().numpy()\n",
    "# 4. 保存\n",
    "out_dir = os.path.join(work_dir, 'impute_out')\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "np.save(os.path.join(out_dir, 'impute_prob.npy'), y_prob)\n",
    "np.save(os.path.join(out_dir, 'impute_mask.npy'), y_mask)\n",
    "print(f'[INF] 概率矩阵已保存 → {out_dir}/impute_prob.npy '\n",
    "      f'with shape = {y_prob.shape} ')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da27d710",
   "metadata": {},
   "source": [
    "### 3.4 Evaluating the imputation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b435b8ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DATA] 总计 99,314 个位点  \n",
      "[DATA] 位点矩阵 = (152, 99314)，稀疏度 = 26.84%，缺失率 = 0.00%\n",
      "[DATA] 位点字典 = {'0|0': 0, '0|1': 1, '1|1': 2, '.|.': 3}，字典深度 = 4\n",
      "     MAF_bin Counts val_Acc val_INFO val_IQS val_MaCH\n",
      "(0.00, 0.05)  41365   0.976    0.379   0.082    0.939\n",
      "(0.05, 0.10)   9108   0.930    0.506   0.384    0.770\n",
      "(0.10, 0.20)  11962   0.898    0.614   0.544    0.836\n",
      "(0.20, 0.30)  12887   0.857    0.725   0.668    0.919\n",
      "(0.30, 0.40)  17081   0.844    0.774   0.720    0.962\n",
      "(0.40, 0.50)   6909   0.840    0.784   0.722    0.960\n"
     ]
    }
   ],
   "source": [
    "gt_enc_true = GenotypeEncoder(phased=False, gts012=False, save2disk=False)\n",
    "gt_enc_true = gt_enc_true.encode_ref(\n",
    "        ref_meta_json = work_dir/\"pre_train\"/\"gt_enc_meta.json\",   # 与 Stage1 同构\n",
    "        vcf_path      = work_dir/\"impute_out\"/\"minor_pops.90pct.vcf.gz\" )\n",
    "y_true = gt_enc_true.X_gt.toarray()\n",
    "maf, bin_cnt = precompute_maf(y_true,  mask_int=gt_enc_true.seq_depth)\n",
    "y_true_oh = np.eye(gt_enc_true.seq_depth - 1)[y_true]\n",
    "bins_metrics   = metrics_by_maf(y_prob, y_true_oh, hap_map = gt_enc_true.hap_map, maf_vec = maf, mask=y_mask)\n",
    "print_maf_stat_df(bin_cnt,{'val': bins_metrics})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de94e3af",
   "metadata": {},
   "source": [
    "### 3.5 Saving to .vcf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a3c07302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INF] 缺失位点填充完成 → /mnt/qmtang/EvoFill_data/20251107_ver4/impute_out/imputed.vcf.gz\n"
     ]
    }
   ],
   "source": [
    "from cyvcf2 import VCF, Writer\n",
    "\n",
    "# 0. 路径\n",
    "ref_vcf = \"/mnt/qmtang/EvoFill_data/20251107_ver4/minor_pops.masked30p.vcf.gz\"\n",
    "out_vcf = os.path.join(out_dir, 'imputed.vcf.gz')\n",
    "\n",
    "n_site = gt_enc.n_variants\n",
    "n_samp = gt_enc.n_samples\n",
    "n_alleles = gt_enc.seq_depth - 1\n",
    "assert y_prob.shape == (n_samp, n_site, n_alleles)\n",
    "\n",
    "# 2. 反向映射  idx -> '0|0' / '0|1' / ...\n",
    "rev_hap_map = {v: k for k, v in gt_enc.hap_map.items()}\n",
    "\n",
    "samp2idx = {sid: i for i, sid in enumerate(gt_enc.sample_ids)}\n",
    "\n",
    "# 4. 打开参考 VCF\n",
    "invcf = VCF(ref_vcf)\n",
    "tmpl  = invcf\n",
    "tmpl.set_samples(gt_enc.sample_ids)   # 替换样本列\n",
    "\n",
    "out = Writer(out_vcf, tmpl, mode='wz')\n",
    "\n",
    "for rec_idx, rec in enumerate(invcf):\n",
    "    # 当前位点全部样本的 GT\n",
    "    gt_int_pairs = []\n",
    "    for samp_idx, sample_id in enumerate(gt_enc.sample_ids):\n",
    "        old_gt = rec.genotypes[samp_idx]          # [allele1, allele2, phased]\n",
    "        if old_gt[0] == -1 or old_gt[1] == -1:    # 缺失\n",
    "            prob_vec = y_prob[samp_idx, rec_idx, :].ravel()\n",
    "            best_idx = int(prob_vec.argmax())\n",
    "            gt_str   = rev_hap_map[best_idx]\n",
    "            alleles  = list(map(int, gt_str.split('|')))\n",
    "            phased   = old_gt[2] if old_gt[2] != -1 else 1\n",
    "            gt_int_pairs.append([alleles[0], alleles[1], phased])\n",
    "        else:                                       # 非缺失，保持原样\n",
    "            gt_int_pairs.append(old_gt)\n",
    "\n",
    "    # 转成 int8 二维数组  (n_sample, 3)  last dim = [a1,a2,phased]\n",
    "    gt_array = np.array(gt_int_pairs, dtype=np.int8)\n",
    "    rec.set_format('GT', gt_array)\n",
    "    out.write_record(rec)\n",
    "\n",
    "invcf.close()\n",
    "out.close()\n",
    "\n",
    "# 5. tabix\n",
    "os.system(f'tabix -fp vcf {out_vcf}')\n",
    "print(f'[INF] 缺失位点填充完成 → {out_vcf}')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
