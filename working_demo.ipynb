{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "928e399c",
   "metadata": {},
   "source": [
    "# EvoFill working demo\n",
    "\n",
    "ver 4. new imputation loss with evo loss\n",
    "\n",
    "last update: 2025/11/4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa78c2a2",
   "metadata": {},
   "source": [
    "## Content\n",
    "- [0. Dependency](#0.-Dependency)  \n",
    "- [1. Genotype(.vcf) encoding](#1.-Genotype(.vcf)-encoding)  \n",
    "- [2. Training a new model](#2.-Training-a-new-model)  \n",
    "  - [2.1 Dataloader](#2.1-Dataloader)  \n",
    "  - [2.2 Model initialization](#2.2-Model-initialization)  \n",
    "  - [2.3 stage 1: Chunk Module Training](#2.3-stage-1:-Chunk-Module-Training)  \n",
    "  - [2.4 stage 2: Ultra-Long-Range LD Module Training](#2.4-stage-2:-Ultra-Long-Range-LD-Module-Training)  \n",
    "- [3. Imputation using trained model](#3.-Imputation-using-trained-model)  \n",
    "  - [3.1 Load the trained model](#3.1-Load-the-trained-model)  \n",
    "  - [3.2 Encode .vcf file need be impute](#3.2-Encode-.vcf-file-need-be-impute)  \n",
    "  - [3.3 Inferring](#3.3-Inferring)  \n",
    "  - [3.4 Evaluating the imputation results](#3.4-Evaluating-the-imputation-results)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f454114",
   "metadata": {},
   "source": [
    "In jupyter notebook, we use single GPU here for demo.\n",
    "\n",
    "For parallel GPU training, please use other framework with `./train.py`, like `torch run --nproc_per_node=8 train.py` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9efe343c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed77817",
   "metadata": {},
   "source": [
    "## 0. Dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23548ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python ver:   3.10.19 | packaged by conda-forge | (main, Oct 13 2025, 14:08:27) [GCC 14.3.0]\n",
      "Pytorch ver:  2.8.0+cu129\n",
      "Mamba ver:    2.2.5\n",
      "GPU in use:   NVIDIA H100 PCIe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "import pandas as pd\n",
    "import torch\n",
    "import mamba_ssm\n",
    "from tqdm import tqdm\n",
    "from itertools import combinations\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam, AdamW, SparseAdam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print('Python ver:  ', sys.version)\n",
    "print('Pytorch ver: ', torch.__version__)\n",
    "print('Mamba ver:   ', mamba_ssm.__version__)\n",
    "print('GPU in use:  ', torch.cuda.get_device_name(torch.cuda.current_device()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca64e47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/qmtang/EvoFill/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4b1516",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import GenotypeEncoder, GenomicDataset, ImputationDataset\n",
    "from src.model import EvoFill\n",
    "from src.loss import ImputationLoss\n",
    "from src.utils import create_directories, set_seed, precompute_maf, metrics_by_maf, print_maf_stat_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7064af",
   "metadata": {},
   "source": [
    "## 1. Genotype(.vcf) encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33ef302",
   "metadata": {},
   "source": [
    "option 1. with extra evolutionary information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d332f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DATA] 总计 99,314 个位点  \n",
      "[DATA] 位点矩阵 = (2404, 99314)，稀疏度 = 28.10%\n",
      "[DATA] EvoMat shape: (2404, 2404)\n",
      "[DATA] 结果已写入 /mnt/qmtang/EvoFill/data/251105_ver4_chr22trim\n",
      "[DATA] 2,404 Samples\n",
      "[DATA] 99,314 Variants Sites\n",
      "[DATA] 4 seq_depth\n"
     ]
    }
   ],
   "source": [
    "work_dir = '/mnt/qmtang/EvoFill/data/251105_ver4_chr22trim'\n",
    "gt_enc = GenotypeEncoder(save_dir = work_dir, phased = True, gts012 = False)\n",
    "\n",
    "gt_enc = gt_enc.encode_new(vcf_path='/home/qmtang/GitHub/STICI-HPC/data/training_sets/ALL.chr22.training.samples.100k.any.type.0.01.maf.variants.vcf.gz',\n",
    "                  evo_mat=\"/mnt/qmtang/EvoFill/data/251104_ver3_chr22trim_ex/evo_mat.tsv\")\n",
    "\n",
    "print(f\"[DATA] {gt_enc.n_samples:,} Samples\")\n",
    "print(f\"[DATA] {gt_enc.n_variants:,} Variants Sites\")\n",
    "print(f\"[DATA] {gt_enc.seq_depth} seq_depth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2ece1d",
   "metadata": {},
   "source": [
    "option 2. vcf files only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804129d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "work_dir = '/mnt/qmtang/EvoFill/data/251105_ver4_chr22trim'\n",
    "gt_enc = GenotypeEncoder(save_dir = work_dir, phased = True, gts012 = False)\n",
    "\n",
    "gt_enc = gt_enc.encode_new(vcf_path='/home/qmtang/GitHub/STICI-HPC/data/training_sets/ALL.chr22.training.samples.100k.any.type.0.01.maf.variants.vcf.gz',\n",
    "                  evo_mat=None)\n",
    "\n",
    "print(f\"[DATA] {gt_enc.n_samples:,} Samples\")\n",
    "print(f\"[DATA] {gt_enc.n_variants:,} Variants Sites\")\n",
    "print(f\"[DATA] {gt_enc.seq_depth} seq_depth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6e5478",
   "metadata": {},
   "source": [
    "## 2. Training a new model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb250f1",
   "metadata": {},
   "source": [
    "Choose a path which including GenotypeEncoder processed files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84a55762",
   "metadata": {},
   "outputs": [],
   "source": [
    "work_dir = '/mnt/qmtang/EvoFill/data/251105_ver4_chr22trim'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebb7acb",
   "metadata": {},
   "source": [
    "### 2.1 Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4404ffa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Work Dir: /mnt/qmtang/EvoFill/data/251105_ver4_chr22trim\n",
      "Using device: cuda\n",
      "2,404 samples, 99,314 variants, 4 seq-depth.\n",
      "2,276 samples in train\n",
      "128 samples in val\n",
      "evo_mat: (2404, 2404)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Work Dir: {work_dir}\")\n",
    "create_directories(work_dir)\n",
    "\n",
    "val_n_samples = 128\n",
    "batch_size    = 16\n",
    "max_mr        = 0.7\n",
    "min_mr        = 0.3\n",
    "\n",
    "# Setup device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.empty_cache()\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "gt_enc = GenotypeEncoder.loadfromdisk(work_dir)\n",
    "print(f'{gt_enc.n_samples:,} samples, {gt_enc.n_variants:,} variants, {gt_enc.seq_depth} seq-depth.')\n",
    "\n",
    "x_train_indices, x_valid_indices = train_test_split(\n",
    "    range(gt_enc.n_samples),\n",
    "    test_size=val_n_samples,\n",
    "    random_state=3047,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "print(f\"{len(x_train_indices):,} samples in train\")\n",
    "print(f\"{len(x_valid_indices):,} samples in val\")\n",
    "print(f\"evo_mat: {gt_enc.evo_mat.shape}\")\n",
    "\n",
    "train_dataset = GenomicDataset(\n",
    "    gt_enc.X_gt,\n",
    "    evo_mat=gt_enc.evo_mat,\n",
    "    seq_depth=gt_enc.seq_depth,\n",
    "    mask=True,\n",
    "    masking_rates=(min_mr, max_mr),\n",
    "    indices=x_train_indices\n",
    ")\n",
    "\n",
    "val_dataset = GenomicDataset(\n",
    "    gt_enc.X_gt,\n",
    "    evo_mat=gt_enc.evo_mat,\n",
    "    seq_depth=gt_enc.seq_depth,\n",
    "    mask=True,\n",
    "    masking_rates=(min_mr, max_mr),\n",
    "    indices=x_valid_indices\n",
    ")\n",
    "\n",
    "def collate_fn(batch):\n",
    "    x_onehot = torch.stack([item[0] for item in batch])\n",
    "    y_onehot = torch.stack([item[1] for item in batch])\n",
    "    real_idx_list = [item[2] for item in batch]\n",
    "\n",
    "    # 提取 evo_mat 子矩阵\n",
    "    if train_dataset.evo_mat is not None:\n",
    "        evo_mat_batch = train_dataset.evo_mat[np.ix_(real_idx_list, real_idx_list)]\n",
    "        evo_mat_batch = torch.FloatTensor(evo_mat_batch)\n",
    "    else:\n",
    "        evo_mat_batch = torch.empty(0)\n",
    "\n",
    "    return x_onehot, y_onehot, evo_mat_batch\n",
    "    \n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2c3f8a",
   "metadata": {},
   "source": [
    "### 2.2 Model initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fd90485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model[hg19_chr22trim] would have 4 chunks.\n"
     ]
    }
   ],
   "source": [
    "model_name  = 'hg19_chr22trim'\n",
    "total_sites = gt_enc.n_variants\n",
    "alleles     = gt_enc.seq_depth\n",
    "chunk_size  = 32768\n",
    "overlap     = 1024\n",
    "d_model     = 64\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "model = EvoFill(d_model, alleles, total_sites, chunk_size, overlap).to(device)\n",
    "print(f\"model[{model_name}] would have {model.n_chunks} chunks.\")\n",
    "\n",
    "criterion = ImputationLoss(use_r2=True, use_evo=True, r2_weight=1, evo_weight=4, evo_lambda=10)\n",
    "# criterion = ImputationLoss(use_r2=True, use_evo=False)\n",
    "\n",
    "meta = {\n",
    "    \"model_name\": model_name,\n",
    "    \"total_sites\": total_sites,\n",
    "    \"alleles\": alleles,\n",
    "    \"chunk_size\": chunk_size,\n",
    "    \"overlap\": overlap,\n",
    "    \"d_model\": d_model\n",
    "}\n",
    "save_path = os.path.join(work_dir, \"model_meta.json\")\n",
    "with open(save_path, \"w\") as f:\n",
    "    json.dump(meta, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233acee1",
   "metadata": {},
   "source": [
    "### 2.3 stage 1: Chunk Module Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bba6dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose            = False\n",
    "max_epochs         = 100\n",
    "lr                 = 0.001\n",
    "weight_decay       = 1e-5\n",
    "earlystop_patience = 13\n",
    "\n",
    "model.global_out.set_ulr_enabled(False)\n",
    "\n",
    "for cid in range(model.n_chunks):\n",
    "    chunk_mask = model.chunk_masks[cid].cpu()\n",
    "    chunk_maf, chunk_bin_cnt = precompute_maf(gt_enc.X_gt[:,chunk_mask.bool().cpu().numpy()].toarray(),  mask_int=gt_enc.seq_depth)\n",
    "    chunk_maf = torch.from_numpy(chunk_maf).to(device)\n",
    "    if verbose:\n",
    "        print(f\"=== Chunk {cid + 1} STAT ===\")\n",
    "        maf_df = pd.DataFrame({\n",
    "            'MAF_bin': ['(0.00, 0.05)', '(0.05, 0.10)', '(0.10, 0.20)',\n",
    "                        '(0.20, 0.30)', '(0.30, 0.40)', '(0.40, 0.50)'],\n",
    "            'Counts':  [f\"{c}\" for c in chunk_bin_cnt],\n",
    "        })\n",
    "        print(maf_df.to_string(index=False))\n",
    "\n",
    "    # 2. 只给当前chunk专家+GlobalOut局部卷积上优化器\n",
    "    trainable = (list(model.chunk_embeds[cid].parameters()) +\n",
    "                list(model.chunk_modules[cid].parameters()) +\n",
    "                [model.global_out.w1, model.global_out.b1,\n",
    "                model.global_out.w2, model.global_out.b2])\n",
    "    # shared_params = [p for n, p in model.global_out.named_parameters()\n",
    "    #              if p.requires_grad and p.grad_fn is not None]\n",
    "\n",
    "    optimizer = AdamW(trainable, lr=lr, weight_decay=weight_decay)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, min_lr=1e-8)\n",
    "    best_loss = float('inf')\n",
    "    patience = earlystop_patience\n",
    "    patience_counter = 0\n",
    "    is_early_stopped = False\n",
    "    train_logs_sum = None\n",
    "    val_logs_sum   = None\n",
    "    for epoch in range(max_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_prob, train_gts, train_mask = [], [], []\n",
    "\n",
    "        train_pbar = tqdm(train_loader, desc=f'Chunk {cid + 1}/{model.n_chunks}, Epoch {epoch + 1}/{max_epochs}',) # leave=False\n",
    "        for batch_idx, (x, target, evo_mat) in enumerate(train_pbar):\n",
    "            x,  target = x.to(device), target.to(device)\n",
    "            if evo_mat.numel() == 0:\n",
    "                evo_mat = None\n",
    "            else:\n",
    "                evo_mat = evo_mat.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            logits, prob, mask_idx = model(x, cid)\n",
    "            loss, logs = criterion(logits[:, mask_idx], \n",
    "                                   prob[:, mask_idx], \n",
    "                                   target[:,mask_idx], \n",
    "                                   evo_mat) \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            if train_logs_sum is None:          # 第一次初始化\n",
    "                train_logs_sum = {k: 0.0 for k in logs}\n",
    "            for k, v in logs.items():\n",
    "                train_logs_sum[k] += v\n",
    "            # train_pbar.set_postfix({'loss': loss.item(), 'ce':logs['ce'], 'r2':logs['r2'], 'evo':logs['evo']})\n",
    "\n",
    "            # === 收集训练结果 ===\n",
    "            miss_mask = x[:, mask_idx][..., -1].bool()         # 只关心被 mask 的位点\n",
    "            train_prob.append(prob[:, mask_idx].detach())\n",
    "            train_gts.append(target[:,mask_idx].detach())\n",
    "            train_mask.append(miss_mask)\n",
    "\n",
    "        # 训练集 MAF-acc\n",
    "        train_prob = torch.cat(train_prob, dim=0)\n",
    "        train_gts  = torch.cat(train_gts,    dim=0)\n",
    "        train_mask = torch.cat(train_mask,   dim=0)\n",
    "\n",
    "        # ----------- 验证循环同理 ------------\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_prob, val_gts = [], []\n",
    "        if val_logs_sum is None:\n",
    "            val_logs_sum = {k: 0.0 for k in train_logs_sum}\n",
    "        with torch.no_grad():\n",
    "            for x, target, evo_mat in val_loader:\n",
    "                x,  target = x.to(device), target.to(device)\n",
    "                if evo_mat.numel() == 0:\n",
    "                    evo_mat = None\n",
    "                else:\n",
    "                    evo_mat = evo_mat.to(device)\n",
    "                logits, prob, mask_idx = model(x, cid)\n",
    "                loss, logs = criterion(logits[:, mask_idx], prob[:, mask_idx], target[:,mask_idx], evo_mat) \n",
    "                val_loss += loss.item()\n",
    "                for k, v in logs.items():\n",
    "                    val_logs_sum[k] += v\n",
    "                val_prob.append(prob[:, mask_idx].detach())\n",
    "                val_gts.append(target[:,mask_idx].detach())\n",
    "\n",
    "        val_prob = torch.cat(val_prob, dim=0)\n",
    "        val_gts    = torch.cat(val_gts,    dim=0)\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        avg_val_loss   = val_loss   / len(val_loader)\n",
    "        avg_train_logs = {k: v / len(train_loader) for k, v in train_logs_sum.items()}\n",
    "        avg_val_logs = {k: v / len(val_loader) for k, v in val_logs_sum.items()}\n",
    "\n",
    "        scheduler.step(avg_val_loss)\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "\n",
    "        log_str = (f'Chunk {cid + 1}/{model.n_chunks}, '\n",
    "            f'Epoch {epoch + 1}/{max_epochs}, '\n",
    "            f'Total Loss, Train = {avg_train_loss:.1f}, '\n",
    "            f'Val = {avg_val_loss:.1f}, '\n",
    "            f'LR: {current_lr:.2e}')\n",
    "        log_str += '\\n        Train'\n",
    "        for k, v in avg_train_logs.items():\n",
    "            log_str += f', {k}: {v:.1f}'\n",
    "        log_str += '\\n        Val  '\n",
    "        for k, v in avg_val_logs.items():\n",
    "            log_str += f', {k}: {v:.1f}'\n",
    "        print(log_str)\n",
    "\n",
    "        # 清空累加器，供下一个 epoch 使用\n",
    "        train_logs_sum = {k: 0.0 for k in train_logs_sum}\n",
    "        val_logs_sum   = {k: 0.0 for k in val_logs_sum}\n",
    "        \n",
    "        # Early stopping\n",
    "        if avg_val_loss < best_loss:\n",
    "            best_loss = avg_val_loss\n",
    "            patience_counter = 0\n",
    "            # 只存当前 chunk 专家 + 全局层\n",
    "            ckpt = {\n",
    "                'chunk_id': cid,\n",
    "                'chunk_embed_state': model.chunk_embeds[cid].state_dict(),\n",
    "                'chunk_module_state': model.chunk_modules[cid].state_dict(),\n",
    "                'global_out_state': model.global_out.state_dict(),\n",
    "                'best_val_loss': best_loss,\n",
    "            }\n",
    "            torch.save(ckpt, f'{work_dir}/models/{model_name}_chunk_{cid}.pth')\n",
    "            predres_with_bestloss = (train_prob, train_gts, val_prob, val_gts)\n",
    "            if verbose:\n",
    "                train_bins_metrics = metrics_by_maf(train_prob, train_gts, hap_map = gt_enc.hap_map, maf_vec = chunk_maf, mask=train_mask)\n",
    "                val_bins_metrics   = metrics_by_maf(val_prob,   val_gts, hap_map = gt_enc.hap_map, maf_vec = chunk_maf, mask=None)\n",
    "                print_maf_stat_df(chunk_bin_cnt,train_bins_metrics,val_bins_metrics)\n",
    "                print(f'  --> updated {model_name}_chunk_{cid}.pth')\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= earlystop_patience:\n",
    "                is_early_stopped = True\n",
    "                print(f'Chunk {cid + 1}/{model.n_chunks}, Early stopping triggered')\n",
    "                train_prob, train_gts, val_prob, val_gts = predres_with_bestloss\n",
    "                train_bins_metrics = metrics_by_maf(train_prob, train_gts, hap_map = gt_enc.hap_map, maf_vec = chunk_maf, mask=train_mask)\n",
    "                val_bins_metrics   = metrics_by_maf(val_prob,   val_gts, hap_map = gt_enc.hap_map, maf_vec = chunk_maf, mask=None)\n",
    "                print_maf_stat_df(chunk_bin_cnt,train_bins_metrics,val_bins_metrics)\n",
    "                break\n",
    "\n",
    "    if not is_early_stopped:\n",
    "        train_bins_metrics = metrics_by_maf(train_prob, train_gts, hap_map = gt_enc.hap_map, maf_vec = chunk_maf, mask=train_mask)\n",
    "        val_bins_metrics   = metrics_by_maf(val_prob,   val_gts, hap_map = gt_enc.hap_map, maf_vec = chunk_maf, mask=None)\n",
    "        print_maf_stat_df(chunk_bin_cnt,train_bins_metrics,val_bins_metrics)\n",
    "    del optimizer, scheduler\n",
    "    torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "\n",
    "# ---------------- 全部 chunk 训练完成 -> 保存完整模型 ----------------\n",
    "final_ckpt = {\n",
    "    'model_state': model.state_dict(),\n",
    "    'n_chunks': model.n_chunks,\n",
    "    'chunk_size': model.chunk_size,\n",
    "    'chunk_overlap': model.chunk_overlap,\n",
    "}\n",
    "torch.save(final_ckpt, f'{work_dir}/models/{model_name}_stage_1.pth')\n",
    "print(f'==> STAGE1 (Chunk Module) training finished: {work_dir}/models/{model_name}_stage1.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c31c2bd",
   "metadata": {},
   "source": [
    "### 2.4 stage 2: Ultra-Long-Range LD Module Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e507273",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs_per_pair = 100\n",
    "lr                 = 5e-4\n",
    "weight_decay       = 1e-5\n",
    "earlystop_patience = 15\n",
    "batch_size         = 8\n",
    "verbose            = True\n",
    "\n",
    "criterion = ImputationLoss(use_r2=True, use_evo=True, r2_weight=1, evo_weight=4, evo_lambda=10)\n",
    "\n",
    "# ----------- 逐个 chunk 加载权重-----------\n",
    "# for cid in range(model.n_chunks):\n",
    "#     chunk_file = f'{work_dir}/models/{model_name}_chunk_{cid}.pth'\n",
    "#     ckpt = torch.load(chunk_file, map_location='cpu')\n",
    "#     model.chunk_embeds[cid].load_state_dict(ckpt['chunk_embed_state'])\n",
    "#     model.chunk_modules[cid].load_state_dict(ckpt['chunk_module_state'])\n",
    "\n",
    "# ----------- 加载第一阶段完整权重-----------\n",
    "ckpt = torch.load(f'{work_dir}/models/{model_name}_stage_1.pth', map_location='cpu')\n",
    "model.load_state_dict(ckpt['model_state'])\n",
    "\n",
    "model.eval()        # chunk 专家冻结（requires_grad=False）\n",
    "model.global_out.set_ulr_enabled(True)  # 只开 ulr 分支\n",
    "\n",
    "# 分离优化器\n",
    "embed_weight = model.global_out.ulr_mamba.idx_embed.weight   # 已经 sparse=True\n",
    "optim_sparse = SparseAdam([embed_weight], lr=1e-4)\n",
    "\n",
    "# 2. 其余所有可训练参数（避开嵌入表）\n",
    "dense_params = [\n",
    "    p for n, p in model.global_out.named_parameters()\n",
    "    if p.requires_grad and 'idx_embed.weight' not in n\n",
    "]\n",
    "\n",
    "optim_dense = Adam(dense_params, lr=1e-4, weight_decay=1e-5, betas=(0.9, 0.999))\n",
    "\n",
    "scheduler_sparse = ReduceLROnPlateau(optim_sparse, mode='min', factor=0.5,\n",
    "                                     patience=5, min_lr=1e-9)\n",
    "scheduler_dense  = ReduceLROnPlateau(optim_dense,  mode='min', factor=0.5,\n",
    "                                     patience=5, min_lr=1e-9)\n",
    "\n",
    "pair_list = list(combinations(range(model.n_chunks), 2))\n",
    "np.random.shuffle(pair_list)          # 打乱\n",
    "total_pairs = len(pair_list)\n",
    "\n",
    "for pair_idx, (cid1, cid2) in enumerate(pair_list, 1):\n",
    "    # ====== 构造并集 mask ======\n",
    "    union_mask = (model.chunk_masks[cid1] + model.chunk_masks[cid2]).clamp(max=1).bool()\n",
    "    train_logs_sum = None\n",
    "    val_logs_sum   = None\n",
    "    \n",
    "    # 并集 MAF\n",
    "    union_maf, union_bin_cnt = precompute_maf(\n",
    "        gt_enc.X_gt[:, union_mask.cpu().numpy()].toarray(),\n",
    "        mask_int=gt_enc.seq_depth\n",
    "    )\n",
    "\n",
    "    # ====== 早停变量 ======\n",
    "    best_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    is_early_stopped = False\n",
    "\n",
    "    # ====== 训练循环 ======\n",
    "    for epoch in range(max_epochs_per_pair):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_prob, train_gts, train_mask = [], [], []\n",
    "\n",
    "        pbar = tqdm(train_loader,\n",
    "                    desc=f'Comb {pair_idx}/{total_pairs}  '\n",
    "                         f'{cid1+1}-{cid2+1}  Epoch {epoch+1}/{max_epochs_per_pair}',\n",
    "                    leave=False)\n",
    "        for x, target, evo_mat in pbar:\n",
    "            x,  target = x.to(device), target.to(device)\n",
    "            if evo_mat.numel() == 0:\n",
    "                evo_mat = None\n",
    "            else:\n",
    "                evo_mat = evo_mat.to(device)\n",
    "\n",
    "            optim_sparse.zero_grad()\n",
    "            optim_dense.zero_grad()\n",
    "\n",
    "            logits, prob, mask_idx = model(x, [cid1, cid2])\n",
    "            loss, logs = criterion(logits[:, mask_idx], prob[:, mask_idx], target[:,mask_idx], evo_mat) \n",
    "            loss.backward()\n",
    "\n",
    "            optim_sparse.step()   # 只更新嵌入表\n",
    "            optim_dense.step()    # 更新其余所有参数\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            if train_logs_sum is None:          # 第一次初始化\n",
    "                train_logs_sum = {k: 0.0 for k in logs}\n",
    "            for k, v in logs.items():\n",
    "                train_logs_sum[k] += v\n",
    "            # pbar.set_postfix({'loss': loss.item(), 'ce':logs['ce'], 'r2':logs['r2'], 'evo':logs['evo']})\n",
    "\n",
    "            # 收集指标\n",
    "            miss_mask = x[:,union_mask][..., -1].bool()\n",
    "            train_prob.append(prob[:, mask_idx].detach())\n",
    "            train_gts.append(target[:,mask_idx].detach())\n",
    "            train_mask.append(miss_mask)\n",
    "\n",
    "        # 训练集 MAF\n",
    "        train_prob = torch.cat(train_prob, dim=0)\n",
    "        train_gts  = torch.cat(train_gts,    dim=0)\n",
    "        train_mask = torch.cat(train_mask,   dim=0)\n",
    "\n",
    "        # ----------- 验证 -----------\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_prob, val_gts = [], []\n",
    "        with torch.no_grad():\n",
    "            if val_logs_sum is None:\n",
    "                val_logs_sum = {k: 0.0 for k in train_logs_sum}\n",
    "            for x, target, evo_mat in val_loader:\n",
    "                x = x.to(device)\n",
    "                target = target.to(device)\n",
    "                evo_mat = evo_mat.to(device) if evo_mat.numel() else None\n",
    "                logits, prob, mask_idx = model(x, [cid1, cid2])\n",
    "                loss, logs = criterion(logits[:, mask_idx], prob[:, mask_idx], target[:,mask_idx], evo_mat)\n",
    "                val_loss += loss.item()\n",
    "                for k, v in logs.items():\n",
    "                    val_logs_sum[k] += v\n",
    "                val_prob.append(prob[:,mask_idx])\n",
    "                val_gts.append(target[:,mask_idx])\n",
    "\n",
    "        val_prob = torch.cat(val_prob, dim=0)\n",
    "        val_gts  = torch.cat(val_gts,    dim=0)\n",
    "\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        avg_val_loss   = val_loss   / len(val_loader)\n",
    "        avg_train_logs = {k: v / len(train_loader) for k, v in train_logs_sum.items()}\n",
    "        avg_val_logs = {k: v / len(val_loader) for k, v in val_logs_sum.items()}\n",
    "        \n",
    "        scheduler_sparse.step(val_loss)\n",
    "        scheduler_dense.step(val_loss)\n",
    "\n",
    "        current_denselr = optim_dense.param_groups[0]['lr']\n",
    "        current_sparselr = optim_sparse.param_groups[0]['lr']\n",
    "\n",
    "        log_str = (f'Comb {pair_idx}/{total_pairs}  '\n",
    "            f'{cid1+1}-{cid2+1}  Epoch {epoch+1}/{max_epochs_per_pair} '\n",
    "            f'Total Loss, Train = {avg_train_loss:.1f}, '\n",
    "            f'Val = {avg_val_loss:.1f}, '\n",
    "            f'dense LR: {current_denselr:.2e}, '\n",
    "            f'sparse LR: {current_sparselr:.2e}')\n",
    "        log_str += '\\n        Train'\n",
    "        for k, v in avg_train_logs.items():\n",
    "            log_str += f', {k}: {v:.1f}'\n",
    "        log_str += '\\n        Val  '\n",
    "        for k, v in avg_val_logs.items():\n",
    "            log_str += f', {k}: {v:.1f}'\n",
    "        print(log_str)\n",
    "        # 清空累加器，供下一个 epoch 使用\n",
    "        train_logs_sum = {k: 0.0 for k in train_logs_sum}\n",
    "        val_logs_sum   = {k: 0.0 for k in val_logs_sum}\n",
    "        # 早停\n",
    "        if avg_val_loss < best_loss:\n",
    "            best_loss = avg_val_loss\n",
    "            patience_counter = 0\n",
    "            torch.save({\n",
    "                'comb': (cid1, cid2),\n",
    "                'global_out': model.global_out.state_dict(),\n",
    "                'best_val_loss': best_loss,\n",
    "                'epoch': epoch,\n",
    "            }, f'{work_dir}/models/{model_name}_chunk_{cid1}-{cid2}.pth')\n",
    "            # MAF 表格\n",
    "            predres_with_bestloss = (train_prob, train_gts, val_prob, val_gts)\n",
    "            if verbose:\n",
    "                train_bins_metrics = metrics_by_maf(train_prob, train_gts, gt_enc.hap_map, union_maf, mask=train_mask)\n",
    "                val_bins_metrics   = metrics_by_maf(val_prob,   val_gts, gt_enc.hap_map, union_maf, mask=None)\n",
    "                print_maf_stat_df(union_bin_cnt,train_bins_metrics,val_bins_metrics)\n",
    "                print(f'  --> updated {model_name}_chunk_{cid1+1}-{cid2+1}.pth')\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= earlystop_patience:\n",
    "                is_early_stopped = True\n",
    "                print(f'Pair {cid1+1}-{cid2+1} early stopping')\n",
    "                train_prob, train_gts, val_prob, val_gts = predres_with_bestloss\n",
    "                train_bins_metrics = metrics_by_maf(train_prob, train_gts, gt_enc.hap_map, union_maf, mask=train_mask)\n",
    "                val_bins_metrics   = metrics_by_maf(val_prob,   val_gts, gt_enc.hap_map, union_maf, mask=None)\n",
    "                print_maf_stat_df(union_bin_cnt,train_bins_metrics,val_bins_metrics)\n",
    "                break\n",
    "            \n",
    "    if not is_early_stopped:\n",
    "        predres_with_bestloss = (train_prob, train_gts, val_prob, val_gts)\n",
    "        train_bins_metrics = metrics_by_maf(train_prob, train_gts, gt_enc.hap_map, union_maf, mask=train_mask)\n",
    "        val_bins_metrics   = metrics_by_maf(val_prob,   val_gts, gt_enc.hap_map, union_maf, mask=None)\n",
    "        print_maf_stat_df(union_bin_cnt,train_bins_metrics,val_bins_metrics)\n",
    "\n",
    "    # del optimizer, scheduler\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# ----------- 全部 pair 结束 -> 保存最终模型 -----------\n",
    "torch.save({\n",
    "    'model_state': model.state_dict(),\n",
    "    'ulr_enabled': True,\n",
    "}, f'{work_dir}/models/{model_name}_stage2_final.pth')\n",
    "print(f'==> STAGE2 training finished: {work_dir}/models/{model_name}_stage2_final.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b718f797",
   "metadata": {},
   "source": [
    "## 3. Imputation using trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4034fdcb",
   "metadata": {},
   "source": [
    "### 3.1 Load the trained model\n",
    "\n",
    "Choose a path where including `<work_dir>/model` and have trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4c2e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "work_dir = '/mnt/qmtang/EvoFill/data/251105_ver4_chr22trim'\n",
    "\n",
    "# ---- 1. 加载模型 ----\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "gt_enc = GenotypeEncoder.loadfromdisk(work_dir)\n",
    "\n",
    "json_path = f\"{work_dir}/model_meta.json\"\n",
    "meta = json.load(open(json_path))\n",
    "model = EvoFill(\n",
    "    d_model=int(meta[\"d_model\"]),\n",
    "    alleles=int(meta[\"alleles\"]),\n",
    "    total_sites=int(meta[\"total_sites\"]),\n",
    "    chunk_size=int(meta[\"chunk_size\"]),\n",
    "    overlap=int(meta[\"overlap\"])\n",
    ").to(device)\n",
    "\n",
    "ckpt = torch.load(f'{work_dir}/models/{meta[\"model_name\"]}_stage2_final.pth', map_location=device)\n",
    "model.load_state_dict(ckpt['model_state'])\n",
    "model.eval()\n",
    "print(f'[INF] 模型加载完成，ULR-enabled={model.global_out.ulr_enabled}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5542df7b",
   "metadata": {},
   "source": [
    "### 3.2 Encode .vcf file need be impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e661be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DATA] 总计 99,314 个位点  \n",
      "[DATA] 位点矩阵 = (2404, 99314)，稀疏度 = 28.10%\n",
      "[DATA] EvoMat shape: (2404, 2404)\n",
      "[DATA] 结果已写入 /mnt/qmtang/EvoFill/data/251105_ver4_chr22trim_2/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<src.data.GenotypeEncoder at 0x712ec5c972b0>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_enc = GenotypeEncoder(save_dir = \"/mnt/qmtang/EvoFill/data/251105_ver4_chr22trim_2/\", phased = True, gts012 = False)\n",
    "gt_enc = gt_enc.encode_ref(ref_meta_json = \"/mnt/qmtang/EvoFill/data/251105_ver4_chr22trim/gt_enc_meta.json\",\n",
    "                  vcf_path='/home/qmtang/GitHub/STICI-HPC/data/training_sets/ALL.chr22.training.samples.100k.any.type.0.01.maf.variants.vcf.gz',\n",
    "                  evo_mat=\"/mnt/qmtang/EvoFill/data/251104_ver3_chr22trim_ex/evo_mat.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accab31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_enc = GenotypeEncoder.loadfromdisk(work_dir)\n",
    "print(f'{gt_enc.n_samples:,} samples, {gt_enc.n_variants:,} variants, {gt_enc.seq_depth} seq-depth.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87b3864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- 2. 构建推理 Dataset / Loader ----\n",
    "imp_dataset = ImputationDataset(\n",
    "    x_gts_sparse=gt_enc.X_gt,\n",
    "    seq_depth=gt_enc.seq_depth,\n",
    "    indices=None                 # 可传入指定样本索引\n",
    ")\n",
    "imp_dataset.print_missing_stat()          # 查看原始缺失比例\n",
    "\n",
    "def collate_fn(batch):\n",
    "    x_onehot = torch.stack([item[0] for item in batch])\n",
    "    real_idx_list = [item[1] for item in batch]\n",
    "    return x_onehot, real_idx_list   # 无 y\n",
    "\n",
    "imp_loader = torch.utils.data.DataLoader(\n",
    "    imp_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809730fd",
   "metadata": {},
   "source": [
    "### 3.3 Inferring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d5223c",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_list, col_list, data_list = [], [], []   # COO 三元组\n",
    "n_site = gt_enc.n_variants\n",
    "\n",
    "with torch.no_grad():\n",
    "    offset = 0                                  # 全局样本偏移\n",
    "    for x_onehot, real_idx in tqdm(imp_loader, desc='Imputing'):\n",
    "        x_onehot = x_onehot.to(device)\n",
    "        _, prob, _ = model(x_onehot)           # (B, L, 3)\n",
    "        prob = prob.cpu()\n",
    "\n",
    "        B, L, _ = prob.shape\n",
    "        # 1. 缺失位点：直接存预测概率\n",
    "        miss_mask = (x_onehot[..., -1] == 1)    # (B, L)\n",
    "        miss_idx  = miss_mask.nonzero(as_tuple=False)  # (N_missing, 2)\n",
    "        row_list.append(offset + miss_idx[:, 0].numpy())  # 全局行号\n",
    "        col_list.append(miss_idx[:, 1].numpy())           # 列号（site）\n",
    "        data_list.append(prob[miss_mask].numpy())         # (N_missing, 3)\n",
    "\n",
    "        # 2. 观测位点：构造 one-hot 概率\n",
    "        obs_mask = ~miss_mask\n",
    "        if obs_mask.any():\n",
    "            obs_idx = obs_mask.nonzero(as_tuple=False)    # (N_obs, 2)\n",
    "            gt_obs  = x_onehot[obs_mask].argmax(-1)       # 0/1/2\n",
    "            eye = torch.eye(3, dtype=torch.float32)\n",
    "            onehot_p = eye[gt_obs]                        # (N_obs, 3)\n",
    "            row_list.append(offset + obs_idx[:, 0].numpy())\n",
    "            col_list.append(obs_idx[:, 1].numpy())\n",
    "            data_list.append(onehot_p.numpy())\n",
    "\n",
    "        offset += B\n",
    "\n",
    "# ---- 4. 拼成整体稀疏矩阵 (B*L, 3) ----\n",
    "row = np.concatenate(row_list)\n",
    "col = np.concatenate(col_list)\n",
    "data = np.concatenate(data_list)        # 已经展平 (N, 3)\n",
    "prob_sp = sparse.csr_matrix(\n",
    "    (data.ravel(), np.repeat(row, 3), np.arange(0, len(data)*3+1, 3)),\n",
    "    shape=(offset * n_site, 3)\n",
    ")\n",
    "\n",
    "# ---- 5. 保存 ----\n",
    "out_dir  = os.path.join(work_dir, 'impute_out')\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "sparse.save_npz(os.path.join(out_dir, 'impute_prob_sparse.npz'), prob_sp)\n",
    "print(f'[INF] 稀疏概率矩阵已保存 → {out_dir}/impute_prob_sparse.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabda8b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe64dc76",
   "metadata": {},
   "source": [
    "### 3.4 Evaluating the imputation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523ad3bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
