{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81c4a14f",
   "metadata": {},
   "source": [
    "# EvoFill all-in-one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fef99aa",
   "metadata": {},
   "source": [
    "本Notebook打包了项目涉及的所有模块与函数，依赖环境: `/home/qmtang/miniconda3/envs/mamba`，可参考通过以下命令克隆：\n",
    "```bash\n",
    "conda create --name mamba --clone /home/qmtang/miniconda3/envs/mamba\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a83746",
   "metadata": {},
   "source": [
    "设置工作目录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6a27a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(r'/home/qmtang/mnt_qmtang/EvoFill') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0a35a2",
   "metadata": {},
   "source": [
    "## 1. Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31acbaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from types import SimpleNamespace\n",
    "def load_config(path: str) -> SimpleNamespace:\n",
    "    def hook(d):\n",
    "        return SimpleNamespace(**{k: hook(v) if isinstance(v, dict) else v\n",
    "                                  for k, v in d.items()})\n",
    "    with open(path) as f:\n",
    "        return json.load(f, object_hook=hook)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21b7ac0",
   "metadata": {},
   "source": [
    "注：在针对变异位点坐标的嵌入上，这里的处理方式和STICI原版稍有不同"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9eadcb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from cyvcf2 import VCF\n",
    "\n",
    "from src.utils import load_config\n",
    "\n",
    "\n",
    "def build_quaternion(chrom, pos, chrom_len_dict, chrom_start_dict, genome_len):\n",
    "    \"\"\"\n",
    "    返回 list[float32] 长度 4\n",
    "    \"\"\"\n",
    "    def _log4(x):\n",
    "        return math.log(x) / math.log(4)\n",
    "\n",
    "    chrom = str(chrom).strip('chr')\n",
    "    pos = int(pos)\n",
    "    c_len = chrom_len_dict[chrom]\n",
    "    c_start = chrom_start_dict[chrom]\n",
    "    abs_pos = c_start + pos\n",
    "    return [\n",
    "        _log4(pos),\n",
    "        _log4(c_len),\n",
    "        _log4(abs_pos),\n",
    "        _log4(genome_len),\n",
    "    ]\n",
    "\n",
    "\n",
    "def read_vcf(path: str, phased: bool, genome_json: str):\n",
    "    \"\"\"\n",
    "    返回\n",
    "        gts: np.ndarray (n_samples, n_snps)  int32\n",
    "        samples: list[str]\n",
    "        var_index: torch.Tensor (n_snps,)  int8\n",
    "        depth: int\n",
    "        pos_tensor: torch.Tensor (n_snps, 2)  str  // 染色体+坐标\n",
    "        quat_tensor: torch.Tensor (n_snps, 4)  float32\n",
    "    同时保存 var_index.pt\n",
    "    \"\"\"\n",
    "    # ---- 0. 读基因组元信息 ----\n",
    "    with open(genome_json) as f:\n",
    "        gmeta = json.load(f)\n",
    "    chrom_len = gmeta[\"chrom_len\"]        # dict[str, int]\n",
    "    chrom_start = gmeta[\"chrom_start\"]    # dict[str, int]\n",
    "    genome_len = gmeta[\"genome_len\"]      # int\n",
    "\n",
    "    vcf = VCF(path)\n",
    "    samples = list(vcf.samples)\n",
    "\n",
    "    gts_list = []\n",
    "    var_depth_list = []\n",
    "    quat_list = []\n",
    "\n",
    "    total = sum(1 for _ in VCF(path))\n",
    "    for var in tqdm(vcf, total=total, desc=\"Parsing VCF\"):\n",
    "        alleles = [var.REF] + var.ALT\n",
    "        allele2idx = {a: i for i, a in enumerate(alleles)}\n",
    "\n",
    "        row = []\n",
    "        for gt_str in var.gt_bases:\n",
    "            if gt_str in ['.|.', './.']:\n",
    "                row.append([-1,-1])\n",
    "            else:\n",
    "                sep = '|' if phased else '/'\n",
    "                for a in gt_str.split(sep):\n",
    "                    row.append(allele2idx[a])\n",
    "        row = np.array(row, dtype=np.int32)\n",
    "        gts_list.append(row)\n",
    "        \n",
    "        var_depth_list.append(int(len(alleles)))\n",
    "\n",
    "        # 变异位点位置坐标\n",
    "        quat = build_quaternion(var.CHROM, var.POS, chrom_len, chrom_start, genome_len)\n",
    "        quat_list.append(quat)\n",
    "\n",
    "    gts = np.vstack(gts_list).T.astype(np.int32)\n",
    "    flat = gts[gts >= 0]\n",
    "    global_depth = int(flat.max())\n",
    "\n",
    "    gts = torch.tensor(gts, dtype=torch.int8)\n",
    "    var_depth_index = torch.tensor(var_depth_list, dtype=torch.int8)\n",
    "    quat_tensor = torch.tensor(quat_list, dtype=torch.float32)\n",
    "\n",
    "    return gts, samples, var_depth_index, global_depth, quat_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90e02209",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = load_config(\"/home/qmtang/mnt_qmtang/EvoFill/config/config.json\")\n",
    "os.makedirs(cfg.data.path, exist_ok=True)\n",
    "\n",
    "phased = bool(cfg.data.tihp)\n",
    "genome_json = cfg.data.genome_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0e86aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##fileformat=VCFv4.2\n",
      "##source=tskit 0.6.4\n",
      "##FILTER=<ID=PASS,Description=\"All filters passed\">\n",
      "##contig=<ID=chr22,length=50818468>\n",
      "##FORMAT=<ID=GT,Number=1,Type=String,Description=\"Genotype\">\n",
      "#CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO\tFORMAT\ttsk_0\ttsk_1\ttsk_2\ttsk_3\ttsk_4\ttsk_5\ttsk_6\ttsk_7\ttsk_8\ttsk_9\ttsk_10\ttsk_11\ttsk_12\ttsk_13\ttsk_14\ttsk_15\ttsk_16\ttsk_17\ttsk_18\ttsk_19\ttsk_20\ttsk_21\ttsk_22\ttsk_23\ttsk_24\ttsk_25\ttsk_26\ttsk_27\ttsk_28\ttsk_29\ttsk_30\ttsk_31\ttsk_32\ttsk_33\ttsk_34\ttsk_35\ttsk_36\ttsk_37\ttsk_38\ttsk_39\ttsk_40\ttsk_41\ttsk_42\ttsk_43\ttsk_44\ttsk_45\ttsk_46\ttsk_47\ttsk_48\ttsk_49\ttsk_50\ttsk_51\ttsk_52\ttsk_53\ttsk_54\ttsk_55\ttsk_56\ttsk_57\ttsk_58\ttsk_59\ttsk_60\ttsk_61\ttsk_62\ttsk_63\ttsk_64\ttsk_65\ttsk_66\ttsk_67\ttsk_68\ttsk_69\ttsk_70\ttsk_71\ttsk_72\ttsk_73\ttsk_74\ttsk_75\ttsk_76\ttsk_77\ttsk_78\ttsk_79\ttsk_80\ttsk_81\ttsk_82\ttsk_83\ttsk_84\ttsk_85\ttsk_86\ttsk_87\ttsk_88\ttsk_89\ttsk_90\ttsk_91\ttsk_92\ttsk_93\ttsk_94\ttsk_95\ttsk_96\ttsk_97\ttsk_98\ttsk_99\ttsk_100\ttsk_101\ttsk_102\ttsk_103\ttsk_104\ttsk_105\ttsk_106\ttsk_107\ttsk_108\ttsk_109\ttsk_110\ttsk_111\ttsk_112\ttsk_113\ttsk_114\ttsk_115\ttsk_116\ttsk_117\ttsk_118\ttsk_119\ttsk_120\ttsk_121\ttsk_122\ttsk_123\ttsk_124\ttsk_125\ttsk_126\ttsk_127\ttsk_128\ttsk_129\ttsk_130\ttsk_131\ttsk_132\ttsk_133\ttsk_134\ttsk_135\ttsk_136\ttsk_137\ttsk_138\ttsk_139\ttsk_140\ttsk_141\ttsk_142\ttsk_143\ttsk_144\ttsk_145\ttsk_146\ttsk_147\ttsk_148\ttsk_149\ttsk_150\ttsk_151\ttsk_152\ttsk_153\ttsk_154\ttsk_155\ttsk_156\ttsk_157\ttsk_158\ttsk_159\ttsk_160\ttsk_161\ttsk_162\ttsk_163\ttsk_164\ttsk_165\ttsk_166\ttsk_167\ttsk_168\ttsk_169\ttsk_170\ttsk_171\ttsk_172\ttsk_173\ttsk_174\ttsk_175\ttsk_176\ttsk_177\ttsk_178\ttsk_179\ttsk_180\ttsk_181\ttsk_182\ttsk_183\ttsk_184\ttsk_185\ttsk_186\ttsk_187\ttsk_188\ttsk_189\ttsk_190\ttsk_191\ttsk_192\ttsk_193\ttsk_194\ttsk_195\ttsk_196\ttsk_197\ttsk_198\ttsk_199\ttsk_200\ttsk_201\ttsk_202\ttsk_203\ttsk_204\ttsk_205\ttsk_206\ttsk_207\ttsk_208\ttsk_209\ttsk_210\ttsk_211\ttsk_212\ttsk_213\ttsk_214\ttsk_215\ttsk_216\ttsk_217\ttsk_218\ttsk_219\ttsk_220\ttsk_221\ttsk_222\ttsk_223\ttsk_224\ttsk_225\ttsk_226\ttsk_227\ttsk_228\ttsk_229\ttsk_230\ttsk_231\ttsk_232\ttsk_233\ttsk_234\ttsk_235\ttsk_236\ttsk_237\ttsk_238\ttsk_239\ttsk_240\ttsk_241\ttsk_242\ttsk_243\ttsk_244\ttsk_245\ttsk_246\ttsk_247\ttsk_248\ttsk_249\ttsk_250\ttsk_251\ttsk_252\ttsk_253\ttsk_254\ttsk_255\ttsk_256\ttsk_257\ttsk_258\ttsk_259\ttsk_260\ttsk_261\ttsk_262\ttsk_263\ttsk_264\ttsk_265\ttsk_266\ttsk_267\ttsk_268\ttsk_269\ttsk_270\ttsk_271\ttsk_272\ttsk_273\ttsk_274\ttsk_275\ttsk_276\ttsk_277\ttsk_278\ttsk_279\ttsk_280\ttsk_281\ttsk_282\ttsk_283\ttsk_284\ttsk_285\ttsk_286\ttsk_287\ttsk_288\ttsk_289\ttsk_290\ttsk_291\ttsk_292\ttsk_293\ttsk_294\ttsk_295\ttsk_296\ttsk_297\ttsk_298\ttsk_299\ttsk_300\ttsk_301\ttsk_302\ttsk_303\ttsk_304\ttsk_305\ttsk_306\ttsk_307\ttsk_308\ttsk_309\ttsk_310\ttsk_311\ttsk_312\ttsk_313\ttsk_314\ttsk_315\ttsk_316\ttsk_317\ttsk_318\ttsk_319\ttsk_320\ttsk_321\ttsk_322\ttsk_323\ttsk_324\ttsk_325\ttsk_326\ttsk_327\ttsk_328\ttsk_329\ttsk_330\ttsk_331\ttsk_332\ttsk_333\ttsk_334\ttsk_335\ttsk_336\ttsk_337\ttsk_338\ttsk_339\ttsk_340\ttsk_341\ttsk_342\ttsk_343\ttsk_344\ttsk_345\ttsk_346\ttsk_347\ttsk_348\ttsk_349\ttsk_350\ttsk_351\ttsk_352\ttsk_353\ttsk_354\ttsk_355\ttsk_356\ttsk_357\ttsk_358\ttsk_359\ttsk_360\ttsk_361\ttsk_362\ttsk_363\ttsk_364\ttsk_365\ttsk_366\ttsk_367\ttsk_368\ttsk_369\ttsk_370\ttsk_371\ttsk_372\ttsk_373\ttsk_374\ttsk_375\ttsk_376\ttsk_377\ttsk_378\ttsk_379\ttsk_380\ttsk_381\ttsk_382\ttsk_383\ttsk_384\ttsk_385\ttsk_386\ttsk_387\ttsk_388\ttsk_389\ttsk_390\ttsk_391\ttsk_392\ttsk_393\ttsk_394\ttsk_395\ttsk_396\ttsk_397\ttsk_398\ttsk_399\ttsk_400\ttsk_401\ttsk_402\ttsk_403\ttsk_404\ttsk_405\ttsk_406\ttsk_407\ttsk_408\ttsk_409\ttsk_410\ttsk_411\ttsk_412\ttsk_413\ttsk_414\ttsk_415\ttsk_416\ttsk_417\ttsk_418\ttsk_419\ttsk_420\ttsk_421\ttsk_422\ttsk_423\ttsk_424\ttsk_425\ttsk_426\ttsk_427\ttsk_428\ttsk_429\ttsk_430\ttsk_431\ttsk_432\ttsk_433\ttsk_434\ttsk_435\ttsk_436\ttsk_437\ttsk_438\ttsk_439\ttsk_440\ttsk_441\ttsk_442\ttsk_443\ttsk_444\ttsk_445\ttsk_446\ttsk_447\ttsk_448\ttsk_449\ttsk_450\ttsk_451\ttsk_452\ttsk_453\ttsk_454\ttsk_455\ttsk_456\ttsk_457\ttsk_458\ttsk_459\ttsk_460\ttsk_461\ttsk_462\ttsk_463\ttsk_464\ttsk_465\ttsk_466\ttsk_467\ttsk_468\ttsk_469\ttsk_470\ttsk_471\ttsk_472\ttsk_473\ttsk_474\ttsk_475\ttsk_476\ttsk_477\ttsk_478\ttsk_479\ttsk_480\ttsk_481\ttsk_482\ttsk_483\ttsk_484\ttsk_485\ttsk_486\ttsk_487\ttsk_488\ttsk_489\ttsk_490\ttsk_491\ttsk_492\ttsk_493\ttsk_494\ttsk_495\ttsk_496\ttsk_497\ttsk_498\ttsk_499\ttsk_500\ttsk_501\ttsk_502\ttsk_503\ttsk_504\ttsk_505\ttsk_506\ttsk_507\ttsk_508\ttsk_509\ttsk_510\ttsk_511\ttsk_512\ttsk_513\ttsk_514\ttsk_515\ttsk_516\ttsk_517\ttsk_518\ttsk_519\ttsk_520\ttsk_521\ttsk_522\ttsk_523\ttsk_524\ttsk_525\ttsk_526\ttsk_527\ttsk_528\ttsk_529\ttsk_530\ttsk_531\ttsk_532\ttsk_533\ttsk_534\ttsk_535\ttsk_536\ttsk_537\ttsk_538\ttsk_539\ttsk_540\ttsk_541\ttsk_542\ttsk_543\ttsk_544\ttsk_545\ttsk_546\ttsk_547\ttsk_548\ttsk_549\ttsk_550\ttsk_551\ttsk_552\ttsk_553\ttsk_554\ttsk_555\ttsk_556\ttsk_557\ttsk_558\ttsk_559\ttsk_560\ttsk_561\ttsk_562\ttsk_563\ttsk_564\ttsk_565\ttsk_566\ttsk_567\ttsk_568\ttsk_569\ttsk_570\ttsk_571\ttsk_572\ttsk_573\ttsk_574\ttsk_575\ttsk_576\ttsk_577\ttsk_578\ttsk_579\ttsk_580\ttsk_581\ttsk_582\ttsk_583\ttsk_584\ttsk_585\ttsk_586\ttsk_587\ttsk_588\ttsk_589\ttsk_590\ttsk_591\ttsk_592\ttsk_593\ttsk_594\ttsk_595\ttsk_596\ttsk_597\ttsk_598\ttsk_599\ttsk_600\ttsk_601\ttsk_602\ttsk_603\ttsk_604\ttsk_605\ttsk_606\ttsk_607\ttsk_608\ttsk_609\ttsk_610\ttsk_611\ttsk_612\ttsk_613\ttsk_614\ttsk_615\ttsk_616\ttsk_617\ttsk_618\ttsk_619\ttsk_620\ttsk_621\ttsk_622\ttsk_623\ttsk_624\ttsk_625\ttsk_626\ttsk_627\ttsk_628\ttsk_629\ttsk_630\ttsk_631\ttsk_632\ttsk_633\ttsk_634\ttsk_635\ttsk_636\ttsk_637\ttsk_638\ttsk_639\ttsk_640\ttsk_641\ttsk_642\ttsk_643\ttsk_644\ttsk_645\ttsk_646\ttsk_647\ttsk_648\ttsk_649\ttsk_650\ttsk_651\ttsk_652\ttsk_653\ttsk_654\ttsk_655\ttsk_656\ttsk_657\ttsk_658\ttsk_659\ttsk_660\ttsk_661\ttsk_662\ttsk_663\ttsk_664\ttsk_665\ttsk_666\ttsk_667\ttsk_668\ttsk_669\ttsk_670\ttsk_671\ttsk_672\ttsk_673\ttsk_674\ttsk_675\ttsk_676\ttsk_677\ttsk_678\ttsk_679\ttsk_680\ttsk_681\ttsk_682\ttsk_683\ttsk_684\ttsk_685\ttsk_686\ttsk_687\ttsk_688\ttsk_689\ttsk_690\ttsk_691\ttsk_692\ttsk_693\ttsk_694\ttsk_695\ttsk_696\ttsk_697\ttsk_698\ttsk_699\ttsk_700\ttsk_701\ttsk_702\ttsk_703\ttsk_704\ttsk_705\ttsk_706\ttsk_707\ttsk_708\ttsk_709\ttsk_710\ttsk_711\ttsk_712\ttsk_713\ttsk_714\ttsk_715\ttsk_716\ttsk_717\ttsk_718\ttsk_719\ttsk_720\ttsk_721\ttsk_722\ttsk_723\ttsk_724\ttsk_725\ttsk_726\ttsk_727\ttsk_728\ttsk_729\ttsk_730\ttsk_731\ttsk_732\ttsk_733\ttsk_734\ttsk_735\ttsk_736\ttsk_737\ttsk_738\ttsk_739\ttsk_740\ttsk_741\ttsk_742\ttsk_743\ttsk_744\ttsk_745\ttsk_746\ttsk_747\ttsk_748\ttsk_749\ttsk_750\ttsk_751\ttsk_752\ttsk_753\ttsk_754\ttsk_755\ttsk_756\ttsk_757\ttsk_758\ttsk_759\ttsk_760\ttsk_761\ttsk_762\ttsk_763\ttsk_764\ttsk_765\ttsk_766\ttsk_767\ttsk_768\ttsk_769\ttsk_770\ttsk_771\ttsk_772\ttsk_773\ttsk_774\ttsk_775\ttsk_776\ttsk_777\ttsk_778\ttsk_779\ttsk_780\ttsk_781\ttsk_782\ttsk_783\ttsk_784\ttsk_785\ttsk_786\ttsk_787\ttsk_788\ttsk_789\ttsk_790\ttsk_791\ttsk_792\ttsk_793\ttsk_794\ttsk_795\ttsk_796\ttsk_797\ttsk_798\ttsk_799\ttsk_800\ttsk_801\ttsk_802\ttsk_803\ttsk_804\ttsk_805\ttsk_806\ttsk_807\ttsk_808\ttsk_809\ttsk_810\ttsk_811\ttsk_812\ttsk_813\ttsk_814\ttsk_815\ttsk_816\ttsk_817\ttsk_818\ttsk_819\ttsk_820\ttsk_821\ttsk_822\ttsk_823\ttsk_824\ttsk_825\ttsk_826\ttsk_827\ttsk_828\ttsk_829\ttsk_830\ttsk_831\ttsk_832\ttsk_833\ttsk_834\ttsk_835\ttsk_836\ttsk_837\ttsk_838\ttsk_839\ttsk_840\ttsk_841\ttsk_842\ttsk_843\ttsk_844\ttsk_845\ttsk_846\ttsk_847\ttsk_848\ttsk_849\ttsk_850\ttsk_851\ttsk_852\ttsk_853\ttsk_854\ttsk_855\ttsk_856\ttsk_857\ttsk_858\ttsk_859\ttsk_860\ttsk_861\ttsk_862\ttsk_863\ttsk_864\ttsk_865\ttsk_866\ttsk_867\ttsk_868\ttsk_869\ttsk_870\ttsk_871\ttsk_872\ttsk_873\ttsk_874\ttsk_875\ttsk_876\ttsk_877\ttsk_878\ttsk_879\ttsk_880\ttsk_881\ttsk_882\ttsk_883\ttsk_884\ttsk_885\ttsk_886\ttsk_887\ttsk_888\ttsk_889\ttsk_890\ttsk_891\ttsk_892\ttsk_893\ttsk_894\ttsk_895\ttsk_896\ttsk_897\ttsk_898\ttsk_899\ttsk_900\ttsk_901\ttsk_902\ttsk_903\ttsk_904\ttsk_905\ttsk_906\ttsk_907\ttsk_908\ttsk_909\ttsk_910\ttsk_911\ttsk_912\ttsk_913\ttsk_914\ttsk_915\ttsk_916\ttsk_917\ttsk_918\ttsk_919\ttsk_920\ttsk_921\ttsk_922\ttsk_923\ttsk_924\ttsk_925\ttsk_926\ttsk_927\ttsk_928\ttsk_929\ttsk_930\ttsk_931\ttsk_932\ttsk_933\ttsk_934\ttsk_935\ttsk_936\ttsk_937\ttsk_938\ttsk_939\ttsk_940\ttsk_941\ttsk_942\ttsk_943\ttsk_944\ttsk_945\ttsk_946\ttsk_947\ttsk_948\ttsk_949\ttsk_950\ttsk_951\ttsk_952\ttsk_953\ttsk_954\ttsk_955\ttsk_956\ttsk_957\ttsk_958\ttsk_959\ttsk_960\ttsk_961\ttsk_962\ttsk_963\ttsk_964\ttsk_965\ttsk_966\ttsk_967\ttsk_968\ttsk_969\ttsk_970\ttsk_971\ttsk_972\ttsk_973\ttsk_974\ttsk_975\ttsk_976\ttsk_977\ttsk_978\ttsk_979\ttsk_980\ttsk_981\ttsk_982\ttsk_983\ttsk_984\ttsk_985\ttsk_986\ttsk_987\ttsk_988\ttsk_989\ttsk_990\ttsk_991\ttsk_992\ttsk_993\ttsk_994\ttsk_995\ttsk_996\ttsk_997\ttsk_998\ttsk_999\ttsk_1000\ttsk_1001\ttsk_1002\ttsk_1003\ttsk_1004\ttsk_1005\ttsk_1006\ttsk_1007\ttsk_1008\ttsk_1009\ttsk_1010\ttsk_1011\ttsk_1012\ttsk_1013\ttsk_1014\ttsk_1015\ttsk_1016\ttsk_1017\ttsk_1018\ttsk_1019\ttsk_1020\ttsk_1021\ttsk_1022\ttsk_1023\ttsk_1024\ttsk_1025\ttsk_1026\ttsk_1027\ttsk_1028\ttsk_1029\ttsk_1030\ttsk_1031\ttsk_1032\ttsk_1033\ttsk_1034\ttsk_1035\ttsk_1036\ttsk_1037\ttsk_1038\ttsk_1039\ttsk_1040\ttsk_1041\ttsk_1042\ttsk_1043\ttsk_1044\ttsk_1045\ttsk_1046\ttsk_1047\ttsk_1048\ttsk_1049\ttsk_1050\ttsk_1051\ttsk_1052\ttsk_1053\ttsk_1054\ttsk_1055\ttsk_1056\ttsk_1057\ttsk_1058\ttsk_1059\ttsk_1060\ttsk_1061\ttsk_1062\ttsk_1063\ttsk_1064\ttsk_1065\ttsk_1066\ttsk_1067\ttsk_1068\ttsk_1069\ttsk_1070\ttsk_1071\ttsk_1072\ttsk_1073\ttsk_1074\ttsk_1075\ttsk_1076\ttsk_1077\ttsk_1078\ttsk_1079\ttsk_1080\ttsk_1081\ttsk_1082\ttsk_1083\ttsk_1084\ttsk_1085\ttsk_1086\ttsk_1087\ttsk_1088\ttsk_1089\ttsk_1090\ttsk_1091\ttsk_1092\ttsk_1093\ttsk_1094\ttsk_1095\ttsk_1096\ttsk_1097\ttsk_1098\ttsk_1099\ttsk_1100\ttsk_1101\ttsk_1102\ttsk_1103\ttsk_1104\ttsk_1105\ttsk_1106\ttsk_1107\ttsk_1108\ttsk_1109\ttsk_1110\ttsk_1111\ttsk_1112\ttsk_1113\ttsk_1114\ttsk_1115\ttsk_1116\ttsk_1117\ttsk_1118\ttsk_1119\ttsk_1120\ttsk_1121\ttsk_1122\ttsk_1123\ttsk_1124\ttsk_1125\ttsk_1126\ttsk_1127\ttsk_1128\ttsk_1129\ttsk_1130\ttsk_1131\ttsk_1132\ttsk_1133\ttsk_1134\ttsk_1135\ttsk_1136\ttsk_1137\ttsk_1138\ttsk_1139\ttsk_1140\ttsk_1141\ttsk_1142\ttsk_1143\ttsk_1144\ttsk_1145\ttsk_1146\ttsk_1147\ttsk_1148\ttsk_1149\ttsk_1150\ttsk_1151\ttsk_1152\ttsk_1153\ttsk_1154\ttsk_1155\ttsk_1156\ttsk_1157\ttsk_1158\ttsk_1159\ttsk_1160\ttsk_1161\ttsk_1162\ttsk_1163\ttsk_1164\ttsk_1165\ttsk_1166\ttsk_1167\ttsk_1168\ttsk_1169\ttsk_1170\ttsk_1171\ttsk_1172\ttsk_1173\ttsk_1174\ttsk_1175\ttsk_1176\ttsk_1177\ttsk_1178\ttsk_1179\ttsk_1180\ttsk_1181\ttsk_1182\ttsk_1183\ttsk_1184\ttsk_1185\ttsk_1186\ttsk_1187\ttsk_1188\ttsk_1189\ttsk_1190\ttsk_1191\ttsk_1192\ttsk_1193\ttsk_1194\ttsk_1195\ttsk_1196\ttsk_1197\ttsk_1198\ttsk_1199\ttsk_1200\ttsk_1201\ttsk_1202\ttsk_1203\ttsk_1204\ttsk_1205\ttsk_1206\ttsk_1207\ttsk_1208\ttsk_1209\ttsk_1210\ttsk_1211\ttsk_1212\ttsk_1213\ttsk_1214\ttsk_1215\ttsk_1216\ttsk_1217\ttsk_1218\ttsk_1219\ttsk_1220\ttsk_1221\ttsk_1222\ttsk_1223\ttsk_1224\ttsk_1225\ttsk_1226\ttsk_1227\ttsk_1228\ttsk_1229\ttsk_1230\ttsk_1231\ttsk_1232\ttsk_1233\ttsk_1234\ttsk_1235\ttsk_1236\ttsk_1237\ttsk_1238\ttsk_1239\ttsk_1240\ttsk_1241\ttsk_1242\ttsk_1243\ttsk_1244\ttsk_1245\ttsk_1246\ttsk_1247\ttsk_1248\ttsk_1249\ttsk_1250\ttsk_1251\ttsk_1252\ttsk_1253\ttsk_1254\ttsk_1255\ttsk_1256\ttsk_1257\ttsk_1258\ttsk_1259\ttsk_1260\ttsk_1261\ttsk_1262\ttsk_1263\ttsk_1264\ttsk_1265\ttsk_1266\ttsk_1267\ttsk_1268\ttsk_1269\ttsk_1270\ttsk_1271\ttsk_1272\ttsk_1273\ttsk_1274\ttsk_1275\ttsk_1276\ttsk_1277\ttsk_1278\ttsk_1279\ttsk_1280\ttsk_1281\ttsk_1282\ttsk_1283\ttsk_1284\ttsk_1285\ttsk_1286\ttsk_1287\ttsk_1288\ttsk_1289\ttsk_1290\ttsk_1291\ttsk_1292\ttsk_1293\ttsk_1294\ttsk_1295\ttsk_1296\ttsk_1297\ttsk_1298\ttsk_1299\ttsk_1300\ttsk_1301\ttsk_1302\ttsk_1303\ttsk_1304\ttsk_1305\ttsk_1306\ttsk_1307\ttsk_1308\ttsk_1309\ttsk_1310\ttsk_1311\ttsk_1312\ttsk_1313\ttsk_1314\ttsk_1315\ttsk_1316\ttsk_1317\ttsk_1318\ttsk_1319\ttsk_1320\ttsk_1321\ttsk_1322\ttsk_1323\ttsk_1324\ttsk_1325\ttsk_1326\ttsk_1327\ttsk_1328\ttsk_1329\ttsk_1330\ttsk_1331\ttsk_1332\ttsk_1333\ttsk_1334\ttsk_1335\ttsk_1336\ttsk_1337\ttsk_1338\ttsk_1339\ttsk_1340\ttsk_1341\ttsk_1342\ttsk_1343\ttsk_1344\ttsk_1345\ttsk_1346\ttsk_1347\ttsk_1348\ttsk_1349\ttsk_1350\ttsk_1351\ttsk_1352\ttsk_1353\ttsk_1354\ttsk_1355\ttsk_1356\ttsk_1357\ttsk_1358\ttsk_1359\ttsk_1360\ttsk_1361\ttsk_1362\ttsk_1363\ttsk_1364\ttsk_1365\ttsk_1366\ttsk_1367\ttsk_1368\ttsk_1369\ttsk_1370\ttsk_1371\ttsk_1372\ttsk_1373\ttsk_1374\ttsk_1375\ttsk_1376\ttsk_1377\ttsk_1378\ttsk_1379\ttsk_1380\ttsk_1381\ttsk_1382\ttsk_1383\ttsk_1384\ttsk_1385\ttsk_1386\ttsk_1387\ttsk_1388\ttsk_1389\ttsk_1390\ttsk_1391\ttsk_1392\ttsk_1393\ttsk_1394\ttsk_1395\ttsk_1396\ttsk_1397\ttsk_1398\ttsk_1399\ttsk_1400\ttsk_1401\ttsk_1402\ttsk_1403\ttsk_1404\ttsk_1405\ttsk_1406\ttsk_1407\ttsk_1408\ttsk_1409\ttsk_1410\ttsk_1411\ttsk_1412\ttsk_1413\ttsk_1414\ttsk_1415\ttsk_1416\ttsk_1417\ttsk_1418\ttsk_1419\ttsk_1420\ttsk_1421\ttsk_1422\ttsk_1423\ttsk_1424\ttsk_1425\ttsk_1426\ttsk_1427\ttsk_1428\ttsk_1429\ttsk_1430\ttsk_1431\ttsk_1432\ttsk_1433\ttsk_1434\ttsk_1435\ttsk_1436\ttsk_1437\ttsk_1438\ttsk_1439\ttsk_1440\ttsk_1441\ttsk_1442\ttsk_1443\ttsk_1444\ttsk_1445\ttsk_1446\ttsk_1447\ttsk_1448\ttsk_1449\ttsk_1450\ttsk_1451\ttsk_1452\ttsk_1453\ttsk_1454\ttsk_1455\ttsk_1456\ttsk_1457\ttsk_1458\ttsk_1459\ttsk_1460\ttsk_1461\ttsk_1462\ttsk_1463\ttsk_1464\ttsk_1465\ttsk_1466\ttsk_1467\ttsk_1468\ttsk_1469\ttsk_1470\ttsk_1471\ttsk_1472\ttsk_1473\ttsk_1474\ttsk_1475\ttsk_1476\ttsk_1477\ttsk_1478\ttsk_1479\ttsk_1480\ttsk_1481\ttsk_1482\ttsk_1483\ttsk_1484\ttsk_1485\ttsk_1486\ttsk_1487\ttsk_1488\ttsk_1489\ttsk_1490\ttsk_1491\ttsk_1492\ttsk_1493\ttsk_1494\ttsk_1495\ttsk_1496\ttsk_1497\ttsk_1498\ttsk_1499\ttsk_1500\ttsk_1501\ttsk_1502\ttsk_1503\ttsk_1504\ttsk_1505\ttsk_1506\ttsk_1507\ttsk_1508\ttsk_1509\ttsk_1510\ttsk_1511\ttsk_1512\ttsk_1513\ttsk_1514\ttsk_1515\ttsk_1516\ttsk_1517\ttsk_1518\ttsk_1519\ttsk_1520\ttsk_1521\ttsk_1522\ttsk_1523\ttsk_1524\ttsk_1525\ttsk_1526\ttsk_1527\ttsk_1528\ttsk_1529\ttsk_1530\ttsk_1531\ttsk_1532\ttsk_1533\ttsk_1534\ttsk_1535\ttsk_1536\ttsk_1537\ttsk_1538\ttsk_1539\ttsk_1540\ttsk_1541\ttsk_1542\ttsk_1543\ttsk_1544\ttsk_1545\ttsk_1546\ttsk_1547\ttsk_1548\ttsk_1549\ttsk_1550\ttsk_1551\ttsk_1552\ttsk_1553\ttsk_1554\ttsk_1555\ttsk_1556\ttsk_1557\ttsk_1558\ttsk_1559\ttsk_1560\ttsk_1561\ttsk_1562\ttsk_1563\ttsk_1564\ttsk_1565\ttsk_1566\ttsk_1567\ttsk_1568\ttsk_1569\ttsk_1570\ttsk_1571\ttsk_1572\ttsk_1573\ttsk_1574\ttsk_1575\ttsk_1576\ttsk_1577\ttsk_1578\ttsk_1579\ttsk_1580\ttsk_1581\ttsk_1582\ttsk_1583\ttsk_1584\ttsk_1585\ttsk_1586\ttsk_1587\ttsk_1588\ttsk_1589\ttsk_1590\ttsk_1591\ttsk_1592\ttsk_1593\ttsk_1594\ttsk_1595\ttsk_1596\ttsk_1597\ttsk_1598\ttsk_1599\ttsk_1600\ttsk_1601\ttsk_1602\ttsk_1603\ttsk_1604\ttsk_1605\ttsk_1606\ttsk_1607\ttsk_1608\ttsk_1609\ttsk_1610\ttsk_1611\ttsk_1612\ttsk_1613\ttsk_1614\ttsk_1615\ttsk_1616\ttsk_1617\ttsk_1618\ttsk_1619\ttsk_1620\ttsk_1621\ttsk_1622\ttsk_1623\ttsk_1624\ttsk_1625\ttsk_1626\ttsk_1627\ttsk_1628\ttsk_1629\ttsk_1630\ttsk_1631\ttsk_1632\ttsk_1633\ttsk_1634\ttsk_1635\ttsk_1636\ttsk_1637\ttsk_1638\ttsk_1639\ttsk_1640\ttsk_1641\ttsk_1642\ttsk_1643\ttsk_1644\ttsk_1645\ttsk_1646\ttsk_1647\ttsk_1648\ttsk_1649\ttsk_1650\ttsk_1651\ttsk_1652\ttsk_1653\ttsk_1654\ttsk_1655\ttsk_1656\ttsk_1657\ttsk_1658\ttsk_1659\ttsk_1660\ttsk_1661\ttsk_1662\ttsk_1663\ttsk_1664\ttsk_1665\ttsk_1666\ttsk_1667\ttsk_1668\ttsk_1669\ttsk_1670\ttsk_1671\ttsk_1672\ttsk_1673\ttsk_1674\ttsk_1675\ttsk_1676\ttsk_1677\ttsk_1678\ttsk_1679\ttsk_1680\ttsk_1681\ttsk_1682\ttsk_1683\ttsk_1684\ttsk_1685\ttsk_1686\ttsk_1687\ttsk_1688\ttsk_1689\ttsk_1690\ttsk_1691\ttsk_1692\ttsk_1693\ttsk_1694\ttsk_1695\ttsk_1696\ttsk_1697\ttsk_1698\ttsk_1699\ttsk_1700\ttsk_1701\ttsk_1702\ttsk_1703\ttsk_1704\ttsk_1705\ttsk_1706\ttsk_1707\ttsk_1708\ttsk_1709\ttsk_1710\ttsk_1711\ttsk_1712\ttsk_1713\ttsk_1714\ttsk_1715\ttsk_1716\ttsk_1717\ttsk_1718\ttsk_1719\ttsk_1720\ttsk_1721\ttsk_1722\ttsk_1723\ttsk_1724\ttsk_1725\ttsk_1726\ttsk_1727\ttsk_1728\ttsk_1729\ttsk_1730\ttsk_1731\ttsk_1732\ttsk_1733\ttsk_1734\ttsk_1735\ttsk_1736\ttsk_1737\ttsk_1738\ttsk_1739\ttsk_1740\ttsk_1741\ttsk_1742\ttsk_1743\ttsk_1744\ttsk_1745\ttsk_1746\ttsk_1747\ttsk_1748\ttsk_1749\ttsk_1750\ttsk_1751\ttsk_1752\ttsk_1753\ttsk_1754\ttsk_1755\ttsk_1756\ttsk_1757\ttsk_1758\ttsk_1759\ttsk_1760\ttsk_1761\ttsk_1762\ttsk_1763\ttsk_1764\ttsk_1765\ttsk_1766\ttsk_1767\ttsk_1768\ttsk_1769\ttsk_1770\ttsk_1771\ttsk_1772\ttsk_1773\ttsk_1774\ttsk_1775\ttsk_1776\ttsk_1777\ttsk_1778\ttsk_1779\ttsk_1780\ttsk_1781\ttsk_1782\ttsk_1783\ttsk_1784\ttsk_1785\ttsk_1786\ttsk_1787\ttsk_1788\ttsk_1789\ttsk_1790\ttsk_1791\ttsk_1792\ttsk_1793\ttsk_1794\ttsk_1795\ttsk_1796\ttsk_1797\ttsk_1798\ttsk_1799\ttsk_1800\ttsk_1801\ttsk_1802\ttsk_1803\ttsk_1804\ttsk_1805\ttsk_1806\ttsk_1807\ttsk_1808\ttsk_1809\ttsk_1810\ttsk_1811\ttsk_1812\ttsk_1813\ttsk_1814\ttsk_1815\ttsk_1816\ttsk_1817\ttsk_1818\ttsk_1819\ttsk_1820\ttsk_1821\ttsk_1822\ttsk_1823\ttsk_1824\ttsk_1825\ttsk_1826\ttsk_1827\ttsk_1828\ttsk_1829\ttsk_1830\ttsk_1831\ttsk_1832\ttsk_1833\ttsk_1834\ttsk_1835\ttsk_1836\ttsk_1837\ttsk_1838\ttsk_1839\ttsk_1840\ttsk_1841\ttsk_1842\ttsk_1843\ttsk_1844\ttsk_1845\ttsk_1846\ttsk_1847\ttsk_1848\ttsk_1849\ttsk_1850\ttsk_1851\ttsk_1852\ttsk_1853\ttsk_1854\ttsk_1855\ttsk_1856\ttsk_1857\ttsk_1858\ttsk_1859\ttsk_1860\ttsk_1861\ttsk_1862\ttsk_1863\ttsk_1864\ttsk_1865\ttsk_1866\ttsk_1867\ttsk_1868\ttsk_1869\ttsk_1870\ttsk_1871\ttsk_1872\ttsk_1873\ttsk_1874\ttsk_1875\ttsk_1876\ttsk_1877\ttsk_1878\ttsk_1879\ttsk_1880\ttsk_1881\ttsk_1882\ttsk_1883\ttsk_1884\ttsk_1885\ttsk_1886\ttsk_1887\ttsk_1888\ttsk_1889\ttsk_1890\ttsk_1891\ttsk_1892\ttsk_1893\ttsk_1894\ttsk_1895\ttsk_1896\ttsk_1897\ttsk_1898\ttsk_1899\ttsk_1900\ttsk_1901\ttsk_1902\ttsk_1903\ttsk_1904\ttsk_1905\ttsk_1906\ttsk_1907\ttsk_1908\ttsk_1909\ttsk_1910\ttsk_1911\ttsk_1912\ttsk_1913\ttsk_1914\ttsk_1915\ttsk_1916\ttsk_1917\ttsk_1918\ttsk_1919\ttsk_1920\ttsk_1921\ttsk_1922\ttsk_1923\ttsk_1924\ttsk_1925\ttsk_1926\ttsk_1927\ttsk_1928\ttsk_1929\ttsk_1930\ttsk_1931\ttsk_1932\ttsk_1933\ttsk_1934\ttsk_1935\ttsk_1936\ttsk_1937\ttsk_1938\ttsk_1939\ttsk_1940\ttsk_1941\ttsk_1942\ttsk_1943\ttsk_1944\ttsk_1945\ttsk_1946\ttsk_1947\ttsk_1948\ttsk_1949\ttsk_1950\ttsk_1951\ttsk_1952\ttsk_1953\ttsk_1954\ttsk_1955\ttsk_1956\ttsk_1957\ttsk_1958\ttsk_1959\ttsk_1960\ttsk_1961\ttsk_1962\ttsk_1963\ttsk_1964\ttsk_1965\ttsk_1966\ttsk_1967\ttsk_1968\ttsk_1969\ttsk_1970\ttsk_1971\ttsk_1972\ttsk_1973\ttsk_1974\ttsk_1975\ttsk_1976\ttsk_1977\ttsk_1978\ttsk_1979\ttsk_1980\ttsk_1981\ttsk_1982\ttsk_1983\ttsk_1984\ttsk_1985\ttsk_1986\ttsk_1987\ttsk_1988\ttsk_1989\ttsk_1990\ttsk_1991\ttsk_1992\ttsk_1993\ttsk_1994\ttsk_1995\ttsk_1996\ttsk_1997\ttsk_1998\ttsk_1999\n",
      "chr22\t40\t0\tT\tC\t.\tPASS\t.\tGT\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\n",
      "chr22\t170\t1\tT\tG\t.\tPASS\t.\tGT\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\n",
      "chr22\t290\t2\tG\tT\t.\tPASS\t.\tGT\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|1\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|1\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t1|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t1|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t1|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|1\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|1\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|1\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t1|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t1|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t1|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\n",
      "chr22\t322\t3\tG\tA\t.\tPASS\t.\tGT\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\t0|0\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "filename = cfg.data.train_vcf\n",
    "opener = gzip.open if filename.endswith('.gz') else open\n",
    "\n",
    "n_lines = 10\n",
    "with opener(filename, 'rt') as f:\n",
    "    lines = 0\n",
    "    for line in f:\n",
    "        print(line.rstrip('\\n'))\n",
    "        lines += 1\n",
    "        if lines >= n_lines:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c212038e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing VCF:   3%|▎         | 1926/56145 [00:02<01:09, 775.65it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n",
      "\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# ---------- 训练集 ----------\u001b[39;00m\n",
      "\u001b[0;32m----> 2\u001b[0m train_gts, train_samples, var_depth_index, global_depth, quat_train \u001b[38;5;241m=\u001b[39m \u001b[43mread_vcf\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_vcf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mphased\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenome_json\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInferred unified depth = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mglobal_depth\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;32m      6\u001b[0m torch\u001b[38;5;241m.\u001b[39msave({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgts\u001b[39m\u001b[38;5;124m'\u001b[39m: train_gts, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoords\u001b[39m\u001b[38;5;124m'\u001b[39m:quat_train, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvar_depths\u001b[39m\u001b[38;5;124m'\u001b[39m:var_depth_index},\n",
      "\u001b[1;32m      7\u001b[0m             os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(cfg\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mpath, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\n",
      "Cell \u001b[0;32mIn[2], line 60\u001b[0m, in \u001b[0;36mread_vcf\u001b[0;34m(path, phased, genome_json)\u001b[0m\n",
      "\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m tqdm(vcf, total\u001b[38;5;241m=\u001b[39mtotal, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParsing VCF\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[1;32m     59\u001b[0m     alleles \u001b[38;5;241m=\u001b[39m [var\u001b[38;5;241m.\u001b[39mREF] \u001b[38;5;241m+\u001b[39m var\u001b[38;5;241m.\u001b[39mALT\n",
      "\u001b[0;32m---> 60\u001b[0m     allele2idx \u001b[38;5;241m=\u001b[39m {a: i \u001b[38;5;28;01mfor\u001b[39;00m i, a \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43malleles\u001b[49m\u001b[43m)\u001b[49m}\n",
      "\u001b[1;32m     62\u001b[0m     row \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m gt_str \u001b[38;5;129;01min\u001b[39;00m var\u001b[38;5;241m.\u001b[39mgt_bases:\n",
      "\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ---------- 训练集 ----------\n",
    "train_gts, train_samples, var_depth_index, global_depth, quat_train = read_vcf(\n",
    "    cfg.data.train_vcf, phased, genome_json)\n",
    "print(f\"Inferred unified depth = {global_depth}\")\n",
    "\n",
    "torch.save({'gts': train_gts, 'coords':quat_train, 'var_depths':var_depth_index},\n",
    "            os.path.join(cfg.data.path, \"train.pt\"))\n",
    "\n",
    "print(f\"Saved train.pt | gts={tuple(train_gts.shape)} | coords={tuple(quat_train.shape)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d2c31e",
   "metadata": {},
   "source": [
    "train_gts 张量形状 = (样本，变异位点)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad479047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], dtype=torch.int8)\n"
     ]
    }
   ],
   "source": [
    "print(train_gts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee2a237",
   "metadata": {},
   "source": [
    "quat_train 张量形状 = (样本，4)\n",
    "\n",
    "变异位点4维坐标 = 位点所在染色体上的位置，位点所在染色体长度，位点在全基因组上的位置，全基因组长度\n",
    "\n",
    "记录值为原碱基数取log4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b5b3e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.6610, 12.7994, 15.6976, 15.7621],\n",
      "        [ 3.7047, 12.7994, 15.6976, 15.7621],\n",
      "        [ 4.0900, 12.7994, 15.6976, 15.7621],\n",
      "        ...,\n",
      "        [11.1267, 12.7994, 15.6989, 15.7621],\n",
      "        [11.1267, 12.7994, 15.6989, 15.7621],\n",
      "        [11.1267, 12.7994, 15.6989, 15.7621]])\n"
     ]
    }
   ],
   "source": [
    "print(quat_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24c301c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing VCF: 100%|██████████| 56145/56145 [00:37<00:00, 1503.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved val.pt   | gts=(2000, 56145) | coords=(56145, 4)\n"
     ]
    }
   ],
   "source": [
    "# ---------- 验证集 ----------\n",
    "val_gts, val_samples, _, _, quat_val = read_vcf(\n",
    "    cfg.data.val_vcf, phased, genome_json)\n",
    "\n",
    "torch.save({'gts': val_gts, 'coords':quat_val, 'var_depths':var_depth_index},\n",
    "            os.path.join(cfg.data.path, \"val.pt\"))\n",
    "\n",
    "print(f\"Saved val.pt   | gts={tuple(val_gts.shape)} | coords={tuple(quat_val.shape)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa44d13",
   "metadata": {},
   "source": [
    "## 2. Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472f2e2c",
   "metadata": {},
   "source": [
    "将STICI中原有的 `chunk_module` 内的注意力、全连接层等模块统一替换为 `BiMamba2Block`\n",
    "\n",
    "以下几个地方需要注意和STICI的差别：\n",
    "\n",
    "1. chunk 划分标准：按 chunk_size 分割？按 n_chunks 分割？尾部 chunk 位点数不足的部分如何处理？ \n",
    "2. 分 chunk 后的 concat 部分，如何处理 chunk 与 chunk 之间 overlap 的位点？\n",
    "3. STICI 在 concat chunk 后，又经过了两层 Conv1D，文章示意图上未标明。\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9067e9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from typing import Optional\n",
    "import torch.nn.functional as F\n",
    "from mamba_ssm import Mamba2  # 官方实现\n",
    "\n",
    "\n",
    "\n",
    "class CatEmbeddings(nn.Module):\n",
    "    \"\"\"\n",
    "    等位基因 + 坐标 嵌入\n",
    "    -1 -> padding_idx (n_cats) -> 零向量\n",
    "    \"\"\"\n",
    "    def __init__(self, n_cats: int, d_model: int, coord_dim: int = 4):\n",
    "        super().__init__()\n",
    "        self.allele_embed = nn.Embedding(n_cats + 1, d_model, padding_idx=n_cats)\n",
    "        self.coord_proj = nn.Linear(coord_dim, d_model)\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, x_coord: torch.Tensor):\n",
    "        \"\"\"\n",
    "        x:       (B, L)        long，-1 会被当成 padding_idx n_cats\n",
    "        x_coord: (L, 4)        float\n",
    "        return:  (B, L, d_model)\n",
    "        \"\"\"\n",
    "        x = x.masked_fill(x == -1, self.allele_embed.padding_idx)\n",
    "        e1 = self.allele_embed(x)                       # (B,L,d)\n",
    "        e2 = self.coord_proj(x_coord).unsqueeze(0)      # (1,L,d)\n",
    "        return self.norm(e1 + e2)\n",
    "\n",
    "class BiMamba2Block(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        d_model: int,\n",
    "        bidirectional: bool = True,\n",
    "        bidirectional_strategy: str = \"add\",      # \"add\" | \"ew_multiply\"\n",
    "        bidirectional_weight_tie: bool = True,\n",
    "        # ---- 以下透传给 Mamba2 ----\n",
    "        d_state: int = 128,\n",
    "        expand: int = 2,\n",
    "        d_conv: int = 4,\n",
    "        conv_bias: bool = True,\n",
    "        bias: bool = False,\n",
    "        headdim: int = 64,\n",
    "        ngroups: int = 1,\n",
    "        **mamba2_kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        if bidirectional and bidirectional_strategy not in {\"add\", \"ew_multiply\"}:\n",
    "            raise NotImplementedError(bidirectional_strategy)\n",
    "\n",
    "        self.bidirectional = bidirectional\n",
    "        self.strategy = bidirectional_strategy\n",
    "\n",
    "        # 前向 SSM\n",
    "        self.mamba_fwd = Mamba2(\n",
    "            d_model=d_model,\n",
    "            d_state=d_state,\n",
    "            expand=expand,\n",
    "            d_conv=d_conv,\n",
    "            conv_bias=conv_bias,\n",
    "            bias=bias,\n",
    "            headdim=headdim,\n",
    "            ngroups=ngroups,\n",
    "            **mamba2_kwargs,\n",
    "        )\n",
    "\n",
    "        if bidirectional:\n",
    "            self.mamba_rev = Mamba2(\n",
    "                d_model=d_model,\n",
    "                d_state=d_state,\n",
    "                expand=expand,\n",
    "                d_conv=d_conv,\n",
    "                conv_bias=conv_bias,\n",
    "                bias=bias,\n",
    "                headdim=headdim,\n",
    "                ngroups=ngroups,\n",
    "                **mamba2_kwargs,\n",
    "            )\n",
    "            if bidirectional_weight_tie:\n",
    "                self.mamba_rev.in_proj.weight = self.mamba_fwd.in_proj.weight\n",
    "                self.mamba_rev.in_proj.bias   = self.mamba_fwd.in_proj.bias\n",
    "                self.mamba_rev.out_proj.weight = self.mamba_fwd.out_proj.weight\n",
    "                self.mamba_rev.out_proj.bias   = self.mamba_fwd.out_proj.bias\n",
    "        else:\n",
    "            self.mamba_rev = None\n",
    "\n",
    "    def forward(self, x: torch.Tensor, mask: Optional[torch.Tensor] = None):\n",
    "        out = self.mamba_fwd(x)\n",
    "        if self.bidirectional:\n",
    "            x_rev = x.flip(dims=[1])\n",
    "            out_rev = self.mamba_rev(x_rev).flip(dims=[1])\n",
    "            if self.strategy == \"add\":\n",
    "                out = out + out_rev\n",
    "            elif self.strategy == \"ew_multiply\":\n",
    "                out = out * out_rev\n",
    "            else:\n",
    "                raise RuntimeError(self.strategy)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ChunkModule(nn.Module):\n",
    "    def __init__(self, d_model: int, n_layers: int, **mamba_kwargs):\n",
    "        super().__init__()\n",
    "        self.blocks = nn.ModuleList([\n",
    "            BiMamba2Block(d_model=d_model, **mamba_kwargs)\n",
    "            for _ in range(n_layers)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x_chunk):\n",
    "        for blk in self.blocks:\n",
    "            x_chunk = blk(x_chunk)\n",
    "        return x_chunk\n",
    "\n",
    "class EvoFill(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_cats: int,\n",
    "        chunk_size: int,\n",
    "        d_model: int = 256,\n",
    "        n_layers: int = 4,\n",
    "        chunk_overlap: int = 64,          # 直接指定 overlap 长度\n",
    "        **mamba_kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.n_cats = n_cats\n",
    "        self.chunk_size = chunk_size\n",
    "        self.chunk_overlap = chunk_overlap\n",
    "\n",
    "        self.embed = CatEmbeddings(n_cats, d_model)\n",
    "        # 只实例化一个 ChunkModule，所有 chunk 共享权重\n",
    "        self.chunk_module = ChunkModule(d_model, n_layers, **mamba_kwargs)\n",
    "\n",
    "        self.length_proj = nn.Sequential(\n",
    "            nn.Conv1d(d_model, d_model, kernel_size=3, padding=1),\n",
    "            nn.GELU(),\n",
    "        )\n",
    "        self.out_conv = nn.Conv1d(d_model, n_cats, kernel_size=1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, x_coord: torch.Tensor):\n",
    "        \"\"\"\n",
    "        x:       (B, L)        long，-1 表示 padding\n",
    "        x_coord: (L, 4)        float\n",
    "        return:  (B, L, n_cats)\n",
    "        \"\"\"\n",
    "        B, L_orig = x.shape\n",
    "        device = x.device\n",
    "\n",
    "        # 1. 嵌入\n",
    "        h = self.embed(x, x_coord)                      # (B, L_orig, d)\n",
    "\n",
    "        # 2. 滑窗切分\n",
    "        chunk_size = self.chunk_size\n",
    "        overlap = self.chunk_overlap\n",
    "        step = chunk_size - overlap\n",
    "        n_chunks = math.ceil((L_orig - overlap) / step)\n",
    "\n",
    "        # 3. 需要 pad 到能整除 step\n",
    "        pad_len = n_chunks * step + overlap - L_orig\n",
    "        if pad_len > 0:\n",
    "            h = F.pad(h, (0, 0, 0, pad_len))            # (B, L_pad, d)\n",
    "        L_pad = h.shape[1]\n",
    "\n",
    "        # 4. 收集每个 chunk 的输出，同时记录每个 token 被哪些 chunk 覆盖\n",
    "        out_buf = torch.zeros(B, L_pad, h.shape[-1], device=device)\n",
    "        count_buf = torch.zeros(B, L_pad, dtype=torch.long, device=device)\n",
    "\n",
    "        for i in range(n_chunks):\n",
    "            start = i * step\n",
    "            end = start + chunk_size\n",
    "            chunk = h[:, start:end, :]                  # (B, chunk_size, d)\n",
    "            chunk_out = self.chunk_module(chunk)        # (B, chunk_size, d)\n",
    "\n",
    "            # 累加重叠区域\n",
    "            out_buf[:, start:end, :] += chunk_out\n",
    "            count_buf[:, start:end] += 1\n",
    "\n",
    "        # 5. 重叠区域取平均\n",
    "        out_buf = out_buf / count_buf.unsqueeze(-1).clamp_min(1)\n",
    "\n",
    "        # 6. 1D 卷积 + 插值回原始长度\n",
    "        out = self.length_proj(out_buf.transpose(1, 2))  # (B, d, L_pad)\n",
    "        out = F.interpolate(out, size=L_orig, mode='linear', align_corners=False)\n",
    "\n",
    "        # 7. 输出 logits\n",
    "        logits = self.out_conv(out).transpose(1, 2)      # (B, L_orig, n_cats)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c0c02b",
   "metadata": {},
   "source": [
    "模型单测，检查输出张量形状"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada08775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1800, 3])\n"
     ]
    }
   ],
   "source": [
    "# unit test\n",
    "model = EvoFill(\n",
    "    n_cats=3,\n",
    "    chunk_size=512,\n",
    "    chunk_overlap=64,\n",
    "    d_model=256,\n",
    "    n_layers=4,\n",
    "    d_state=128,\n",
    "    expand=2,\n",
    ").cuda()\n",
    "\n",
    "x = torch.randint(-1, 2, (2, 1800)).cuda() # -1（missing）, 0, 1\n",
    "x_coord = torch.randn(1800, 4).cuda()\n",
    "logits = model(x, x_coord)\n",
    "print(logits.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93def35e",
   "metadata": {},
   "source": [
    "## 3. Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2629d868",
   "metadata": {},
   "source": [
    "STICI 的 `ImputationLoss` 计算本身以及Pytorch复现存在问题：\n",
    "\n",
    "`tf.keras.losses.KLDivergence` 计算要求输入logits，会在其内部做一遍`softmax`。\n",
    "\n",
    "然而 STICI 最后一层（`STICI_V1.1.py`, L387）：\n",
    "\n",
    "`self.last_conv = layers.Conv1D(self.in_channel - 1, 5, padding='same', activation=tf.nn.softmax)`\n",
    "\n",
    "输出值已经做过一次`softmax`，如此一来会导致计算的KL散度偏大。\n",
    "\n",
    "同时，Pytorch 中的`nn.KLDivLoss`输入要求为`softmax`处理后的`log-probabilities`，其余差异见下表：\n",
    "\n",
    "| 特性                | `tf.keras.losses.KLDivergence` | `nn.KLDivLoss`                        |\n",
    "| ----------------- | ------------------------------ | ------------------------------------- |\n",
    "| 输入格式              | 概率                             | 输入：log-probabilities，目标：probabilities |\n",
    "| 是否需手动取 log        | ❌                              | ✅                                     |\n",
    "| 是否自动裁剪输入          | ✅                              | ❌                                     |\n",
    "| 默认归约方式            | `sum_over_batch_size`          | `batchmean`                           |\n",
    "| 是否支持 `log_target` | ❌                              | ✅（可选）                                 |\n",
    "\n",
    "在 `y_true` 为 one-hot 编码时，真实分布 `y_true` 的熵为0，交叉熵和KL散度应该相等，两者累加无意义。\n",
    "\n",
    "在以下代码中采取了和STICI不同的处理方法：保留MCE，删除KL，R2取10/log（而非负数），用GradNorm平衡MCE和R2损失。实际性能表现待评估。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1aeb7e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import grad\n",
    "\n",
    "class GradNormLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    GradNorm: Gradient Normalization for Adaptive Loss Balancing\n",
    "    参考原始论文 Chen et al. 2018 实现，适配 2 任务（CE + R²）\n",
    "    \"\"\"\n",
    "    def __init__(self, num_tasks=2, alpha=1.5, lr_w=1e-3, eps=1e-8):\n",
    "        super().__init__()\n",
    "        self.num_tasks = num_tasks\n",
    "        self.alpha   = alpha          # 恢复速度偏好，论文默认 1.5\n",
    "        self.lr_w    = lr_w           # 权重学习率，比模型 lr 小 1~2 量级\n",
    "        self.eps     = eps\n",
    "        self.w       = nn.Parameter(torch.ones(num_tasks))   # 可训练权重\n",
    "        self.register_buffer('L0', torch.zeros(num_tasks))   # 初始损失\n",
    "        self.initialized = False\n",
    "\n",
    "    def forward(self, losses: torch.Tensor):\n",
    "        # losses: [ce, r2]  已经 detach-free\n",
    "        if not self.initialized:\n",
    "            self.L0 = losses.detach().clone()\n",
    "            self.initialized = True\n",
    "\n",
    "        self.L_t = losses\n",
    "        weighted = self.w * losses          # w_i * L_i\n",
    "        return weighted.sum()               # 返回给主优化器\n",
    "\n",
    "    def gradnorm_step(self, shared_params, retain_graph=False):\n",
    "        \"\"\"\n",
    "        在 model.loss_backward() 之后、optimizer.step() 之前调用一次\n",
    "        shared_params:  ***共享部分*** 的参数（例如 encoder 最后一层）\n",
    "        \"\"\"\n",
    "        if not self.initialized:\n",
    "            return\n",
    "\n",
    "        # 1. 清零 w 的 grad\n",
    "        if self.w.grad is not None:\n",
    "            self.w.grad.zero_()\n",
    "\n",
    "        # 2. 计算每个任务对 shared 的梯度范数  G_i(t)\n",
    "        G_t = []\n",
    "        for i in range(self.num_tasks):\n",
    "            g = grad(self.L_t[i], shared_params, retain_graph=True,\n",
    "                     create_graph=True)[0]          # 返回 tuple\n",
    "            G_t.append(torch.norm(g * self.w[i]) + self.eps)\n",
    "        G_t = torch.stack(G_t)                      # [T]\n",
    "\n",
    "        # 3. 相对逆训练速率  r_i(t)\n",
    "        tilde_L_t = (self.L_t / self.L0).detach()\n",
    "        r_t       = tilde_L_t / tilde_L_t.mean()\n",
    "\n",
    "        # 4. 期望梯度范数\n",
    "        bar_G_t = G_t.mean()\n",
    "\n",
    "        # 5. GradNorm 损失：L_grad = sum|G_i(t) - bar_G_t * r_i(t)^α|\n",
    "        l_grad = F.l1_loss(G_t, bar_G_t * (r_t ** self.alpha))\n",
    "\n",
    "        # 6. 只更新 w\n",
    "        self.w.grad = torch.autograd.grad(l_grad, self.w)[0]\n",
    "        with torch.no_grad():\n",
    "            new_w = self.w - self.lr_w * self.w.grad\n",
    "            new_w = new_w * (self.num_tasks / new_w.sum())\n",
    "            self.w.data = new_w  # ✅ 替换 copy_\n",
    "\n",
    "\n",
    "class ImputationLoss(nn.Module):\n",
    "    def __init__(self, use_r2_loss=True, group_size=4, eps=1e-8,\n",
    "                 use_grad_norm=False, gn_alpha=1.5, gn_lr_w=1e-3):\n",
    "        super().__init__()\n",
    "        self.use_r2_loss = use_r2_loss\n",
    "        self.group_size  = group_size\n",
    "        self.eps         = eps\n",
    "        self.use_gn      = use_grad_norm\n",
    "        if self.use_gn:\n",
    "            self.gn_loss = GradNormLoss(num_tasks=2, alpha=gn_alpha, lr_w=gn_lr_w)\n",
    "\n",
    "    # ---------- 工具函数 ---------- #\n",
    "    def _calc_r2(self, pred_alt_prob: torch.Tensor, gt_alt_af: torch.Tensor):\n",
    "        mask = ((gt_alt_af == 0.0) | (gt_alt_af == 1.0))\n",
    "        gt_alt_af = torch.where(mask, 0.5, gt_alt_af)\n",
    "        denom = gt_alt_af * (1.0 - gt_alt_af)\n",
    "        denom = torch.clamp(denom, min=0.01)\n",
    "        r2 = ((pred_alt_prob - gt_alt_af) ** 2) / denom\n",
    "        r2 = torch.where(mask, 0.0, r2)\n",
    "        return r2\n",
    "\n",
    "    # ---------- R2 loss（改为 10/log(r2)） ---------- #\n",
    "    def _r2_loss(self, y_pred: torch.Tensor, y_true: torch.Tensor, mask_valid: torch.Tensor):\n",
    "        B, V, C = y_pred.shape\n",
    "        G = self.group_size\n",
    "        num_full = B // G\n",
    "        rem = B % G\n",
    "\n",
    "        prob = F.softmax(y_pred, dim=-1)\n",
    "        alt_prob = prob[..., 1] + 2.0 * prob[..., 2]\n",
    "\n",
    "        r2_penalty = 0.0\n",
    "\n",
    "        def one_group(sl):\n",
    "            gt_sl   = y_true[sl]                     # (g_size, V)\n",
    "            mask_sl = mask_valid[sl]                 # (g_size, V)\n",
    "            alt_sl  = alt_prob[sl]                   # (g_size, V)\n",
    "\n",
    "            gt_alt_cnt = (gt_sl * mask_sl).sum(dim=0)\n",
    "            gt_alt_af  = gt_alt_cnt / (mask_sl.sum(dim=0) + self.eps)\n",
    "\n",
    "            pred_alt_af = (alt_sl * mask_sl).sum(dim=0) / (mask_sl.sum(dim=0) + self.eps)\n",
    "\n",
    "            r2 = self._calc_r2(pred_alt_af, gt_alt_af)          # (V,)\n",
    "            return r2.sum() * (sl.stop - sl.start)      # 保持与原来相同的加权方式\n",
    "\n",
    "        # 完整组\n",
    "        for g in range(num_full):\n",
    "            r2_penalty += one_group(slice(g * G, (g + 1) * G))\n",
    "\n",
    "        # 剩余样本\n",
    "        if rem:\n",
    "            r2_penalty += one_group(slice(num_full * G, B))\n",
    "\n",
    "        return 10.0 / torch.log(r2_penalty + self.eps)\n",
    "\n",
    "    # ---------- 前向 ---------- #\n",
    "    def forward(self, y_pred, y_true):\n",
    "        mask_valid = (y_true != -1)\n",
    "        y_true_m   = y_true.clone()\n",
    "        y_true_m[~mask_valid] = 0\n",
    "\n",
    "        # 1. MCE 改为 mean\n",
    "        log_p = F.log_softmax(y_pred, dim=-1)\n",
    "        ce = -log_p.gather(dim=-1, index=y_true_m.long().unsqueeze(-1)).squeeze(-1)\n",
    "        ce = (ce * mask_valid).sum() / (mask_valid.sum() + self.eps)\n",
    "        # 2. R²\n",
    "        r2 = 0.\n",
    "        if self.use_r2_loss:\n",
    "            r2 = self._r2_loss(y_pred, y_true, mask_valid)\n",
    "\n",
    "        # 3. GradNorm 或固定系数\n",
    "        if self.use_gn:\n",
    "            losses = torch.stack([ce, r2])\n",
    "            gn_loss = self.gn_loss(losses)\n",
    "            # print('ce:',ce,'r2:',r2, 'gn_loss:', gn_loss)\n",
    "            return gn_loss\n",
    "        else:\n",
    "            return ce + r2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cade7b9",
   "metadata": {},
   "source": [
    "## 4. Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e871913",
   "metadata": {},
   "source": [
    "单卡，早停，AdamW优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9cd5adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "\n",
    "class GenotypeDataset(Dataset):\n",
    "    def __init__(self, gts, coords, mask_ratio=0.0):\n",
    "        self.gt_true = gts.long()          # 原始完整标签\n",
    "        self.coords = coords.float()\n",
    "        self.mask_ratio = mask_ratio\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.gt_true.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        gt_true = self.gt_true[idx]        # 完整标签\n",
    "        coords = self.coords                # (L, 4)\n",
    "\n",
    "        # 训练时额外随机遮掩\n",
    "        gt_mask = gt_true.clone()\n",
    "        if self.mask_ratio > 0:\n",
    "            mask = torch.rand_like(gt_mask.float()) < self.mask_ratio\n",
    "            gt_mask[mask] = -1             # 仅输入被遮掩\n",
    "\n",
    "        # 返回：输入（含缺失）、原始标签、坐标\n",
    "        return gt_mask, gt_true, coords \n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    batch: List[(gt_mask, gt_true, coords)] 每个 coords 形状相同\n",
    "    返回：gt_mask, gt_true, coords（二维，直接取第 0 个即可\n",
    "    \"\"\"\n",
    "    gt_mask  = torch.stack([b[0] for b in batch], 0)\n",
    "    gt_true  = torch.stack([b[1] for b in batch], 0)\n",
    "    coords   = batch[0][2]          # 全局共享\n",
    "    return gt_mask, gt_true, coords\n",
    "\n",
    "def build_loader(pt_path, batch_size, shuffle, mask_ratio):\n",
    "    data = torch.load(pt_path)\n",
    "    dataset = GenotypeDataset(data['gts'], data['coords'], mask_ratio=mask_ratio)\n",
    "    return DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=shuffle,\n",
    "        collate_fn=collate_fn,\n",
    "    )\n",
    "\n",
    "def imputation_accuracy(logits, gts, mask):\n",
    "    \"\"\"仅在被 mask 位点计算 accuracy\"\"\"\n",
    "    preds = torch.argmax(logits, dim=-1)  # (B, L)\n",
    "    correct = (preds == gts) & mask\n",
    "    return correct.sum().float() / mask.sum().float()\n",
    "\n",
    "def train_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss, total_acc, total_mask = 0.0, 0.0, 0\n",
    "\n",
    "    shared_params = list(model.length_proj.parameters()) + list(model.out_conv.parameters())\n",
    "    assert len(shared_params) > 0\n",
    "    assert all(p.requires_grad for p in shared_params)\n",
    "\n",
    "    pbar = tqdm(loader, leave=False)\n",
    "    for gt_mask, gt_true, coords in pbar:\n",
    "        gt_mask, gt_true, coords = gt_mask.to(device), gt_true.to(device), \\\n",
    "                                               coords.to(device)\n",
    "        \n",
    "        logits = model(gt_mask, coords)  # (B, L, n_cats)\n",
    "        loss = criterion(logits, gt_true) \n",
    "\n",
    "        if criterion.use_gn:\n",
    "            criterion.gn_loss.gradnorm_step(shared_params, retain_graph=False)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # accuracy：只算被 mask 的位点\n",
    "        mask = gt_mask == -1\n",
    "        acc = imputation_accuracy(logits, gt_true, mask)\n",
    "        total_loss += loss.item()\n",
    "        total_acc += acc.item() * mask.sum().item()\n",
    "        total_mask += mask.sum().item()\n",
    "        pbar.set_postfix(loss=f\"{loss.item():.4f}\", acc=f\"{acc.item():.4f}\")\n",
    "\n",
    "    return total_loss / len(loader), total_acc / total_mask\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss, total_acc, total_mask = 0.0, 0.0, 0\n",
    "\n",
    "    pbar = tqdm(loader, leave=False, desc='validate')\n",
    "    for gt_mask, gt_true, coords in pbar:\n",
    "        gt_mask, gt_true, coords = gt_mask.to(device), \\\n",
    "                                     gt_true.to(device), \\\n",
    "                                     coords.to(device)\n",
    "\n",
    "        logits = model(gt_mask, coords)          # (B, L, n_cats)\n",
    "        loss   = criterion(logits, gt_true)      # 计算与真值差异\n",
    "\n",
    "        # 只统计被 mask 的位点\n",
    "        mask = gt_mask == -1\n",
    "        acc  = imputation_accuracy(logits, gt_true, mask)\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_acc  += acc.item() * mask.sum().item()\n",
    "        total_mask += mask.sum().item()\n",
    "\n",
    "        pbar.set_postfix(loss=f\"{loss.item():.4f}\", acc=f\"{acc.item():.4f}\")\n",
    "\n",
    "    return total_loss / len(loader), total_acc / (total_mask + 1e-8)\n",
    "\n",
    "\n",
    "class EarlyStopper:\n",
    "    def __init__(self, patience=10, min_delta=0.0, mode='min'):\n",
    "        assert mode in {'min', 'max'}\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.mode = mode\n",
    "        self.counter = 0\n",
    "        self.best = None\n",
    "        self.best_state = None\n",
    "\n",
    "    def __call__(self, metric, model):\n",
    "        if self.best is None:\n",
    "            self.best = metric\n",
    "            self.best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "            return False\n",
    "\n",
    "        better = (metric < self.best - self.min_delta) if self.mode == 'min' else \\\n",
    "                 (metric > self.best + self.min_delta)\n",
    "\n",
    "        if better:\n",
    "            self.best = metric\n",
    "            self.best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "\n",
    "        return self.counter >= self.patience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c49f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from tqdm import tqdm\n",
    "\n",
    "cfg = load_config(\"/home/qmtang/mnt_qmtang/EvoFill/config/config.json\")\n",
    "device = torch.device(cfg.train.device)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# 数据\n",
    "train_loader = build_loader(\n",
    "    Path(cfg.data.path) / \"train.pt\",\n",
    "    batch_size=cfg.train.batch_size,\n",
    "    shuffle=True,\n",
    "    mask_ratio=cfg.train.mask_ratio,\n",
    ")\n",
    "val_loader = build_loader(\n",
    "    Path(cfg.data.path) / \"val.pt\",\n",
    "    batch_size=cfg.train.batch_size,\n",
    "    shuffle=False,\n",
    "    mask_ratio=cfg.train.mask_ratio,\n",
    ")\n",
    "\n",
    "# 模型 & 优化器\n",
    "model = EvoFill(**vars(cfg.model)).to(device)\n",
    "\n",
    "criterion = ImputationLoss(use_r2_loss=True,\n",
    "                        use_grad_norm=True,\n",
    "                        gn_alpha=0.8,\n",
    "                        gn_lr_w=cfg.train.lr/10).to(device) #权重学习率，比模型 lr 小 1~2 量级\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=cfg.train.lr, weight_decay=cfg.train.weight_decay)\n",
    "\n",
    "early_stopper = EarlyStopper(patience=cfg.train.patience,\n",
    "                                min_delta=cfg.train.min_delta,\n",
    "                                mode='min')\n",
    "\n",
    "# 训练循环\n",
    "for epoch in range(1, cfg.train.num_epochs + 1):\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    val_loss, val_acc = validate(model, val_loader, criterion, device)\n",
    "    print(f\"Epoch {epoch:03d} | train loss {train_loss:.4f} acc {train_acc:.4f} | \"\n",
    "            f\"val loss {val_loss:.4f} acc {val_acc:.4f}\")\n",
    "    if early_stopper(val_loss, model):\n",
    "        print(f\"Early stopping triggered at epoch {epoch}\")\n",
    "        break\n",
    "\n",
    "# 保存最优模型\n",
    "save_dir = Path(cfg.train.save)\n",
    "save_dir.mkdir(parents=True, exist_ok=True)\n",
    "torch.save(early_stopper.best_state, save_dir / \"evofill_best.pt\")\n",
    "print(f\"Best model saved to {save_dir / 'evofill_best.pt'} (epoch {epoch - early_stopper.counter})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02dd78d",
   "metadata": {},
   "source": [
    "## 5. Imuptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c0b933",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "002ac335",
   "metadata": {},
   "source": [
    "## 6. Evaulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed80fb15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
