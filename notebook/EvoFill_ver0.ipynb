{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b60ccf3a",
   "metadata": {},
   "source": [
    "ver0: 多 chunk modules 独立权重"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4bb00d",
   "metadata": {},
   "source": [
    "## Dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "757312f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os; os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\" # 设置用GPU1\n",
    "import gzip\n",
    "import json\n",
    "import logging\n",
    "import shutil\n",
    "from typing import Union\n",
    "from argparse import Namespace\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datatable as dt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import grad\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from mamba_ssm import Mamba2\n",
    "from mamba_ssm.modules.mamba2_simple import Mamba2Simple as Mamba2Block # 原Mamba2Block\n",
    "from torch_optimizer import Lamb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975df815",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5eeded0",
   "metadata": {},
   "outputs": [],
   "source": [
    "SUPPORTED_FILE_FORMATS = {\"vcf\", \"csv\", \"tsv\"}\n",
    "class DataReader:\n",
    "    def __init__(self):\n",
    "        self.target_is_gonna_be_phased = None\n",
    "        self.target_set = None\n",
    "        self.target_sample_value_index = 2\n",
    "        self.ref_sample_value_index = 2\n",
    "        self.target_file_extension = None\n",
    "        self.allele_count = 2\n",
    "        self.genotype_vals = None\n",
    "        self.ref_is_phased = None\n",
    "        self.reference_panel = None\n",
    "        self.VARIANT_COUNT = 0\n",
    "        self.is_phased = False\n",
    "        self.MISSING_VALUE = None\n",
    "        self.ref_is_hap = False\n",
    "        self.target_is_hap = False\n",
    "        self.ref_n_header_lines = []\n",
    "        self.ref_n_data_header = \"\"\n",
    "        self.target_n_header_lines = []\n",
    "        self.target_n_data_header = \"\"\n",
    "        self.ref_separator = None\n",
    "        self.map_values_1_vec = np.vectorize(self.__map_hap_2_ind_parent_1)\n",
    "        self.map_values_2_vec = np.vectorize(self.__map_hap_2_ind_parent_2)\n",
    "        self.map_haps_to_vec = np.vectorize(self.__map_haps_2_ind)\n",
    "        self.delimiter_dictionary = {\"vcf\": \"\\t\", \"csv\": \",\", \"tsv\": \"\\t\", \"infer\": \"\\t\"}\n",
    "        self.ref_file_extension = \"vcf\"\n",
    "        self.test_file_extension = \"vcf\"\n",
    "        self.target_is_phased = True\n",
    "\n",
    "    def __read_csv(self, file_path, is_vcf=False, is_reference=False, separator=\"\\t\", first_column_is_index=True,\n",
    "                   comments=\"##\") -> pd.DataFrame:\n",
    "        \"\"\"Read CSV/VCF files\"\"\"\n",
    "        print(\"Reading the file...\")\n",
    "        data_header = None\n",
    "        path_sep = \"/\" if \"/\" in file_path else os.path.sep\n",
    "        line_counter = 0\n",
    "        root, ext = os.path.splitext(file_path)\n",
    "        with gzip.open(file_path, 'rt') if ext == '.gz' else open(file_path, 'rt') as f_in:\n",
    "            while True:\n",
    "                line = f_in.readline()\n",
    "                if line.startswith(comments):\n",
    "                    line_counter += 1\n",
    "                    if is_reference:\n",
    "                        self.ref_n_header_lines.append(line)\n",
    "                    else:\n",
    "                        self.target_n_header_lines.append(line)\n",
    "                else:\n",
    "                    data_header = line\n",
    "                    break\n",
    "        if data_header is None:\n",
    "            raise IOError(\"The file only contains comments!\")\n",
    "        df = dt.fread(file=file_path, sep=separator, header=True, skip_to_line=line_counter + 1)\n",
    "        df = df.to_pandas()\n",
    "        if first_column_is_index:\n",
    "            df.set_index(df.columns[0], inplace=True)\n",
    "        return df\n",
    "\n",
    "    def __find_file_extension(self, file_path, file_format, delimiter):\n",
    "        separator = \"\\t\"\n",
    "        found_file_format = None\n",
    "        if file_format not in [\"infer\"] + list(SUPPORTED_FILE_FORMATS):\n",
    "            raise ValueError(\"File extension must be one of {'vcf', 'csv', 'tsv', 'infer'}.\")\n",
    "        if file_format == 'infer':\n",
    "            file_name_tokenized = file_path.split(\".\")\n",
    "            for possible_extension in file_name_tokenized[::-1]:\n",
    "                if possible_extension in SUPPORTED_FILE_FORMATS:\n",
    "                    found_file_format = possible_extension\n",
    "                    separator = self.delimiter_dictionary[possible_extension] if delimiter is None else delimiter\n",
    "                    break\n",
    "            if found_file_format is None:\n",
    "                logging.warning(\"Could not infer the file type. Using tsv as the last resort.\")\n",
    "                found_file_format = \"tsv\"\n",
    "        else:\n",
    "            found_file_format = file_format\n",
    "            separator = self.delimiter_dictionary[file_format] if delimiter is None else delimiter\n",
    "        return found_file_format, separator\n",
    "\n",
    "    def assign_training_set(self, file_path: str, target_is_gonna_be_phased_or_haps: bool,\n",
    "                            variants_as_columns: bool = False, delimiter=None, file_format=\"infer\",\n",
    "                            first_column_is_index=True, comments=\"##\") -> None:\n",
    "        self.target_is_gonna_be_phased = target_is_gonna_be_phased_or_haps\n",
    "        self.ref_file_extension, self.ref_separator = self.__find_file_extension(file_path, file_format, delimiter)\n",
    "\n",
    "        self.reference_panel = self.__read_csv(file_path, is_reference=True, is_vcf=False, separator=self.ref_separator,\n",
    "                                               first_column_is_index=first_column_is_index,\n",
    "                                               comments=comments) if self.ref_file_extension != 'vcf' else self.__read_csv(\n",
    "            file_path, is_reference=True, is_vcf=True, separator='\\t', first_column_is_index=False, comments=\"##\")\n",
    "\n",
    "        if self.ref_file_extension != \"vcf\":\n",
    "            if variants_as_columns:\n",
    "                self.reference_panel = self.reference_panel.transpose()\n",
    "            self.reference_panel.reset_index(drop=False, inplace=True)\n",
    "            self.reference_panel.rename(columns={self.reference_panel.columns[0]: \"ID\"}, inplace=True)\n",
    "        else:\n",
    "            self.ref_sample_value_index += 8\n",
    "\n",
    "        self.ref_is_hap = not (\"|\" in self.reference_panel.iloc[0, self.ref_sample_value_index - 1] or \"/\" in\n",
    "                               self.reference_panel.iloc[0, self.ref_sample_value_index - 1])\n",
    "        self.ref_is_phased = \"|\" in self.reference_panel.iloc[0, self.ref_sample_value_index - 1]\n",
    "\n",
    "        if self.ref_is_hap and not target_is_gonna_be_phased_or_haps:\n",
    "            raise ValueError(\n",
    "                \"Reference contains haploids while target will be unphased diploids. Model cannot predict target.\")\n",
    "\n",
    "        if not (self.ref_is_phased or self.ref_is_hap) and target_is_gonna_be_phased_or_haps:\n",
    "            raise ValueError(\n",
    "                \"Reference contains unphased diploids while target will be phased/haploid. Model cannot predict target.\")\n",
    "\n",
    "        self.VARIANT_COUNT = self.reference_panel.shape[0]\n",
    "        print(\n",
    "            f\"{self.reference_panel.shape[1] - (self.ref_sample_value_index - 1)} {'haploid' if self.ref_is_hap else 'diploid'} samples with {self.VARIANT_COUNT} variants found!\")\n",
    "\n",
    "        self.is_phased = target_is_gonna_be_phased_or_haps and (self.ref_is_phased or self.ref_is_hap)\n",
    "\n",
    "        original_allele_sep = \"|\" if self.ref_is_phased or self.ref_is_hap else \"/\"\n",
    "        final_allele_sep = \"|\" if self.is_phased else \"/\"\n",
    "\n",
    "        def get_diploid_alleles(genotype_vals):\n",
    "            allele_set = set()\n",
    "            for genotype_val in genotype_vals:\n",
    "                if genotype_val not in [\".\", \".|.\", \"./.\"]:\n",
    "                    if final_allele_sep in genotype_val:\n",
    "                        v1, v2 = genotype_val.split(final_allele_sep)\n",
    "                        allele_set.update([v1, v2])\n",
    "                    else:\n",
    "                        allele_set.add(genotype_val)  # For haploids\n",
    "            return np.array(list(allele_set))\n",
    "\n",
    "        genotype_vals = pd.unique(self.reference_panel.iloc[:, self.ref_sample_value_index - 1:].values.ravel('K'))\n",
    "        print(f\"DEBUG: Unique genotypes in dataset: {genotype_vals[:10]}...\")  # Show first 10\n",
    "\n",
    "        if self.ref_is_phased and not target_is_gonna_be_phased_or_haps:\n",
    "            phased_to_unphased_dict = {}\n",
    "            for i in range(genotype_vals.shape[0]):\n",
    "                key = genotype_vals[i]\n",
    "                if \"|\" in key and key not in [\".\", \".|.\"]:\n",
    "                    v1, v2 = [int(s) for s in genotype_vals[i].split(original_allele_sep)]\n",
    "                    genotype_vals[i] = f\"{min(v1, v2)}/{max(v1, v2)}\"\n",
    "                    phased_to_unphased_dict[key] = genotype_vals[i]\n",
    "            if phased_to_unphased_dict:\n",
    "                self.reference_panel.iloc[:, self.ref_sample_value_index - 1:].replace(phased_to_unphased_dict,\n",
    "                                                                                       inplace=True)\n",
    "\n",
    "        self.genotype_vals = np.unique(genotype_vals)\n",
    "        self.alleles = get_diploid_alleles(self.genotype_vals) if not self.ref_is_hap else self.genotype_vals\n",
    "        self.allele_count = len(self.alleles)\n",
    "        self.MISSING_VALUE = self.allele_count if self.is_phased else len(self.genotype_vals)\n",
    "\n",
    "        print(f\"DEBUG: self.genotype_vals: {self.genotype_vals}\")\n",
    "        print(f\"DEBUG: self.alleles: {self.alleles}\")\n",
    "        print(f\"DEBUG: is_phased: {self.is_phased}\")\n",
    "\n",
    "        if self.is_phased:\n",
    "            self.hap_map = {str(v): i for i, v in enumerate(list(sorted(self.alleles)))}\n",
    "            self.hap_map.update({\".\": self.MISSING_VALUE})\n",
    "            self.r_hap_map = {i: k for k, i in self.hap_map.items()}\n",
    "            self.map_preds_2_allele = np.vectorize(lambda x: self.r_hap_map[x])\n",
    "            print(f\"DEBUG: hap_map: {self.hap_map}\")\n",
    "        else:\n",
    "            unphased_missing_genotype = \"./.\"\n",
    "            self.replacement_dict = {g: i for i, g in enumerate(list(sorted(self.genotype_vals)))}\n",
    "            self.replacement_dict[unphased_missing_genotype] = self.MISSING_VALUE\n",
    "            self.reverse_replacement_dict = {v: k for k, v in self.replacement_dict.items()}\n",
    "            print(f\"DEBUG: replacement_dict: {self.replacement_dict}\")\n",
    "\n",
    "        self.SEQ_DEPTH = self.allele_count + 1 if self.is_phased else len(self.genotype_vals) + 1\n",
    "        print(f\"DEBUG: self.SEQ_DEPTH: {self.SEQ_DEPTH}\")\n",
    "\n",
    "    def assign_test_set(self, file_path, variants_as_columns=False, delimiter=None,\n",
    "                        file_format=\"infer\", first_column_is_index=True, comments=\"##\") -> None:\n",
    "        \"\"\"Assign test set for imputation\"\"\"\n",
    "        if self.reference_panel is None:\n",
    "            raise RuntimeError(\"First you need to use 'DataReader.assign_training_set(...) to assign a training set.'\")\n",
    "\n",
    "        self.target_file_extension, separator = self.__find_file_extension(file_path, file_format, delimiter)\n",
    "\n",
    "        test_df = self.__read_csv(file_path, is_reference=False, is_vcf=False, separator=separator,\n",
    "                                  first_column_is_index=first_column_is_index,\n",
    "                                  comments=comments) if self.target_file_extension != 'vcf' else self.__read_csv(\n",
    "            file_path, is_reference=False, is_vcf=True, separator='\\t', first_column_is_index=False, comments=\"##\")\n",
    "\n",
    "        if self.target_file_extension != \"vcf\":\n",
    "            if variants_as_columns:\n",
    "                test_df = test_df.transpose()\n",
    "            test_df.reset_index(drop=False, inplace=True)\n",
    "            test_df.rename(columns={test_df.columns[0]: \"ID\"}, inplace=True)\n",
    "        else:\n",
    "            self.target_sample_value_index += 8\n",
    "\n",
    "        self.target_is_hap = not (\"|\" in test_df.iloc[0, self.target_sample_value_index - 1] or \"/\" in\n",
    "                                  test_df.iloc[0, self.target_sample_value_index - 1])\n",
    "        is_phased = \"|\" in test_df.iloc[0, self.target_sample_value_index - 1]\n",
    "        test_var_count = test_df.shape[0]\n",
    "        print(f\"{test_var_count} {'haplotype' if self.target_is_hap else 'diplotype'} variants found!\")\n",
    "\n",
    "        # Validate compatibility\n",
    "        if (self.target_is_hap or is_phased) and not (self.ref_is_phased or self.ref_is_hap):\n",
    "            raise RuntimeError(\"The training set contains unphased data. The target must be unphased as well.\")\n",
    "        if self.ref_is_hap and not (self.target_is_hap or is_phased):\n",
    "            raise RuntimeError(\"The training set contains haploids. Target set should be phased or haploids.\")\n",
    "\n",
    "        # Merge with reference panel to align variants\n",
    "        self.target_set = test_df.merge(right=self.reference_panel[[\"ID\"]], on='ID', how='right')\n",
    "        if self.target_file_extension == \"vcf\" == self.ref_file_extension:\n",
    "            self.target_set[self.reference_panel.columns[:9]] = self.reference_panel[self.reference_panel.columns[:9]]\n",
    "\n",
    "        self.target_set = self.target_set.astype('str')\n",
    "        missing_value = \".\" if self.target_is_hap else \".|.\" if self.is_phased else \"./.\"\n",
    "        self.target_set.fillna(missing_value, inplace=True)\n",
    "        self.target_set.replace(\"nan\", missing_value, inplace=True)\n",
    "        print(\"Target set assignment done!\")\n",
    "\n",
    "    def __map_hap_2_ind_parent_1(self, x) -> int:\n",
    "        return self.hap_map[x.split('|')[0]]\n",
    "\n",
    "    def __map_hap_2_ind_parent_2(self, x) -> int:\n",
    "        return self.hap_map[x.split('|')[1]]\n",
    "\n",
    "    def __map_haps_2_ind(self, x) -> int:\n",
    "        return self.hap_map[x]\n",
    "\n",
    "    def get_ref_set(self, starting_var_index=0, ending_var_index=0) -> np.ndarray:\n",
    "        if 0 <= starting_var_index < ending_var_index:\n",
    "            data = self.reference_panel.iloc[starting_var_index:ending_var_index, self.ref_sample_value_index - 1:]\n",
    "        else:\n",
    "            data = self.reference_panel.iloc[:, self.ref_sample_value_index - 1:]\n",
    "\n",
    "        if self.is_phased:\n",
    "            is_haps = \"|\" not in data.iloc[0, 0]\n",
    "            if not is_haps:\n",
    "                # diploids to hap vecs\n",
    "                _x = np.empty((data.shape[1] * 2, data.shape[0]), dtype=np.int32)\n",
    "                _x[0::2] = self.map_values_1_vec(data.values.T)\n",
    "                _x[1::2] = self.map_values_2_vec(data.values.T)\n",
    "                return _x\n",
    "            else:\n",
    "                return self.map_haps_to_vec(data.values.T)\n",
    "        else:\n",
    "            return data.replace(self.replacement_dict).values.T.astype(np.int32)\n",
    "\n",
    "    def get_target_set(self, starting_var_index=0, ending_var_index=0) -> np.ndarray:\n",
    "        \"\"\"Get target data for imputation\"\"\"\n",
    "        if 0 <= starting_var_index < ending_var_index:\n",
    "            data = self.target_set.iloc[starting_var_index:ending_var_index, self.target_sample_value_index - 1:]\n",
    "        else:\n",
    "            data = self.target_set.iloc[:, self.target_sample_value_index - 1:]\n",
    "\n",
    "        if self.is_phased:\n",
    "            is_haps = \"|\" not in data.iloc[0, 0]\n",
    "            if not is_haps:\n",
    "                # diploids to hap vecs\n",
    "                _x = np.empty((data.shape[1] * 2, data.shape[0]), dtype=np.int32)\n",
    "                _x[0::2] = self.map_values_1_vec(data.values.T)\n",
    "                _x[1::2] = self.map_values_2_vec(data.values.T)\n",
    "                return _x\n",
    "            else:\n",
    "                return self.map_haps_to_vec(data.values.T)\n",
    "        else:\n",
    "            return data.replace(self.replacement_dict).values.T.astype(np.int32)\n",
    "\n",
    "    def __convert_unphased_probs_to_genotypes(self, allele_probs) -> np.ndarray:\n",
    "        \"\"\"Convert unphased probabilities to genotypes\"\"\"\n",
    "        n_samples, n_variants, n_alleles = allele_probs.shape\n",
    "        genotypes = np.zeros((n_samples, n_variants), dtype=object)\n",
    "\n",
    "        for i in tqdm(range(n_samples)):\n",
    "            for j in range(n_variants):\n",
    "                unphased_probs = allele_probs[i, j]\n",
    "                variant_genotypes = np.vectorize(self.reverse_replacement_dict.get)(\n",
    "                    np.argmax(unphased_probs, axis=-1)).flatten()\n",
    "                genotypes[i, j] = variant_genotypes\n",
    "        return genotypes\n",
    "\n",
    "    def __convert_hap_probs_to_diploid_genotypes(self, allele_probs) -> np.ndarray:\n",
    "        \"\"\"Convert haplotype probabilities to diploid genotypes\"\"\"\n",
    "        n_haploids, n_variants, n_alleles = allele_probs.shape\n",
    "\n",
    "        if n_haploids % 2 != 0:\n",
    "            raise ValueError(\"Number of haploids should be even.\")\n",
    "\n",
    "        n_samples = n_haploids // 2\n",
    "        genotypes = np.empty((n_samples, n_variants), dtype=object)\n",
    "        haploids_as_diploids = allele_probs.reshape((n_samples, 2, n_variants, -1))\n",
    "        variant_genotypes = self.map_preds_2_allele(np.argmax(haploids_as_diploids, axis=-1))\n",
    "\n",
    "        def process_variant_in_sample(haps_for_sample_at_variant, variant_genotypes_for_sample_at_variant):\n",
    "            if n_alleles > 2:\n",
    "                return '|'.join(variant_genotypes_for_sample_at_variant)\n",
    "            else:\n",
    "                # Output GP (genotype probabilities)\n",
    "                phased_probs = np.outer(haps_for_sample_at_variant[0], haps_for_sample_at_variant[1]).flatten()\n",
    "                unphased_probs = np.array([phased_probs[0], phased_probs[1] + phased_probs[2], phased_probs[-1]])\n",
    "                unphased_probs_str = \",\".join([f\"{v:.6f}\" for v in unphased_probs])\n",
    "                alt_dosage = np.dot(unphased_probs, [0, 1, 2])\n",
    "                return '|'.join(variant_genotypes_for_sample_at_variant) + f\":{unphased_probs_str}:{alt_dosage:.3f}\"\n",
    "\n",
    "        def process_sample(i):\n",
    "            return np.array([\n",
    "                process_variant_in_sample(haploids_as_diploids[i, :, j, :], variant_genotypes[i, :, j])\n",
    "                for j in range(n_variants)\n",
    "            ])\n",
    "\n",
    "        # Parallel processing\n",
    "        genotypes = Parallel(n_jobs=-1)(delayed(process_sample)(i) for i in tqdm(range(n_samples)))\n",
    "        return np.array(genotypes)\n",
    "\n",
    "    def __convert_hap_probs_to_hap_genotypes(self, allele_probs) -> np.ndarray:\n",
    "        \"\"\"Convert hap probabilities to hap genotypes\"\"\"\n",
    "        return np.argmax(allele_probs, axis=1).astype(str)\n",
    "\n",
    "    def __get_headers_for_output(self, contain_probs, chr=22):\n",
    "        \"\"\"Get VCF headers for output file\"\"\"\n",
    "        headers = [\n",
    "            \"##fileformat=VCFv4.2\",\n",
    "            '''##source=BiMamba v1.0.0''',\n",
    "            '''##INFO=<ID=AF,Number=A,Type=Float,Description=\"Estimated Alternate Allele Frequency\">''',\n",
    "            '''##INFO=<ID=MAF,Number=1,Type=Float,Description=\"Estimated Minor Allele Frequency\">''',\n",
    "            '''##INFO=<ID=AVG_CS,Number=1,Type=Float,Description=\"Average Call Score\">''',\n",
    "            '''##INFO=<ID=IMPUTED,Number=0,Type=Flag,Description=\"Marker was imputed\">''',\n",
    "            '''##FORMAT=<ID=GT,Number=1,Type=String,Description=\"Genotype\">''',\n",
    "        ]\n",
    "        probs_headers = [\n",
    "            '''##FORMAT=<ID=DS,Number=A,Type=Float,Description=\"Estimated Alternate Allele Dosage : [P(0/1)+2*P(1/1)]\">''',\n",
    "            '''##FORMAT=<ID=GP,Number=G,Type=Float,Description=\"Estimated Posterior Probabilities for Genotypes 0/0, 0/1 and 1/1\">'''\n",
    "        ]\n",
    "        if contain_probs:\n",
    "            headers.extend(probs_headers)\n",
    "        return headers\n",
    "\n",
    "    def __convert_genotypes_to_vcf(self, genotypes, pred_format=\"GT:GP:DS\"):\n",
    "        \"\"\"Convert genotypes to VCF format\"\"\"\n",
    "        new_vcf = self.target_set.copy()\n",
    "        new_vcf[new_vcf.columns[self.target_sample_value_index - 1:]] = genotypes\n",
    "        new_vcf[\"FORMAT\"] = pred_format\n",
    "        new_vcf[\"QUAL\"] = \".\"\n",
    "        new_vcf[\"FILTER\"] = \".\"\n",
    "        new_vcf[\"INFO\"] = \"IMPUTED\"\n",
    "        return new_vcf\n",
    "\n",
    "    def preds_to_genotypes(self, predictions: Union[str, np.ndarray]) -> pd.DataFrame:\n",
    "        \"\"\"Convert predictions to genotypes\"\"\"\n",
    "        if isinstance(predictions, str):\n",
    "            preds = np.load(predictions)\n",
    "        else:\n",
    "            preds = predictions\n",
    "\n",
    "        target_df = self.target_set.copy()\n",
    "        if not self.is_phased:\n",
    "            target_df[\n",
    "                target_df.columns[self.target_sample_value_index - 1:]] = self.__convert_unphased_probs_to_genotypes(\n",
    "                preds).T\n",
    "        elif self.target_is_hap:\n",
    "            target_df[\n",
    "                target_df.columns[self.target_sample_value_index - 1:]] = self.__convert_hap_probs_to_hap_genotypes(\n",
    "                preds).T\n",
    "        else:\n",
    "            pred_format = \"GT:GP:DS\" if preds.shape[-1] == 2 else \"GT\"\n",
    "            target_df = self.__convert_genotypes_to_vcf(self.__convert_hap_probs_to_diploid_genotypes(preds).T,\n",
    "                                                        pred_format)\n",
    "        return target_df\n",
    "\n",
    "    def write_ligated_results_to_file(self, df: pd.DataFrame, file_name: str, compress=True) -> str:\n",
    "        \"\"\"Write results to file\"\"\"\n",
    "        to_write_format = self.ref_file_extension\n",
    "        file_path = f\"{file_name}.{to_write_format}.gz\" if compress else f\"{file_name}.{to_write_format}\"\n",
    "\n",
    "        with gzip.open(file_path, 'wt') if compress else open(file_path, 'wt') as f_out:\n",
    "            # Write headers\n",
    "            if self.ref_file_extension == \"vcf\":\n",
    "                f_out.write(\n",
    "                    \"\\n\".join(self.__get_headers_for_output(contain_probs=\"GP\" in df[\"FORMAT\"].values[0])) + \"\\n\")\n",
    "            else:\n",
    "                f_out.write(\"\\n\".join(self.ref_n_header_lines))\n",
    "\n",
    "        # Append data\n",
    "        df.to_csv(file_path, sep=self.ref_separator, mode='a', index=False)\n",
    "        return file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbb96506",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenomicDataset(Dataset):\n",
    "    \"\"\"Dataset class for genomic data with masking for training\"\"\"\n",
    "\n",
    "    def __init__(self, data, targets, seq_depth, offset_before=0, offset_after=0,\n",
    "                 training=True, masking_rates=(0.5, 0.99)):\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "        self.seq_depth = seq_depth\n",
    "        self.offset_before = offset_before\n",
    "        self.offset_after = offset_after\n",
    "        self.training = training\n",
    "        self.masking_rates = masking_rates\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data[idx].copy()\n",
    "        y = self.targets[idx]\n",
    "\n",
    "        if self.training:\n",
    "            # Apply masking\n",
    "            seq_len = len(x)\n",
    "            masking_rate = np.random.uniform(*self.masking_rates)\n",
    "            mask_size = int(seq_len * masking_rate)\n",
    "            mask_indices = np.random.choice(seq_len, mask_size, replace=False)\n",
    "            x[mask_indices] = self.seq_depth - 1  # Missing value token\n",
    "\n",
    "        # Convert to one-hot\n",
    "        x_onehot = np.eye(self.seq_depth)[x]\n",
    "        y_onehot = np.eye(self.seq_depth - 1)[y]\n",
    "\n",
    "        return torch.FloatTensor(x_onehot), torch.FloatTensor(y_onehot)\n",
    "\n",
    "class ImputationDataset(Dataset):\n",
    "    \"\"\"Dataset for imputation (no masking needed)\"\"\"\n",
    "\n",
    "    def __init__(self, data, seq_depth):\n",
    "        self.data = data\n",
    "        self.seq_depth = seq_depth\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data[idx]\n",
    "        # Convert to one-hot without masking\n",
    "        x_onehot = np.eye(self.seq_depth)[x]\n",
    "        return torch.FloatTensor(x_onehot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c86e007",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac21e2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiMambaBlock(nn.Module):\n",
    "    \"\"\"Bidirectional Mamba block for genomic sequence processing\"\"\"\n",
    "\n",
    "    def __init__(self, d_model, d_state=16, d_conv=4, expand=2):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "\n",
    "        # Forward and backward Mamba blocks\n",
    "        self.mamba_forward = Mamba2(\n",
    "            d_model=d_model,\n",
    "            d_state=d_state,\n",
    "            d_conv=d_conv,\n",
    "            expand=expand\n",
    "        )\n",
    "\n",
    "        self.mamba_backward = Mamba2(\n",
    "            d_model=d_model,\n",
    "            d_state=d_state,\n",
    "            d_conv=d_conv,\n",
    "            expand=expand\n",
    "        )\n",
    "\n",
    "        # Layer normalization\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "\n",
    "        # FFN\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(d_model * 2, d_model * 4),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(d_model * 4, d_model),\n",
    "            nn.GELU()\n",
    "        )\n",
    "\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, seq_len, d_model)\n",
    "        residual = x\n",
    "\n",
    "        # Bidirectional processing\n",
    "        x_norm = self.norm1(x)\n",
    "\n",
    "        # Forward direction\n",
    "        forward_out = self.mamba_forward(x_norm)\n",
    "\n",
    "        # Backward direction (flip sequence)\n",
    "        x_backward = torch.flip(x_norm, dims=[1])\n",
    "        backward_out = self.mamba_backward(x_backward)\n",
    "        backward_out = torch.flip(backward_out, dims=[1])\n",
    "\n",
    "        # Concatenate bidirectional outputs\n",
    "        bi_out = torch.cat([forward_out, backward_out], dim=-1)\n",
    "\n",
    "        # FFN\n",
    "        ffn_out = self.ffn(bi_out)\n",
    "        ffn_out = self.dropout(ffn_out)\n",
    "\n",
    "        # Residual connection\n",
    "        out = self.norm2(residual + ffn_out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    \"\"\"Convolutional block for local pattern extraction\"\"\"\n",
    "\n",
    "    def __init__(self, d_model):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "\n",
    "        self.conv1 = nn.Conv1d(d_model, d_model, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(d_model, d_model, kernel_size=5, padding=2)\n",
    "        self.conv3 = nn.Conv1d(d_model, d_model, kernel_size=7, padding=3)\n",
    "\n",
    "        self.conv_large1 = nn.Conv1d(d_model, d_model, kernel_size=7, padding=3)\n",
    "        self.conv_large2 = nn.Conv1d(d_model, d_model, kernel_size=15, padding=7)\n",
    "\n",
    "        self.conv_final = nn.Conv1d(d_model, d_model, kernel_size=3, padding=1)\n",
    "        self.conv_reduce = nn.Conv1d(d_model, d_model, kernel_size=1)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(d_model)\n",
    "        self.bn2 = nn.BatchNorm1d(d_model)\n",
    "\n",
    "        self.gelu = nn.GELU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, seq_len, d_model)\n",
    "        x = x.transpose(1, 2)  # (batch, d_model, seq_len)\n",
    "\n",
    "        xa = self.gelu(self.conv1(x))\n",
    "\n",
    "        xb = self.gelu(self.conv2(xa))\n",
    "        xb = self.gelu(self.conv3(xb))\n",
    "\n",
    "        xc = self.gelu(self.conv_large1(xa))\n",
    "        xc = self.gelu(self.conv_large2(xc))\n",
    "\n",
    "        xa = xb + xc\n",
    "        xa = self.gelu(self.conv_final(xa))\n",
    "        xa = self.bn1(xa)\n",
    "        xa = self.gelu(self.conv_reduce(xa))\n",
    "        xa = self.bn2(xa)\n",
    "        xa = self.gelu(xa)\n",
    "\n",
    "        return xa.transpose(1, 2)  # (batch, seq_len, d_model)\n",
    "\n",
    "class CrossAttentionLayer(nn.Module):\n",
    "    \"\"\"Cross attention for integrating local and global features\"\"\"\n",
    "    def __init__(self, d_model, n_heads=8):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.n_heads = n_heads\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "\n",
    "        self.cross_attention = nn.MultiheadAttention(\n",
    "            embed_dim=d_model,\n",
    "            num_heads=n_heads,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model // 2),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(d_model // 2, d_model),\n",
    "            nn.GELU()\n",
    "        )\n",
    "\n",
    "    def forward(self, local_repr, global_repr, start_offset=0, end_offset=0):\n",
    "        local_norm = self.norm1(local_repr)\n",
    "        global_norm = self.norm2(global_repr)\n",
    "\n",
    "        # Apply offsets\n",
    "        if start_offset > 0 or end_offset > 0:\n",
    "            query = local_norm[:, start_offset:local_norm.shape[1] - end_offset]\n",
    "        else:\n",
    "            query = local_norm\n",
    "\n",
    "        key = value = global_norm\n",
    "\n",
    "        # Cross attention\n",
    "        attn_output, _ = self.cross_attention(query, key, value)\n",
    "\n",
    "        # Pad attn_output back to original length if offsets were applied\n",
    "        if start_offset > 0 or end_offset > 0:\n",
    "            pad_left = start_offset\n",
    "            pad_right = end_offset\n",
    "            attn_output = torch.nn.functional.pad(attn_output, (0, 0, pad_left, pad_right), mode='constant', value=0)\n",
    "\n",
    "        # Skip connection\n",
    "        attn_output = attn_output + local_norm  # Changed from +query to +local_norm\n",
    "\n",
    "        # FFN\n",
    "        attn_output = self.norm3(attn_output)\n",
    "        ffn_output = self.ffn(attn_output)\n",
    "        output = ffn_output + attn_output\n",
    "\n",
    "        return output\n",
    "\n",
    "class Mamba2CrossBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    用 Mamba2Simple 替代 MultiheadAttention 的交叉块。\n",
    "    接口与原来 CrossAttentionLayer 保持一致，可直接替换。\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        d_model,\n",
    "        d_state=64,\n",
    "        d_conv=4,\n",
    "        expand=2,\n",
    "        headdim=128,\n",
    "        ngroups=1,\n",
    "        chunk_size=256,\n",
    "        dropout=0.0,\n",
    "        device=None,\n",
    "        dtype=None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "\n",
    "        # 1. 归一化\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "\n",
    "        # 2. Mamba2Simple 作为交叉建模核心\n",
    "        self.ssd = Mamba2Block(\n",
    "            d_model=d_model,\n",
    "            d_state=d_state,\n",
    "            d_conv=d_conv,\n",
    "            expand=expand,\n",
    "            headdim=headdim,\n",
    "            ngroups=ngroups,\n",
    "            chunk_size=chunk_size,\n",
    "            use_mem_eff_path=True,\n",
    "            device=device,\n",
    "            dtype=dtype,\n",
    "        )\n",
    "\n",
    "        # 3. FFN 保持不变\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model // 2),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(d_model // 2, d_model),\n",
    "        )\n",
    "\n",
    "    def forward(self, local_repr, global_repr, start_offset=0, end_offset=0):\n",
    "        \"\"\"\n",
    "        local_repr: [B, L, D]\n",
    "        global_repr: [B, G, D]\n",
    "        输出:       [B, L, D]  （长度与 local_repr 保持一致）\n",
    "        \"\"\"\n",
    "        B, L, D = local_repr.shape\n",
    "\n",
    "        # 1. 归一化\n",
    "        local_norm  = self.norm1(local_repr)\n",
    "        global_norm = self.norm2(global_repr)\n",
    "\n",
    "        # 2. 如果用了 offset，先截断 query 长度\n",
    "        if start_offset > 0 or end_offset > 0:\n",
    "            query = local_norm[:, start_offset:L - end_offset]\n",
    "        else:\n",
    "            query = local_norm\n",
    "\n",
    "        # 3. 拼接：global 在前，local 在后，让 SSD 扫描时 local 能看到 global\n",
    "        x = torch.cat([global_norm, query], dim=1)   # [B, G + L', D]\n",
    "        x = self.ssd(x)                              # [B, G + L', D]\n",
    "        x = x[:, global_norm.shape[1]:, :]           # 只取 local 对应部分 [B, L', D]\n",
    "\n",
    "        # 4. pad 回原始长度（如果之前截断过）\n",
    "        if start_offset > 0 or end_offset > 0:\n",
    "            x = F.pad(x, (0, 0, start_offset, end_offset))  # [B, L, D]\n",
    "\n",
    "        # 5. 残差连接\n",
    "        x = x + local_norm\n",
    "\n",
    "        # 6. FFN\n",
    "        x = self.norm3(x)\n",
    "        x = self.ffn(x) + x\n",
    "\n",
    "        return x\n",
    "\n",
    "class GenoEmbedding(nn.Module):\n",
    "    \"\"\"Genomic embedding layer with positional encoding\"\"\"\n",
    "\n",
    "    def __init__(self, n_alleles, n_snps, d_model):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.n_alleles = n_alleles\n",
    "        self.n_snps = n_snps\n",
    "\n",
    "        # Allele embedding\n",
    "        self.allele_embedding = nn.Parameter(torch.randn(n_alleles, d_model))\n",
    "\n",
    "        # Positional embedding\n",
    "        self.position_embedding = nn.Embedding(n_snps, d_model)\n",
    "\n",
    "        # Initialize parameters\n",
    "        nn.init.xavier_uniform_(self.allele_embedding)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, seq_len, n_alleles) - one-hot encoded\n",
    "        batch_size, seq_len, _ = x.shape\n",
    "\n",
    "        # Allele embedding\n",
    "        embedded = torch.einsum('bsn,nd->bsd', x, self.allele_embedding)\n",
    "\n",
    "        # Positional embedding\n",
    "        positions = torch.arange(seq_len, device=x.device)\n",
    "        pos_emb = self.position_embedding(positions).unsqueeze(0)\n",
    "\n",
    "        return embedded + pos_emb\n",
    "\n",
    "class ChunkModule(nn.Module):\n",
    "    \"\"\"Single chunk processing module with BiMamba\"\"\"\n",
    "\n",
    "    def __init__(self, d_model, start_offset=0, end_offset=0, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.start_offset = start_offset\n",
    "        self.end_offset = end_offset\n",
    "\n",
    "        # BiMamba block\n",
    "        self.bimamba_block = BiMambaBlock(d_model)\n",
    "\n",
    "        # Convolutional blocks\n",
    "        self.conv_block1 = ConvBlock(d_model)\n",
    "        self.conv_block2 = ConvBlock(d_model)\n",
    "        self.conv_block3 = ConvBlock(d_model)\n",
    "\n",
    "        # Cross attention\n",
    "        # self.cross_attention = CrossAttentionLayer(d_model, n_heads)\n",
    "        self.cross_attention = Mamba2CrossBlock(\n",
    "            d_model=d_model,\n",
    "            d_state=64,\n",
    "            d_conv=4,\n",
    "            expand=2,\n",
    "            headdim=128,\n",
    "            ngroups=1,\n",
    "            chunk_size=256,\n",
    "        )\n",
    "\n",
    "        # Additional layers\n",
    "        self.dense = nn.Linear(d_model, d_model)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.gelu = nn.GELU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # BiMamba processing\n",
    "        xa0 = self.bimamba_block(x)\n",
    "\n",
    "        # First conv block\n",
    "        xa = self.conv_block1(xa0)\n",
    "        xa_skip = self.conv_block2(xa)\n",
    "\n",
    "        # Dense layer\n",
    "        xa = self.gelu(self.dense(xa))\n",
    "        xa = self.conv_block2(xa)\n",
    "\n",
    "        # Cross attention\n",
    "        xa = self.cross_attention(xa, xa0, self.start_offset, self.end_offset)\n",
    "        xa = self.dropout(xa)\n",
    "\n",
    "        # Final conv block\n",
    "        xa = self.conv_block3(xa)\n",
    "\n",
    "        # Concatenate with skip connection\n",
    "        xa = torch.cat([xa_skip, xa], dim=-1)\n",
    "\n",
    "        return xa\n",
    "\n",
    "class EvoFill(nn.Module):\n",
    "    \"\"\"Main BiMamba model for genomic imputation\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 d_model,\n",
    "                 chunk_size=2048,\n",
    "                 chunk_overlap=64,\n",
    "                 offset_before=0,\n",
    "                 offset_after=0,\n",
    "                 dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.chunk_size = chunk_size\n",
    "        self.chunk_overlap = chunk_overlap\n",
    "        self.offset_before = offset_before\n",
    "        self.offset_after = offset_after\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "        # Will be set during build\n",
    "        self.seq_len = None\n",
    "        self.n_alleles = None\n",
    "        self.embedding = None\n",
    "        self.chunk_modules = nn.ModuleList()\n",
    "        self.final_conv = None\n",
    "        self.output_conv = None\n",
    "\n",
    "    def build(self, seq_len, n_alleles):\n",
    "        \"\"\"Build the model with specific sequence length and allele count\"\"\"\n",
    "        self.seq_len = seq_len\n",
    "        self.n_alleles = n_alleles\n",
    "\n",
    "        # Embedding layer\n",
    "        self.embedding = GenoEmbedding(n_alleles, seq_len, self.d_model)\n",
    "\n",
    "        # Calculate chunks\n",
    "        chunk_starts = list(range(0, seq_len, self.chunk_size))\n",
    "        chunk_ends = [min(cs + self.chunk_size, seq_len) for cs in chunk_starts]\n",
    "        mask_starts = [max(0, cs - self.chunk_overlap) for cs in chunk_starts]\n",
    "        mask_ends = [min(ce + self.chunk_overlap, seq_len) for ce in chunk_ends]\n",
    "\n",
    "        # Create chunk modules\n",
    "        for i, cs in enumerate(chunk_starts):\n",
    "            start_offset = cs - mask_starts[i]\n",
    "            end_offset = mask_ends[i] - chunk_ends[i]\n",
    "\n",
    "            chunk_module = ChunkModule(\n",
    "                d_model=self.d_model,\n",
    "                start_offset=start_offset,\n",
    "                end_offset=end_offset,\n",
    "                dropout_rate=self.dropout_rate\n",
    "            )\n",
    "            self.chunk_modules.append(chunk_module)\n",
    "\n",
    "        # Store chunk information\n",
    "        self.chunk_starts = chunk_starts\n",
    "        self.chunk_ends = chunk_ends\n",
    "        self.mask_starts = mask_starts\n",
    "        self.mask_ends = mask_ends\n",
    "\n",
    "        # Final layers\n",
    "        self.final_conv = nn.Conv1d(self.d_model * 2, self.d_model // 2,\n",
    "                                    kernel_size=5, padding=2)\n",
    "        self.output_conv = nn.Conv1d(self.d_model // 2, n_alleles - 1,\n",
    "                                     kernel_size=5, padding=2)\n",
    "        # self.output_proj = nn.Linear(self.d_model * 2, n_alleles - 1)\n",
    "\n",
    "        self.gelu = nn.GELU()\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, seq_len, n_alleles)\n",
    "        if self.embedding is None:\n",
    "            raise RuntimeError(\"Model not built. Call build() first.\")\n",
    "\n",
    "        # Embedding\n",
    "        x_embedded = self.embedding(x)\n",
    "\n",
    "        # Process chunks\n",
    "        chunk_outputs = []\n",
    "        for i, chunk_module in enumerate(self.chunk_modules):\n",
    "            chunk_input = x_embedded[:, self.mask_starts[i]:self.mask_ends[i]]\n",
    "            chunk_output = chunk_module(chunk_input)\n",
    "            chunk_outputs.append(chunk_output)\n",
    "\n",
    "        # Concatenate chunks along sequence dimension\n",
    "        x_concat = torch.cat(chunk_outputs, dim=1)\n",
    "\n",
    "        # # Final processing\n",
    "        x_concat = x_concat.transpose(1, 2)  # (batch, features, seq_len)\n",
    "        x_final = self.gelu(self.final_conv(x_concat))\n",
    "        x_output = self.output_conv(x_final)\n",
    "        x_output = x_output.transpose(1, 2)  # (batch, seq_len, n_alleles-1)\n",
    "        # x_output = self.output_proj(x_concat) \n",
    "\n",
    "        # Apply offsets\n",
    "        if self.offset_before > 0 or self.offset_after > 0:\n",
    "            x_output = x_output[:, self.offset_before:self.seq_len - self.offset_after]\n",
    "        else:\n",
    "            x_output = x_output[:, :self.seq_len]\n",
    "\n",
    "        x_output = self.softmax(x_output)\n",
    "\n",
    "        return x_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f053a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 含缺失数据前向通过，输出形状: torch.Size([2, 5120, 3])\n"
     ]
    }
   ],
   "source": [
    "n_alleles = 4  # 包含missing\n",
    "model = EvoFill(\n",
    "    d_model=256,\n",
    "    chunk_size=5120,\n",
    "    chunk_overlap=64, \n",
    "    offset_before=0,\n",
    "    offset_after=0,\n",
    "    dropout_rate=0.1,\n",
    ").cuda()\n",
    "\n",
    "B, L = 2, 5120\n",
    "model.build(seq_len=L, n_alleles=n_alleles)\n",
    "model = model.cuda()  \n",
    "\n",
    "# 1. 生成输入\n",
    "x = torch.randint(0, n_alleles, (B, L)).long().cuda()   # {0,1,2,3} 3=missing\n",
    "\n",
    "# 2. -1 -> 3，并构造 one-hot（4 维）\n",
    "x_map = x.clone()\n",
    "x_onehot = torch.zeros(B, L, n_alleles, device='cuda')\n",
    "x_onehot.scatter_(2, x_map.unsqueeze(-1), 1)\n",
    "\n",
    "# 3. 前向\n",
    "with torch.no_grad():\n",
    "    probs = model(x_onehot)          # shape: (B,L,3)\n",
    "\n",
    "# 4. 简单校验\n",
    "assert torch.allclose(probs.sum(dim=-1), torch.ones(B, L, device='cuda'), atol=1e-5), \\\n",
    "    \"概率未归一\"\n",
    "print(\"✅ 含缺失数据前向通过，输出形状:\", probs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce8c794",
   "metadata": {},
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f6f2206",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImputationLoss(nn.Module):\n",
    "    \"\"\"Custom loss function for genomic imputation\"\"\"\n",
    "\n",
    "    def __init__(self, use_r2=True, \n",
    "                 use_focal=False, #  all dummy \n",
    "                 group_size=None,\n",
    "                 gamma=None,\n",
    "                 alpha=None,\n",
    "                 eps=None,\n",
    "                 use_gradnorm=None,\n",
    "                 gn_alpha=None,\n",
    "                 gn_lr_w=None,):\n",
    "        super().__init__()\n",
    "        self.use_r2_loss = use_r2\n",
    "        self.ce_loss = nn.CrossEntropyLoss(reduction='sum')\n",
    "        self.kl_loss = nn.KLDivLoss(reduction='sum')\n",
    "\n",
    "    def calculate_minimac_r2(self, pred_alt_allele_probs, gt_alt_af):\n",
    "        \"\"\"Calculate Minimac-style RÂ² metric\"\"\"\n",
    "        mask = torch.logical_or(torch.eq(gt_alt_af, 0.0), torch.eq(gt_alt_af, 1.0))\n",
    "        gt_alt_af = torch.where(mask, 0.5, gt_alt_af)\n",
    "        denom = gt_alt_af * (1.0 - gt_alt_af)\n",
    "        denom = torch.where(denom < 0.01, 0.01, denom)\n",
    "        r2 = torch.mean(torch.square(pred_alt_allele_probs - gt_alt_af), dim=0) / denom\n",
    "        r2 = torch.where(mask, torch.zeros_like(r2), r2)\n",
    "        return r2\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        y_true = y_true.float()\n",
    "\n",
    "        # Convert to proper format for losses\n",
    "        y_true_ce = torch.argmax(y_true, dim=-1)  # For CrossEntropy\n",
    "        y_pred_log = torch.log(y_pred + 1e-8)  # For KL divergence\n",
    "\n",
    "        # Basic losses\n",
    "        ce_loss = self.ce_loss(y_pred.view(-1, y_pred.size(-1)), y_true_ce.view(-1))\n",
    "        kl_loss = self.kl_loss(y_pred_log.view(-1, y_pred.size(-1)),\n",
    "                               y_true.view(-1, y_true.size(-1)))\n",
    "\n",
    "        total_loss = ce_loss + kl_loss\n",
    "\n",
    "        if self.use_r2_loss:\n",
    "            batch_size = y_true.size(0)\n",
    "            group_size = 4\n",
    "            num_full_groups = batch_size // group_size\n",
    "\n",
    "            if num_full_groups > 0:\n",
    "                y_true_grouped = y_true[:num_full_groups * group_size].view(\n",
    "                    num_full_groups, group_size, *y_true.shape[1:])\n",
    "                y_pred_grouped = y_pred[:num_full_groups * group_size].view(\n",
    "                    num_full_groups, group_size, *y_pred.shape[1:])\n",
    "\n",
    "                r2_loss = 0.0\n",
    "                for i in range(num_full_groups):\n",
    "                    gt_alt_af = torch.count_nonzero(\n",
    "                        torch.argmax(y_true_grouped[i], dim=-1), dim=0\n",
    "                    ).float() / group_size\n",
    "\n",
    "                    pred_alt_allele_probs = torch.sum(y_pred_grouped[i][:, :, 1:], dim=-1)\n",
    "                    r2_loss += -torch.sum(self.calculate_minimac_r2(\n",
    "                        pred_alt_allele_probs, gt_alt_af)) * group_size\n",
    "\n",
    "                total_loss += r2_loss\n",
    "\n",
    "        return total_loss, None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d0ff63",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb648d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_similar_rows(array):\n",
    "    \"\"\"Remove duplicate haploids from training set\"\"\"\n",
    "    print(\"Finding duplicate haploids in training set.\")\n",
    "    unique_array = np.unique(array, axis=0)\n",
    "    print(f\"Removed {len(array) - len(unique_array)} rows. {len(unique_array)} training samples remaining.\")\n",
    "    return unique_array\n",
    "\n",
    "def create_directories(save_dir, models_dir=\"models\", outputs=\"out\") -> None:\n",
    "    \"\"\"Create necessary directories\"\"\"\n",
    "    for dd in [save_dir, f\"{save_dir}/{models_dir}\", f\"{save_dir}/{outputs}\"]:\n",
    "        if not os.path.exists(dd):\n",
    "            os.makedirs(dd)\n",
    "\n",
    "def clear_dir(path) -> None:\n",
    "    \"\"\"Clear directory if it exists\"\"\"\n",
    "    if os.path.exists(path):\n",
    "        shutil.rmtree(path)\n",
    "\n",
    "def load_chunk_info(save_dir, break_points):\n",
    "    \"\"\"Load chunk training status information\"\"\"\n",
    "    chunk_info = {ww: False for ww in list(range(len(break_points) - 1))}\n",
    "    if os.path.isfile(f\"{save_dir}/models/chunks_info.json\"):\n",
    "        with open(f\"{save_dir}/models/chunks_info.json\", 'r') as f:\n",
    "            loaded_chunks_info = json.load(f)\n",
    "            if isinstance(loaded_chunks_info, dict) and len(loaded_chunks_info) == len(chunk_info):\n",
    "                pprint(\"Resuming the training...\")\n",
    "                chunk_info = {int(k): v for k, v in loaded_chunks_info.items()}\n",
    "    return chunk_info\n",
    "\n",
    "def save_chunk_status(save_dir, chunk_info) -> None:\n",
    "    \"\"\"Save chunk training status information\"\"\"\n",
    "    with open(f\"{save_dir}/models/chunks_info.json\", \"w\") as outfile:\n",
    "        json.dump(chunk_info, outfile)\n",
    "\n",
    "def create_model(args, seq_len, n_alleles):\n",
    "    \"\"\"Create BiMamba model\"\"\"\n",
    "    model = EvoFill(\n",
    "        d_model=args.embed_dim,\n",
    "        chunk_size=args.cs,\n",
    "        chunk_overlap=args.co,\n",
    "        offset_before=getattr(args, 'offset_before', 0),\n",
    "        offset_after=getattr(args, 'offset_after', 0),\n",
    "        dropout_rate=0.1\n",
    "    )\n",
    "\n",
    "    # Build the model\n",
    "    model.build(seq_len, n_alleles)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c302bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAF_BINS = [(0.00, 0.05), (0.05, 0.10), (0.10, 0.20),\n",
    "            (0.20, 0.30), (0.30, 0.40), (0.40, 0.50)]\n",
    "\n",
    "def precompute_maf(gts_np, mask_int=-1):\n",
    "    \"\"\"\n",
    "    gts_np: (N, L)  int64\n",
    "    return:\n",
    "        maf: (L,) float32\n",
    "        bin_cnt: list[int] 长度 6，对应 6 个 bin 的位点数量\n",
    "    \"\"\"\n",
    "    L = gts_np.shape[1]\n",
    "    maf = np.zeros(L, dtype=np.float32)\n",
    "    bin_cnt = [0] * 6\n",
    "\n",
    "    for l in range(L):\n",
    "        alleles = gts_np[:, l]\n",
    "        alleles = alleles[alleles != mask_int]   # 去掉缺失\n",
    "        if alleles.size == 0:\n",
    "            maf[l] = 0.0\n",
    "            continue\n",
    "\n",
    "        uniq, cnt = np.unique(alleles, return_counts=True)\n",
    "        total = cnt.sum()\n",
    "        freq = cnt / total\n",
    "        freq[::-1].sort()\n",
    "        maf_val = freq[1] if len(freq) > 1 else 0.0\n",
    "        maf[l] = maf_val\n",
    "\n",
    "        # 统计 bin\n",
    "        for i, (lo, hi) in enumerate(MAF_BINS):\n",
    "            if lo <= maf_val < hi:\n",
    "                bin_cnt[i] += 1\n",
    "                break\n",
    "\n",
    "    return maf, bin_cnt\n",
    "\n",
    "def imputation_maf_accuracy_epoch(all_logits, all_gts, global_maf, mask=None):\n",
    "    \"\"\"\n",
    "    all_logits: (N, L, C)\n",
    "    all_gts:    (N, L, C) one-hot\n",
    "    global_maf: (L,)\n",
    "    mask:       (N, L) 或 None\n",
    "    return:     list[float] 长度 6\n",
    "    \"\"\"\n",
    "    # 1. 预测 vs 真实\n",
    "    all_gts = all_gts.argmax(dim=-1)      # (N, L)\n",
    "    preds   = all_logits.argmax(dim=-1)   # (N, L)\n",
    "\n",
    "    # 2. 如果没有外部 mask，就默认全 1\n",
    "    if mask is None:\n",
    "        mask = torch.ones_like(all_gts, dtype=torch.bool)   # (N, L)\n",
    "    correct = (preds == all_gts) & mask                   # (N, L)\n",
    "\n",
    "    # 3. MAF 条件 -> (1, L) 再广播到 (N, L)\n",
    "    maf = global_maf.unsqueeze(0)                         # (1, L)\n",
    "\n",
    "    # 4. 分 bin 计算\n",
    "    accs = []\n",
    "    for lo, hi in MAF_BINS:\n",
    "        maf_bin = mask & (maf >= lo) & (maf < hi)                # (1, L)\n",
    "        n_cor = (correct & maf_bin).sum()\n",
    "        n_tot = maf_bin.sum()\n",
    "        accs.append(100*(n_cor / n_tot).item() if n_tot > 0 else 0.0)\n",
    "    return accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d21fb7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Reading the file...\n",
      "2404 diploid samples with 99314 variants found!\n",
      "DEBUG: Unique genotypes in dataset: ['0|0' '0|1' '1|0' '1|1']...\n",
      "DEBUG: self.genotype_vals: ['0|0' '0|1' '1|0' '1|1']\n",
      "DEBUG: self.alleles: ['0' '1']\n",
      "DEBUG: is_phased: True\n",
      "DEBUG: hap_map: {'0': 0, '1': 1, '.': 2}\n",
      "DEBUG: self.SEQ_DEPTH: 3\n"
     ]
    }
   ],
   "source": [
    "# ---------------- 以下即命令行参数对应的行内变量 ----------------\n",
    "mode                 = 'train'\n",
    "restart_training     = True          # 对应命令行 1\n",
    "ref                  = \"/home/qmtang/GitHub/STICI-HPC/data/training_sets/ALL.chr22.training.samples.100k.any.type.0.01.maf.variants.vcf.gz\"\n",
    "tihp                 = True          # 对应命令行 1\n",
    "which_chunk          = -1            # All chunkss\n",
    "save_dir             = '/home/qmtang/mnt_qmtang/EvoFill/data/251016_ver0_chr22'\n",
    "co                   = 64            # 64 in STICI\n",
    "cs                   = 8192          # 2048 in STICI\n",
    "sites_per_model      = 65536        # 10240 in STICI\n",
    "max_mr               = 0.7\n",
    "min_mr               = 0.3\n",
    "epochs               = 100\n",
    "embed_dim            = 64            # 128 in STICI\n",
    "lr                   = 0.001\n",
    "weight_decay         = 1e-5\n",
    "batch_size_per_gpu   = 8\n",
    "use_r2               = True\n",
    "earlystop_patience   = 9\n",
    "verbose              = 1\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "# 组装成 Namespace\n",
    "args = Namespace(\n",
    "    restart_training=restart_training,\n",
    "    ref=ref,\n",
    "    tihp=tihp,\n",
    "    which_chunk=which_chunk,\n",
    "    save_dir=save_dir,\n",
    "    co=co,\n",
    "    cs=cs,\n",
    "    sites_per_model=sites_per_model,\n",
    "    max_mr=max_mr,\n",
    "    min_mr=min_mr,\n",
    "    epochs=epochs,\n",
    "    embed_dim=embed_dim,\n",
    "    lr=lr,\n",
    "    weight_decay=weight_decay,\n",
    "    batch_size_per_gpu=batch_size_per_gpu,\n",
    "    use_r2=use_r2,\n",
    "    earlystop_patience=earlystop_patience,\n",
    "    verbose=verbose,\n",
    ")\n",
    "\n",
    "assert args.max_mr > 0\n",
    "assert args.min_mr > 0\n",
    "assert args.max_mr >= args.min_mr\n",
    "\n",
    "# Setup device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Create directories\n",
    "create_directories(args.save_dir)\n",
    "with open(f\"{args.save_dir}/commandline_args.json\", 'w') as f:\n",
    "    json.dump(vars(args), f, indent=4)\n",
    "\n",
    "# Load data\n",
    "dr = DataReader()\n",
    "dr.assign_training_set(\n",
    "    file_path=args.ref,\n",
    "    target_is_gonna_be_phased_or_haps=args.tihp,\n",
    "    variants_as_columns=getattr(args, 'ref_vac', False),\n",
    "    delimiter=getattr(args, 'ref_sep', None),\n",
    "    file_format=getattr(args, 'ref_file_format', 'infer'),\n",
    "    first_column_is_index=getattr(args, 'ref_fcai', True),\n",
    "    comments=getattr(args, 'ref_comment', '##')\n",
    ")\n",
    "\n",
    "# Split data for validation\n",
    "n_samples = dr.get_ref_set(0, 1).shape[0]\n",
    "val_n_samples = args.batch_size_per_gpu * getattr(args, 'val_n_batches', 8)\n",
    "x_train_indices, x_valid_indices = train_test_split(\n",
    "    range(n_samples),\n",
    "    test_size=val_n_samples,\n",
    "    random_state=getattr(args, 'random_seed', 3047),\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Process chunks\n",
    "break_points = list(np.arange(0, dr.VARIANT_COUNT, args.sites_per_model)) + [dr.VARIANT_COUNT]\n",
    "chunks_done = load_chunk_info(args.save_dir, break_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ee4dea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on chunk 1/2\n",
      "Data shape: (4808, 65664)\n",
      "Finding duplicate haploids in training set.\n",
      "Removed 0 rows. 4744 training samples remaining.\n",
      "Chunk MAF-bin counts: [26859, 9314, 10413, 6899, 6055, 5992]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 1/100, Train Loss: 295609.4848, Val Loss: 296327.9570\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 97.57 97.92\n",
      "(0.05, 0.10)   9314 92.86 93.73\n",
      "(0.10, 0.20)  10413 86.00 87.08\n",
      "(0.20, 0.30)   6899 77.20 78.01\n",
      "(0.30, 0.40)   6055 69.00 71.46\n",
      "(0.40, 0.50)   5992 64.41 68.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 2/100, Train Loss: 239563.2331, Val Loss: 227306.3887\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 97.73 98.07\n",
      "(0.05, 0.10)   9314 93.73 94.63\n",
      "(0.10, 0.20)  10413 88.13 89.23\n",
      "(0.20, 0.30)   6899 81.20 82.64\n",
      "(0.30, 0.40)   6055 75.96 78.54\n",
      "(0.40, 0.50)   5992 72.79 76.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 3/100, Train Loss: 201804.9939, Val Loss: 189574.9902\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 97.81 98.18\n",
      "(0.05, 0.10)   9314 94.22 95.09\n",
      "(0.10, 0.20)  10413 89.63 90.86\n",
      "(0.20, 0.30)   6899 83.80 84.98\n",
      "(0.30, 0.40)   6055 80.25 82.10\n",
      "(0.40, 0.50)   5992 77.93 80.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 4/100, Train Loss: 172447.0639, Val Loss: 157039.9453\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 97.85 98.28\n",
      "(0.05, 0.10)   9314 94.69 95.74\n",
      "(0.10, 0.20)  10413 90.85 92.06\n",
      "(0.20, 0.30)   6899 85.67 87.39\n",
      "(0.30, 0.40)   6055 83.23 85.46\n",
      "(0.40, 0.50)   5992 81.98 84.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 5/100, Train Loss: 150323.7915, Val Loss: 130741.6641\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 97.93 98.38\n",
      "(0.05, 0.10)   9314 95.13 96.24\n",
      "(0.10, 0.20)  10413 91.66 93.19\n",
      "(0.20, 0.30)   6899 87.30 89.28\n",
      "(0.30, 0.40)   6055 85.45 87.83\n",
      "(0.40, 0.50)   5992 84.82 87.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 6/100, Train Loss: 134280.2834, Val Loss: 119666.8320\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 98.01 98.44\n",
      "(0.05, 0.10)   9314 95.48 96.54\n",
      "(0.10, 0.20)  10413 92.42 93.79\n",
      "(0.20, 0.30)   6899 88.42 90.20\n",
      "(0.30, 0.40)   6055 86.86 88.81\n",
      "(0.40, 0.50)   5992 86.41 88.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 7/100, Train Loss: 118863.0824, Val Loss: 101801.0664\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 98.07 98.53\n",
      "(0.05, 0.10)   9314 95.78 96.87\n",
      "(0.10, 0.20)  10413 93.01 94.42\n",
      "(0.20, 0.30)   6899 89.41 91.37\n",
      "(0.30, 0.40)   6055 88.28 90.60\n",
      "(0.40, 0.50)   5992 88.24 90.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 8/100, Train Loss: 107080.7662, Val Loss: 91742.4648\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 98.14 98.56\n",
      "(0.05, 0.10)   9314 96.06 96.95\n",
      "(0.10, 0.20)  10413 93.52 94.96\n",
      "(0.20, 0.30)   6899 90.36 92.17\n",
      "(0.30, 0.40)   6055 89.39 91.53\n",
      "(0.40, 0.50)   5992 89.25 91.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 9/100, Train Loss: 97968.5088, Val Loss: 83211.2305\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 98.18 98.60\n",
      "(0.05, 0.10)   9314 96.29 97.20\n",
      "(0.10, 0.20)  10413 93.97 95.37\n",
      "(0.20, 0.30)   6899 91.02 92.68\n",
      "(0.30, 0.40)   6055 90.13 91.98\n",
      "(0.40, 0.50)   5992 89.89 91.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 10/100, Train Loss: 90602.4211, Val Loss: 74232.4277\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 98.25 98.68\n",
      "(0.05, 0.10)   9314 96.51 97.46\n",
      "(0.10, 0.20)  10413 94.36 95.79\n",
      "(0.20, 0.30)   6899 91.61 93.49\n",
      "(0.30, 0.40)   6055 90.70 92.74\n",
      "(0.40, 0.50)   5992 90.46 92.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 11/100, Train Loss: 84675.5249, Val Loss: 71100.6523\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 98.30 98.71\n",
      "(0.05, 0.10)   9314 96.67 97.48\n",
      "(0.10, 0.20)  10413 94.63 95.89\n",
      "(0.20, 0.30)   6899 92.02 93.65\n",
      "(0.30, 0.40)   6055 91.12 92.85\n",
      "(0.40, 0.50)   5992 90.87 92.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 12/100, Train Loss: 80127.4225, Val Loss: 64839.9336\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 98.33 98.77\n",
      "(0.05, 0.10)   9314 96.79 97.73\n",
      "(0.10, 0.20)  10413 94.83 96.24\n",
      "(0.20, 0.30)   6899 92.35 94.10\n",
      "(0.30, 0.40)   6055 91.46 93.48\n",
      "(0.40, 0.50)   5992 91.15 93.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 13/100, Train Loss: 75636.8581, Val Loss: 64043.7910\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 98.40 98.80\n",
      "(0.05, 0.10)   9314 96.93 97.76\n",
      "(0.10, 0.20)  10413 95.03 96.26\n",
      "(0.20, 0.30)   6899 92.63 94.15\n",
      "(0.30, 0.40)   6055 91.76 93.41\n",
      "(0.40, 0.50)   5992 91.44 93.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 14/100, Train Loss: 72508.1139, Val Loss: 59331.6621\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 98.44 98.85\n",
      "(0.05, 0.10)   9314 97.03 97.91\n",
      "(0.10, 0.20)  10413 95.16 96.42\n",
      "(0.20, 0.30)   6899 92.84 94.34\n",
      "(0.30, 0.40)   6055 91.98 93.79\n",
      "(0.40, 0.50)   5992 91.66 93.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 15/100, Train Loss: 69567.0352, Val Loss: 54365.5449\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 98.48 98.88\n",
      "(0.05, 0.10)   9314 97.13 97.98\n",
      "(0.10, 0.20)  10413 95.30 96.57\n",
      "(0.20, 0.30)   6899 93.00 94.56\n",
      "(0.30, 0.40)   6055 92.22 94.13\n",
      "(0.40, 0.50)   5992 91.86 93.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 16/100, Train Loss: 67144.5160, Val Loss: 52225.8320\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 98.51 98.91\n",
      "(0.05, 0.10)   9314 97.18 98.04\n",
      "(0.10, 0.20)  10413 95.40 96.68\n",
      "(0.20, 0.30)   6899 93.15 94.73\n",
      "(0.30, 0.40)   6055 92.36 94.29\n",
      "(0.40, 0.50)   5992 92.03 93.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 17/100, Train Loss: 64477.9364, Val Loss: 50094.2402\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 98.54 98.94\n",
      "(0.05, 0.10)   9314 97.24 98.11\n",
      "(0.10, 0.20)  10413 95.50 96.75\n",
      "(0.20, 0.30)   6899 93.29 94.81\n",
      "(0.30, 0.40)   6055 92.56 94.44\n",
      "(0.40, 0.50)   5992 92.28 94.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 18/100, Train Loss: 61837.3356, Val Loss: 49241.9375\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 98.57 98.94\n",
      "(0.05, 0.10)   9314 97.32 98.14\n",
      "(0.10, 0.20)  10413 95.61 96.78\n",
      "(0.20, 0.30)   6899 93.44 94.85\n",
      "(0.30, 0.40)   6055 92.75 94.48\n",
      "(0.40, 0.50)   5992 92.46 94.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 19/100, Train Loss: 59858.7230, Val Loss: 44341.2988\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 98.59 98.98\n",
      "(0.05, 0.10)   9314 97.37 98.24\n",
      "(0.10, 0.20)  10413 95.71 97.03\n",
      "(0.20, 0.30)   6899 93.56 95.16\n",
      "(0.30, 0.40)   6055 92.88 94.88\n",
      "(0.40, 0.50)   5992 92.62 94.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 20/100, Train Loss: 57624.7220, Val Loss: 42726.2168\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 98.62 99.02\n",
      "(0.05, 0.10)   9314 97.42 98.25\n",
      "(0.10, 0.20)  10413 95.81 97.09\n",
      "(0.20, 0.30)   6899 93.70 95.28\n",
      "(0.30, 0.40)   6055 93.02 94.97\n",
      "(0.40, 0.50)   5992 92.80 94.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 21/100, Train Loss: 56040.7366, Val Loss: 41513.4707\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 98.65 99.03\n",
      "(0.05, 0.10)   9314 97.47 98.29\n",
      "(0.10, 0.20)  10413 95.89 97.16\n",
      "(0.20, 0.30)   6899 93.80 95.36\n",
      "(0.30, 0.40)   6055 93.14 95.08\n",
      "(0.40, 0.50)   5992 92.89 94.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 22/100, Train Loss: 54557.6240, Val Loss: 39748.0977\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 98.68 99.05\n",
      "(0.05, 0.10)   9314 97.54 98.34\n",
      "(0.10, 0.20)  10413 95.98 97.25\n",
      "(0.20, 0.30)   6899 93.91 95.47\n",
      "(0.30, 0.40)   6055 93.26 95.16\n",
      "(0.40, 0.50)   5992 93.03 94.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 23/100, Train Loss: 52841.5636, Val Loss: 39173.2363\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 98.68 99.05\n",
      "(0.05, 0.10)   9314 97.57 98.32\n",
      "(0.10, 0.20)  10413 96.04 97.24\n",
      "(0.20, 0.30)   6899 94.00 95.48\n",
      "(0.30, 0.40)   6055 93.42 95.31\n",
      "(0.40, 0.50)   5992 93.11 94.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 24/100, Train Loss: 50996.9863, Val Loss: 38183.8164\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 98.71 99.08\n",
      "(0.05, 0.10)   9314 97.62 98.38\n",
      "(0.10, 0.20)  10413 96.13 97.33\n",
      "(0.20, 0.30)   6899 94.10 95.61\n",
      "(0.30, 0.40)   6055 93.55 95.41\n",
      "(0.40, 0.50)   5992 93.22 95.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 25/100, Train Loss: 49262.1411, Val Loss: 35747.3906\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 98.74 99.09\n",
      "(0.05, 0.10)   9314 97.67 98.44\n",
      "(0.10, 0.20)  10413 96.21 97.42\n",
      "(0.20, 0.30)   6899 94.21 95.71\n",
      "(0.30, 0.40)   6055 93.71 95.56\n",
      "(0.40, 0.50)   5992 93.31 95.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 26/100, Train Loss: 48038.7004, Val Loss: 34029.5957\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 98.75 99.11\n",
      "(0.05, 0.10)   9314 97.71 98.49\n",
      "(0.10, 0.20)  10413 96.27 97.51\n",
      "(0.20, 0.30)   6899 94.25 95.76\n",
      "(0.30, 0.40)   6055 93.81 95.65\n",
      "(0.40, 0.50)   5992 93.39 95.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 27/100, Train Loss: 47198.9708, Val Loss: 33648.5312\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 98.77 99.11\n",
      "(0.05, 0.10)   9314 97.73 98.46\n",
      "(0.10, 0.20)  10413 96.31 97.52\n",
      "(0.20, 0.30)   6899 94.32 95.83\n",
      "(0.30, 0.40)   6055 93.87 95.73\n",
      "(0.40, 0.50)   5992 93.44 95.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 28/100, Train Loss: 46397.6648, Val Loss: 33365.0234\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 98.78 99.13\n",
      "(0.05, 0.10)   9314 97.76 98.49\n",
      "(0.10, 0.20)  10413 96.36 97.55\n",
      "(0.20, 0.30)   6899 94.39 95.86\n",
      "(0.30, 0.40)   6055 93.93 95.74\n",
      "(0.40, 0.50)   5992 93.52 95.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 29/100, Train Loss: 45193.0173, Val Loss: 31626.1152\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 98.80 99.14\n",
      "(0.05, 0.10)   9314 97.78 98.52\n",
      "(0.10, 0.20)  10413 96.40 97.62\n",
      "(0.20, 0.30)   6899 94.45 95.99\n",
      "(0.30, 0.40)   6055 94.00 95.85\n",
      "(0.40, 0.50)   5992 93.57 95.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 30/100, Train Loss: 44357.9719, Val Loss: 32054.2227\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 98.81 99.13\n",
      "(0.05, 0.10)   9314 97.82 98.50\n",
      "(0.10, 0.20)  10413 96.45 97.59\n",
      "(0.20, 0.30)   6899 94.50 95.97\n",
      "(0.30, 0.40)   6055 94.06 95.81\n",
      "(0.40, 0.50)   5992 93.65 95.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 31/100, Train Loss: 43505.9880, Val Loss: 30342.2188\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 98.81 99.15\n",
      "(0.05, 0.10)   9314 97.83 98.56\n",
      "(0.10, 0.20)  10413 96.46 97.65\n",
      "(0.20, 0.30)   6899 94.55 96.06\n",
      "(0.30, 0.40)   6055 94.07 95.85\n",
      "(0.40, 0.50)   5992 93.66 95.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 32/100, Train Loss: 42135.5233, Val Loss: 28950.4023\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 98.84 99.17\n",
      "(0.05, 0.10)   9314 97.88 98.59\n",
      "(0.10, 0.20)  10413 96.55 97.71\n",
      "(0.20, 0.30)   6899 94.63 96.14\n",
      "(0.30, 0.40)   6055 94.18 96.00\n",
      "(0.40, 0.50)   5992 93.78 95.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 33/100, Train Loss: 41518.4672, Val Loss: 29880.1797\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 98.85 99.16\n",
      "(0.05, 0.10)   9314 97.89 98.56\n",
      "(0.10, 0.20)  10413 96.57 97.63\n",
      "(0.20, 0.30)   6899 94.69 96.06\n",
      "(0.30, 0.40)   6055 94.22 95.90\n",
      "(0.40, 0.50)   5992 93.80 95.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 34/100, Train Loss: 40960.6821, Val Loss: 27956.5430\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 98.86 99.17\n",
      "(0.05, 0.10)   9314 97.91 98.61\n",
      "(0.10, 0.20)  10413 96.60 97.77\n",
      "(0.20, 0.30)   6899 94.72 96.27\n",
      "(0.30, 0.40)   6055 94.24 96.03\n",
      "(0.40, 0.50)   5992 93.86 95.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 35/100, Train Loss: 40285.6516, Val Loss: 27213.9102\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 98.87 99.20\n",
      "(0.05, 0.10)   9314 97.93 98.64\n",
      "(0.10, 0.20)  10413 96.62 97.79\n",
      "(0.20, 0.30)   6899 94.77 96.20\n",
      "(0.30, 0.40)   6055 94.29 96.08\n",
      "(0.40, 0.50)   5992 93.90 95.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 36/100, Train Loss: 39586.2260, Val Loss: 27171.3555\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 98.88 99.20\n",
      "(0.05, 0.10)   9314 97.95 98.65\n",
      "(0.10, 0.20)  10413 96.65 97.80\n",
      "(0.20, 0.30)   6899 94.80 96.30\n",
      "(0.30, 0.40)   6055 94.32 96.10\n",
      "(0.40, 0.50)   5992 93.94 95.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 37/100, Train Loss: 38942.8162, Val Loss: 26231.6562\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 98.89 99.21\n",
      "(0.05, 0.10)   9314 97.97 98.62\n",
      "(0.10, 0.20)  10413 96.69 97.84\n",
      "(0.20, 0.30)   6899 94.85 96.32\n",
      "(0.30, 0.40)   6055 94.37 96.15\n",
      "(0.40, 0.50)   5992 93.99 95.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 38/100, Train Loss: 38153.4020, Val Loss: 26121.6152\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 98.91 99.22\n",
      "(0.05, 0.10)   9314 97.98 98.68\n",
      "(0.10, 0.20)  10413 96.72 97.85\n",
      "(0.20, 0.30)   6899 94.89 96.37\n",
      "(0.30, 0.40)   6055 94.41 96.12\n",
      "(0.40, 0.50)   5992 94.02 95.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 39/100, Train Loss: 37578.4324, Val Loss: 25004.0449\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 98.91 99.22\n",
      "(0.05, 0.10)   9314 98.01 98.69\n",
      "(0.10, 0.20)  10413 96.76 97.90\n",
      "(0.20, 0.30)   6899 94.92 96.44\n",
      "(0.30, 0.40)   6055 94.44 96.23\n",
      "(0.40, 0.50)   5992 94.06 95.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 40/100, Train Loss: 36918.2299, Val Loss: 25277.5078\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 98.92 99.22\n",
      "(0.05, 0.10)   9314 98.03 98.67\n",
      "(0.10, 0.20)  10413 96.80 97.88\n",
      "(0.20, 0.30)   6899 94.97 96.37\n",
      "(0.30, 0.40)   6055 94.49 96.18\n",
      "(0.40, 0.50)   5992 94.10 95.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 41/100, Train Loss: 37237.2215, Val Loss: 25763.3574\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 98.92 99.21\n",
      "(0.05, 0.10)   9314 98.02 98.65\n",
      "(0.10, 0.20)  10413 96.79 97.89\n",
      "(0.20, 0.30)   6899 94.96 96.35\n",
      "(0.30, 0.40)   6055 94.48 96.16\n",
      "(0.40, 0.50)   5992 94.12 95.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 42/100, Train Loss: 36400.1615, Val Loss: 24520.0566\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 98.94 99.23\n",
      "(0.05, 0.10)   9314 98.05 98.72\n",
      "(0.10, 0.20)  10413 96.81 97.93\n",
      "(0.20, 0.30)   6899 95.01 96.52\n",
      "(0.30, 0.40)   6055 94.52 96.25\n",
      "(0.40, 0.50)   5992 94.15 95.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 43/100, Train Loss: 35760.0408, Val Loss: 23892.3574\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 98.95 99.23\n",
      "(0.05, 0.10)   9314 98.08 98.72\n",
      "(0.10, 0.20)  10413 96.85 97.96\n",
      "(0.20, 0.30)   6899 95.04 96.49\n",
      "(0.30, 0.40)   6055 94.57 96.27\n",
      "(0.40, 0.50)   5992 94.20 96.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 44/100, Train Loss: 34933.5639, Val Loss: 23254.3535\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 98.97 99.26\n",
      "(0.05, 0.10)   9314 98.10 98.71\n",
      "(0.10, 0.20)  10413 96.89 97.98\n",
      "(0.20, 0.30)   6899 95.10 96.56\n",
      "(0.30, 0.40)   6055 94.62 96.33\n",
      "(0.40, 0.50)   5992 94.25 96.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 45/100, Train Loss: 34433.7395, Val Loss: 23358.0664\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 98.96 99.25\n",
      "(0.05, 0.10)   9314 98.09 98.71\n",
      "(0.10, 0.20)  10413 96.89 97.98\n",
      "(0.20, 0.30)   6899 95.10 96.55\n",
      "(0.30, 0.40)   6055 94.62 96.31\n",
      "(0.40, 0.50)   5992 94.26 96.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 46/100, Train Loss: 34374.7570, Val Loss: 22478.3418\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 98.97 99.25\n",
      "(0.05, 0.10)   9314 98.11 98.73\n",
      "(0.10, 0.20)  10413 96.90 97.99\n",
      "(0.20, 0.30)   6899 95.11 96.59\n",
      "(0.30, 0.40)   6055 94.64 96.36\n",
      "(0.40, 0.50)   5992 94.27 96.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 47/100, Train Loss: 33666.9783, Val Loss: 22617.4590\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 98.98 99.26\n",
      "(0.05, 0.10)   9314 98.14 98.72\n",
      "(0.10, 0.20)  10413 96.95 98.01\n",
      "(0.20, 0.30)   6899 95.17 96.57\n",
      "(0.30, 0.40)   6055 94.70 96.41\n",
      "(0.40, 0.50)   5992 94.31 96.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 48/100, Train Loss: 33144.7332, Val Loss: 21635.3633\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 98.99 99.26\n",
      "(0.05, 0.10)   9314 98.13 98.78\n",
      "(0.10, 0.20)  10413 96.95 98.03\n",
      "(0.20, 0.30)   6899 95.17 96.63\n",
      "(0.30, 0.40)   6055 94.72 96.45\n",
      "(0.40, 0.50)   5992 94.34 96.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 49/100, Train Loss: 32749.6439, Val Loss: 21575.8418\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 98.99 99.24\n",
      "(0.05, 0.10)   9314 98.15 98.76\n",
      "(0.10, 0.20)  10413 96.97 98.06\n",
      "(0.20, 0.30)   6899 95.20 96.65\n",
      "(0.30, 0.40)   6055 94.73 96.46\n",
      "(0.40, 0.50)   5992 94.37 96.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 50/100, Train Loss: 32196.1603, Val Loss: 22042.0176\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 99.01 99.26\n",
      "(0.05, 0.10)   9314 98.18 98.73\n",
      "(0.10, 0.20)  10413 97.00 98.02\n",
      "(0.20, 0.30)   6899 95.24 96.62\n",
      "(0.30, 0.40)   6055 94.77 96.43\n",
      "(0.40, 0.50)   5992 94.41 96.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 51/100, Train Loss: 32172.8958, Val Loss: 20906.0977\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 99.01 99.25\n",
      "(0.05, 0.10)   9314 98.18 98.78\n",
      "(0.10, 0.20)  10413 97.00 98.06\n",
      "(0.20, 0.30)   6899 95.24 96.69\n",
      "(0.30, 0.40)   6055 94.78 96.52\n",
      "(0.40, 0.50)   5992 94.41 96.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 52/100, Train Loss: 31871.0988, Val Loss: 21877.2031\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 99.01 99.26\n",
      "(0.05, 0.10)   9314 98.18 98.74\n",
      "(0.10, 0.20)  10413 97.00 98.05\n",
      "(0.20, 0.30)   6899 95.25 96.62\n",
      "(0.30, 0.40)   6055 94.79 96.40\n",
      "(0.40, 0.50)   5992 94.41 96.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 53/100, Train Loss: 31162.5486, Val Loss: 20317.1875\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 99.03 99.28\n",
      "(0.05, 0.10)   9314 98.21 98.80\n",
      "(0.10, 0.20)  10413 97.04 98.10\n",
      "(0.20, 0.30)   6899 95.30 96.70\n",
      "(0.30, 0.40)   6055 94.85 96.52\n",
      "(0.40, 0.50)   5992 94.46 96.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 54/100, Train Loss: 31080.9441, Val Loss: 20370.6250\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 99.02 99.28\n",
      "(0.05, 0.10)   9314 98.20 98.80\n",
      "(0.10, 0.20)  10413 97.04 98.11\n",
      "(0.20, 0.30)   6899 95.30 96.70\n",
      "(0.30, 0.40)   6055 94.84 96.55\n",
      "(0.40, 0.50)   5992 94.47 96.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 55/100, Train Loss: 30566.2848, Val Loss: 20318.6836\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 99.03 99.28\n",
      "(0.05, 0.10)   9314 98.21 98.77\n",
      "(0.10, 0.20)  10413 97.06 98.09\n",
      "(0.20, 0.30)   6899 95.33 96.70\n",
      "(0.30, 0.40)   6055 94.86 96.54\n",
      "(0.40, 0.50)   5992 94.48 96.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 56/100, Train Loss: 30099.6805, Val Loss: 20154.8418\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 99.04 99.29\n",
      "(0.05, 0.10)   9314 98.22 98.79\n",
      "(0.10, 0.20)  10413 97.07 98.11\n",
      "(0.20, 0.30)   6899 95.34 96.68\n",
      "(0.30, 0.40)   6055 94.89 96.55\n",
      "(0.40, 0.50)   5992 94.52 96.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 57/100, Train Loss: 30303.6649, Val Loss: 19514.5000\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 99.04 99.29\n",
      "(0.05, 0.10)   9314 98.24 98.81\n",
      "(0.10, 0.20)  10413 97.09 98.13\n",
      "(0.20, 0.30)   6899 95.37 96.74\n",
      "(0.30, 0.40)   6055 94.90 96.57\n",
      "(0.40, 0.50)   5992 94.54 96.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 58/100, Train Loss: 29795.0378, Val Loss: 19387.2324\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 99.05 99.30\n",
      "(0.05, 0.10)   9314 98.24 98.83\n",
      "(0.10, 0.20)  10413 97.09 98.12\n",
      "(0.20, 0.30)   6899 95.36 96.75\n",
      "(0.30, 0.40)   6055 94.90 96.57\n",
      "(0.40, 0.50)   5992 94.54 96.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 59/100, Train Loss: 29512.3097, Val Loss: 19104.1914\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 99.05 99.28\n",
      "(0.05, 0.10)   9314 98.25 98.82\n",
      "(0.10, 0.20)  10413 97.12 98.14\n",
      "(0.20, 0.30)   6899 95.40 96.80\n",
      "(0.30, 0.40)   6055 94.93 96.61\n",
      "(0.40, 0.50)   5992 94.57 96.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 60/100, Train Loss: 28956.3998, Val Loss: 18759.5078\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 99.06 99.29\n",
      "(0.05, 0.10)   9314 98.27 98.82\n",
      "(0.10, 0.20)  10413 97.13 98.16\n",
      "(0.20, 0.30)   6899 95.41 96.81\n",
      "(0.30, 0.40)   6055 94.96 96.63\n",
      "(0.40, 0.50)   5992 94.60 96.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 61/100, Train Loss: 28958.5626, Val Loss: 18997.8555\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 99.06 99.29\n",
      "(0.05, 0.10)   9314 98.26 98.83\n",
      "(0.10, 0.20)  10413 97.14 98.14\n",
      "(0.20, 0.30)   6899 95.42 96.78\n",
      "(0.30, 0.40)   6055 94.95 96.62\n",
      "(0.40, 0.50)   5992 94.60 96.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 62/100, Train Loss: 28574.4994, Val Loss: 18464.1211\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 99.07 99.29\n",
      "(0.05, 0.10)   9314 98.28 98.81\n",
      "(0.10, 0.20)  10413 97.15 98.17\n",
      "(0.20, 0.30)   6899 95.43 96.82\n",
      "(0.30, 0.40)   6055 94.96 96.70\n",
      "(0.40, 0.50)   5992 94.62 96.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 63/100, Train Loss: 28579.1445, Val Loss: 18274.7949\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 99.08 99.30\n",
      "(0.05, 0.10)   9314 98.29 98.83\n",
      "(0.10, 0.20)  10413 97.17 98.19\n",
      "(0.20, 0.30)   6899 95.45 96.88\n",
      "(0.30, 0.40)   6055 94.99 96.68\n",
      "(0.40, 0.50)   5992 94.64 96.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 64/100, Train Loss: 27976.1648, Val Loss: 18075.0762\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 99.08 99.29\n",
      "(0.05, 0.10)   9314 98.30 98.83\n",
      "(0.10, 0.20)  10413 97.19 98.16\n",
      "(0.20, 0.30)   6899 95.48 96.80\n",
      "(0.30, 0.40)   6055 95.02 96.68\n",
      "(0.40, 0.50)   5992 94.67 96.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 65/100, Train Loss: 27571.4187, Val Loss: 17910.2617\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 99.08 99.32\n",
      "(0.05, 0.10)   9314 98.31 98.86\n",
      "(0.10, 0.20)  10413 97.20 98.22\n",
      "(0.20, 0.30)   6899 95.49 96.87\n",
      "(0.30, 0.40)   6055 95.03 96.64\n",
      "(0.40, 0.50)   5992 94.69 96.42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 66/100, Train Loss: 27583.6186, Val Loss: 17716.0820\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 99.08 99.30\n",
      "(0.05, 0.10)   9314 98.30 98.86\n",
      "(0.10, 0.20)  10413 97.20 98.21\n",
      "(0.20, 0.30)   6899 95.49 96.87\n",
      "(0.30, 0.40)   6055 95.02 96.72\n",
      "(0.40, 0.50)   5992 94.68 96.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 67/100, Train Loss: 26986.5704, Val Loss: 17171.0430\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 99.10 99.31\n",
      "(0.05, 0.10)   9314 98.33 98.87\n",
      "(0.10, 0.20)  10413 97.24 98.22\n",
      "(0.20, 0.30)   6899 95.52 96.88\n",
      "(0.30, 0.40)   6055 95.07 96.75\n",
      "(0.40, 0.50)   5992 94.71 96.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 68/100, Train Loss: 26492.4601, Val Loss: 17663.6465\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 99.10 99.29\n",
      "(0.05, 0.10)   9314 98.33 98.84\n",
      "(0.10, 0.20)  10413 97.24 98.22\n",
      "(0.20, 0.30)   6899 95.54 96.89\n",
      "(0.30, 0.40)   6055 95.09 96.76\n",
      "(0.40, 0.50)   5992 94.74 96.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 69/100, Train Loss: 26705.4166, Val Loss: 17258.9629\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 99.10 99.32\n",
      "(0.05, 0.10)   9314 98.34 98.86\n",
      "(0.10, 0.20)  10413 97.25 98.23\n",
      "(0.20, 0.30)   6899 95.55 96.87\n",
      "(0.30, 0.40)   6055 95.09 96.72\n",
      "(0.40, 0.50)   5992 94.75 96.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 70/100, Train Loss: 26891.3776, Val Loss: 17172.1777\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 99.10 99.30\n",
      "(0.05, 0.10)   9314 98.34 98.90\n",
      "(0.10, 0.20)  10413 97.26 98.24\n",
      "(0.20, 0.30)   6899 95.55 96.94\n",
      "(0.30, 0.40)   6055 95.08 96.76\n",
      "(0.40, 0.50)   5992 94.74 96.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 71/100, Train Loss: 26394.0794, Val Loss: 17172.3320\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 99.10 99.31\n",
      "(0.05, 0.10)   9314 98.34 98.87\n",
      "(0.10, 0.20)  10413 97.25 98.23\n",
      "(0.20, 0.30)   6899 95.55 96.94\n",
      "(0.30, 0.40)   6055 95.10 96.75\n",
      "(0.40, 0.50)   5992 94.75 96.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 72/100, Train Loss: 23317.7481, Val Loss: 15146.2617\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 99.17 99.34\n",
      "(0.05, 0.10)   9314 98.44 98.91\n",
      "(0.10, 0.20)  10413 97.40 98.30\n",
      "(0.20, 0.30)   6899 95.75 97.02\n",
      "(0.30, 0.40)   6055 95.29 96.86\n",
      "(0.40, 0.50)   5992 94.95 96.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 73/100, Train Loss: 22462.6163, Val Loss: 14541.1797\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 99.19 99.37\n",
      "(0.05, 0.10)   9314 98.48 98.94\n",
      "(0.10, 0.20)  10413 97.44 98.34\n",
      "(0.20, 0.30)   6899 95.80 97.07\n",
      "(0.30, 0.40)   6055 95.34 96.89\n",
      "(0.40, 0.50)   5992 95.01 96.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 74/100, Train Loss: 21818.2318, Val Loss: 14477.3340\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 99.19 99.37\n",
      "(0.05, 0.10)   9314 98.47 98.94\n",
      "(0.10, 0.20)  10413 97.44 98.32\n",
      "(0.20, 0.30)   6899 95.82 97.03\n",
      "(0.30, 0.40)   6055 95.36 96.87\n",
      "(0.40, 0.50)   5992 95.02 96.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 75/100, Train Loss: 22210.2676, Val Loss: 14313.5020\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 99.19 99.38\n",
      "(0.05, 0.10)   9314 98.48 98.94\n",
      "(0.10, 0.20)  10413 97.45 98.33\n",
      "(0.20, 0.30)   6899 95.82 97.03\n",
      "(0.30, 0.40)   6055 95.35 96.88\n",
      "(0.40, 0.50)   5992 95.02 96.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 76/100, Train Loss: 21874.5508, Val Loss: 14120.8535\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 99.19 99.36\n",
      "(0.05, 0.10)   9314 98.48 98.94\n",
      "(0.10, 0.20)  10413 97.46 98.34\n",
      "(0.20, 0.30)   6899 95.83 97.09\n",
      "(0.30, 0.40)   6055 95.38 96.93\n",
      "(0.40, 0.50)   5992 95.04 96.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 77/100, Train Loss: 21545.3752, Val Loss: 13947.8477\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 99.20 99.38\n",
      "(0.05, 0.10)   9314 98.48 98.95\n",
      "(0.10, 0.20)  10413 97.46 98.34\n",
      "(0.20, 0.30)   6899 95.83 97.09\n",
      "(0.30, 0.40)   6055 95.37 96.86\n",
      "(0.40, 0.50)   5992 95.05 96.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 78/100, Train Loss: 21438.5501, Val Loss: 13697.1953\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 99.20 99.39\n",
      "(0.05, 0.10)   9314 98.49 98.96\n",
      "(0.10, 0.20)  10413 97.47 98.35\n",
      "(0.20, 0.30)   6899 95.85 97.07\n",
      "(0.30, 0.40)   6055 95.38 96.91\n",
      "(0.40, 0.50)   5992 95.05 96.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 79/100, Train Loss: 21566.7089, Val Loss: 13833.4023\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 99.21 99.37\n",
      "(0.05, 0.10)   9314 98.50 98.94\n",
      "(0.10, 0.20)  10413 97.48 98.36\n",
      "(0.20, 0.30)   6899 95.84 97.10\n",
      "(0.30, 0.40)   6055 95.41 96.91\n",
      "(0.40, 0.50)   5992 95.08 96.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 80/100, Train Loss: 21176.8406, Val Loss: 14082.5547\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 99.21 99.36\n",
      "(0.05, 0.10)   9314 98.50 98.93\n",
      "(0.10, 0.20)  10413 97.48 98.33\n",
      "(0.20, 0.30)   6899 95.86 97.05\n",
      "(0.30, 0.40)   6055 95.40 96.88\n",
      "(0.40, 0.50)   5992 95.07 96.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 81/100, Train Loss: 21077.5073, Val Loss: 13677.9629\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 99.21 99.38\n",
      "(0.05, 0.10)   9314 98.50 98.95\n",
      "(0.10, 0.20)  10413 97.49 98.37\n",
      "(0.20, 0.30)   6899 95.86 97.14\n",
      "(0.30, 0.40)   6055 95.41 96.93\n",
      "(0.40, 0.50)   5992 95.09 96.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 82/100, Train Loss: 21327.1054, Val Loss: 13416.3672\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 99.20 99.37\n",
      "(0.05, 0.10)   9314 98.50 98.98\n",
      "(0.10, 0.20)  10413 97.49 98.37\n",
      "(0.20, 0.30)   6899 95.86 97.11\n",
      "(0.30, 0.40)   6055 95.41 96.97\n",
      "(0.40, 0.50)   5992 95.09 96.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 83/100, Train Loss: 21070.0387, Val Loss: 13613.1094\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 99.21 99.37\n",
      "(0.05, 0.10)   9314 98.51 98.94\n",
      "(0.10, 0.20)  10413 97.50 98.38\n",
      "(0.20, 0.30)   6899 95.90 97.13\n",
      "(0.30, 0.40)   6055 95.46 96.95\n",
      "(0.40, 0.50)   5992 95.13 96.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 84/100, Train Loss: 20750.9116, Val Loss: 13476.8965\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 99.22 99.37\n",
      "(0.05, 0.10)   9314 98.52 98.94\n",
      "(0.10, 0.20)  10413 97.51 98.35\n",
      "(0.20, 0.30)   6899 95.88 97.10\n",
      "(0.30, 0.40)   6055 95.45 96.94\n",
      "(0.40, 0.50)   5992 95.12 96.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 85/100, Train Loss: 20659.6542, Val Loss: 12990.4180\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 99.21 99.40\n",
      "(0.05, 0.10)   9314 98.51 98.97\n",
      "(0.10, 0.20)  10413 97.49 98.39\n",
      "(0.20, 0.30)   6899 95.86 97.12\n",
      "(0.30, 0.40)   6055 95.42 96.98\n",
      "(0.40, 0.50)   5992 95.09 96.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 86/100, Train Loss: 20499.1233, Val Loss: 13269.6074\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 99.22 99.39\n",
      "(0.05, 0.10)   9314 98.52 98.97\n",
      "(0.10, 0.20)  10413 97.51 98.37\n",
      "(0.20, 0.30)   6899 95.89 97.07\n",
      "(0.30, 0.40)   6055 95.45 96.95\n",
      "(0.40, 0.50)   5992 95.12 96.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 87/100, Train Loss: 20493.7837, Val Loss: 13069.7891\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 99.22 99.38\n",
      "(0.05, 0.10)   9314 98.52 98.96\n",
      "(0.10, 0.20)  10413 97.52 98.38\n",
      "(0.20, 0.30)   6899 95.90 97.13\n",
      "(0.30, 0.40)   6055 95.46 96.99\n",
      "(0.40, 0.50)   5992 95.13 96.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 88/100, Train Loss: 20301.9371, Val Loss: 13086.0391\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 99.22 99.37\n",
      "(0.05, 0.10)   9314 98.52 98.96\n",
      "(0.10, 0.20)  10413 97.52 98.38\n",
      "(0.20, 0.30)   6899 95.89 97.12\n",
      "(0.30, 0.40)   6055 95.46 97.01\n",
      "(0.40, 0.50)   5992 95.13 96.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 89/100, Train Loss: 20286.4540, Val Loss: 13072.1406\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 99.22 99.39\n",
      "(0.05, 0.10)   9314 98.53 98.96\n",
      "(0.10, 0.20)  10413 97.53 98.39\n",
      "(0.20, 0.30)   6899 95.91 97.17\n",
      "(0.30, 0.40)   6055 95.46 96.99\n",
      "(0.40, 0.50)   5992 95.14 96.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 90/100, Train Loss: 18535.1574, Val Loss: 11967.3516\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 99.26 99.41\n",
      "(0.05, 0.10)   9314 98.59 99.00\n",
      "(0.10, 0.20)  10413 97.61 98.43\n",
      "(0.20, 0.30)   6899 96.03 97.23\n",
      "(0.30, 0.40)   6055 95.59 97.04\n",
      "(0.40, 0.50)   5992 95.27 96.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 91/100, Train Loss: 18042.0691, Val Loss: 11776.3789\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 99.27 99.41\n",
      "(0.05, 0.10)   9314 98.60 99.00\n",
      "(0.10, 0.20)  10413 97.62 98.44\n",
      "(0.20, 0.30)   6899 96.04 97.21\n",
      "(0.30, 0.40)   6055 95.62 97.05\n",
      "(0.40, 0.50)   5992 95.29 96.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 92/100, Train Loss: 18068.0742, Val Loss: 11728.6445\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 99.26 99.41\n",
      "(0.05, 0.10)   9314 98.60 98.99\n",
      "(0.10, 0.20)  10413 97.62 98.42\n",
      "(0.20, 0.30)   6899 96.04 97.21\n",
      "(0.30, 0.40)   6055 95.61 97.07\n",
      "(0.40, 0.50)   5992 95.29 96.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 93/100, Train Loss: 17973.0510, Val Loss: 11938.1738\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 99.27 99.40\n",
      "(0.05, 0.10)   9314 98.60 98.98\n",
      "(0.10, 0.20)  10413 97.62 98.42\n",
      "(0.20, 0.30)   6899 96.05 97.20\n",
      "(0.30, 0.40)   6055 95.61 97.04\n",
      "(0.40, 0.50)   5992 95.29 96.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 94/100, Train Loss: 17562.6238, Val Loss: 11613.6367\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 99.27 99.41\n",
      "(0.05, 0.10)   9314 98.60 99.00\n",
      "(0.10, 0.20)  10413 97.62 98.44\n",
      "(0.20, 0.30)   6899 96.05 97.25\n",
      "(0.30, 0.40)   6055 95.61 97.05\n",
      "(0.40, 0.50)   5992 95.29 96.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 95/100, Train Loss: 17537.2970, Val Loss: 11548.2246\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 99.27 99.41\n",
      "(0.05, 0.10)   9314 98.61 99.01\n",
      "(0.10, 0.20)  10413 97.64 98.45\n",
      "(0.20, 0.30)   6899 96.05 97.24\n",
      "(0.30, 0.40)   6055 95.62 97.07\n",
      "(0.40, 0.50)   5992 95.31 96.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 96/100, Train Loss: 17717.3938, Val Loss: 11618.7480\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 99.27 99.40\n",
      "(0.05, 0.10)   9314 98.61 99.00\n",
      "(0.10, 0.20)  10413 97.63 98.44\n",
      "(0.20, 0.30)   6899 96.07 97.22\n",
      "(0.30, 0.40)   6055 95.64 97.09\n",
      "(0.40, 0.50)   5992 95.32 96.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 97/100, Train Loss: 17455.6649, Val Loss: 11311.5352\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 99.28 99.42\n",
      "(0.05, 0.10)   9314 98.61 99.02\n",
      "(0.10, 0.20)  10413 97.65 98.43\n",
      "(0.20, 0.30)   6899 96.07 97.20\n",
      "(0.30, 0.40)   6055 95.65 97.09\n",
      "(0.40, 0.50)   5992 95.33 96.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 98/100, Train Loss: 17347.5030, Val Loss: 11403.9902\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 99.28 99.41\n",
      "(0.05, 0.10)   9314 98.62 99.02\n",
      "(0.10, 0.20)  10413 97.65 98.44\n",
      "(0.20, 0.30)   6899 96.07 97.23\n",
      "(0.30, 0.40)   6055 95.64 97.07\n",
      "(0.40, 0.50)   5992 95.32 96.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 99/100, Train Loss: 17218.0646, Val Loss: 11465.0742\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 99.28 99.41\n",
      "(0.05, 0.10)   9314 98.62 98.99\n",
      "(0.10, 0.20)  10413 97.65 98.43\n",
      "(0.20, 0.30)   6899 96.09 97.26\n",
      "(0.30, 0.40)   6055 95.66 97.09\n",
      "(0.40, 0.50)   5992 95.34 96.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1, Epoch 100/100, Train Loss: 17112.4287, Val Loss: 11281.4023\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  26859 99.28 99.42\n",
      "(0.05, 0.10)   9314 98.62 99.01\n",
      "(0.10, 0.20)  10413 97.66 98.43\n",
      "(0.20, 0.30)   6899 96.10 97.24\n",
      "(0.30, 0.40)   6055 95.66 97.10\n",
      "(0.40, 0.50)   5992 95.35 96.96\n",
      "Training on chunk 2/2\n",
      "Data shape: (4808, 33906)\n",
      "Finding duplicate haploids in training set.\n",
      "Removed 0 rows. 4744 training samples remaining.\n",
      "Chunk MAF-bin counts: [15300, 4779, 5050, 3298, 2780, 2567]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 1/100, Train Loss: 112614.6237, Val Loss: 81809.8496\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 97.56 98.37\n",
      "(0.05, 0.10)   4779 93.30 95.45\n",
      "(0.10, 0.20)   5050 88.29 92.47\n",
      "(0.20, 0.30)   3298 81.74 88.39\n",
      "(0.30, 0.40)   2780 77.64 86.10\n",
      "(0.40, 0.50)   2567 75.49 85.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 2/100, Train Loss: 66436.4723, Val Loss: 49186.0801\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 97.94 98.63\n",
      "(0.05, 0.10)   4779 94.84 96.90\n",
      "(0.10, 0.20)   5050 92.55 95.45\n",
      "(0.20, 0.30)   3298 89.54 93.70\n",
      "(0.30, 0.40)   2780 88.93 92.67\n",
      "(0.40, 0.50)   2567 88.65 92.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 3/100, Train Loss: 50235.9964, Val Loss: 38200.5498\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 98.10 98.79\n",
      "(0.05, 0.10)   4779 95.83 97.55\n",
      "(0.10, 0.20)   5050 94.23 96.26\n",
      "(0.20, 0.30)   3298 92.43 95.12\n",
      "(0.30, 0.40)   2780 91.71 94.42\n",
      "(0.40, 0.50)   2567 91.51 94.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 4/100, Train Loss: 40580.3289, Val Loss: 33659.7881\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 98.26 98.87\n",
      "(0.05, 0.10)   4779 96.54 97.81\n",
      "(0.10, 0.20)   5050 95.25 96.77\n",
      "(0.20, 0.30)   3298 93.92 95.78\n",
      "(0.30, 0.40)   2780 93.33 94.98\n",
      "(0.40, 0.50)   2567 93.08 94.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 5/100, Train Loss: 34704.1682, Val Loss: 25521.7412\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 98.37 99.00\n",
      "(0.05, 0.10)   4779 96.95 98.20\n",
      "(0.10, 0.20)   5050 95.83 97.34\n",
      "(0.20, 0.30)   3298 94.68 96.55\n",
      "(0.30, 0.40)   2780 94.23 95.88\n",
      "(0.40, 0.50)   2567 93.97 95.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 6/100, Train Loss: 30767.5128, Val Loss: 21808.8691\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 98.49 99.11\n",
      "(0.05, 0.10)   4779 97.25 98.48\n",
      "(0.10, 0.20)   5050 96.24 97.68\n",
      "(0.20, 0.30)   3298 95.15 96.93\n",
      "(0.30, 0.40)   2780 94.79 96.52\n",
      "(0.40, 0.50)   2567 94.46 96.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 7/100, Train Loss: 27380.7660, Val Loss: 16811.4619\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 98.60 99.20\n",
      "(0.05, 0.10)   4779 97.51 98.66\n",
      "(0.10, 0.20)   5050 96.59 98.14\n",
      "(0.20, 0.30)   3298 95.59 97.48\n",
      "(0.30, 0.40)   2780 95.25 97.16\n",
      "(0.40, 0.50)   2567 94.88 96.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 8/100, Train Loss: 25237.8004, Val Loss: 19271.5615\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 98.67 99.22\n",
      "(0.05, 0.10)   4779 97.66 98.66\n",
      "(0.10, 0.20)   5050 96.78 97.85\n",
      "(0.20, 0.30)   3298 95.81 97.24\n",
      "(0.30, 0.40)   2780 95.48 96.76\n",
      "(0.40, 0.50)   2567 95.10 96.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 9/100, Train Loss: 23007.3651, Val Loss: 16689.5918\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 98.75 99.27\n",
      "(0.05, 0.10)   4779 97.82 98.80\n",
      "(0.10, 0.20)   5050 96.98 98.14\n",
      "(0.20, 0.30)   3298 96.05 97.44\n",
      "(0.30, 0.40)   2780 95.75 96.97\n",
      "(0.40, 0.50)   2567 95.34 96.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 10/100, Train Loss: 21752.5935, Val Loss: 15384.8281\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 98.80 99.31\n",
      "(0.05, 0.10)   4779 97.93 98.84\n",
      "(0.10, 0.20)   5050 97.14 98.24\n",
      "(0.20, 0.30)   3298 96.22 97.55\n",
      "(0.30, 0.40)   2780 95.90 97.08\n",
      "(0.40, 0.50)   2567 95.52 96.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 11/100, Train Loss: 20284.0628, Val Loss: 14378.3281\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 98.85 99.33\n",
      "(0.05, 0.10)   4779 98.05 98.89\n",
      "(0.10, 0.20)   5050 97.27 98.27\n",
      "(0.20, 0.30)   3298 96.41 97.73\n",
      "(0.30, 0.40)   2780 96.07 97.31\n",
      "(0.40, 0.50)   2567 95.68 97.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 12/100, Train Loss: 18990.6933, Val Loss: 14908.4619\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 98.90 99.36\n",
      "(0.05, 0.10)   4779 98.15 98.94\n",
      "(0.10, 0.20)   5050 97.38 98.27\n",
      "(0.20, 0.30)   3298 96.53 97.66\n",
      "(0.30, 0.40)   2780 96.23 97.21\n",
      "(0.40, 0.50)   2567 95.84 96.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 13/100, Train Loss: 18054.4099, Val Loss: 11158.8906\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 98.93 99.44\n",
      "(0.05, 0.10)   4779 98.22 99.05\n",
      "(0.10, 0.20)   5050 97.47 98.61\n",
      "(0.20, 0.30)   3298 96.64 98.05\n",
      "(0.30, 0.40)   2780 96.33 97.72\n",
      "(0.40, 0.50)   2567 95.95 97.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 14/100, Train Loss: 17059.9982, Val Loss: 10762.4648\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 98.97 99.43\n",
      "(0.05, 0.10)   4779 98.29 99.12\n",
      "(0.10, 0.20)   5050 97.56 98.62\n",
      "(0.20, 0.30)   3298 96.74 98.10\n",
      "(0.30, 0.40)   2780 96.45 97.78\n",
      "(0.40, 0.50)   2567 96.04 97.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 15/100, Train Loss: 16109.2052, Val Loss: 9732.2910\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 99.00 99.46\n",
      "(0.05, 0.10)   4779 98.34 99.12\n",
      "(0.10, 0.20)   5050 97.63 98.65\n",
      "(0.20, 0.30)   3298 96.82 98.17\n",
      "(0.30, 0.40)   2780 96.53 97.90\n",
      "(0.40, 0.50)   2567 96.14 97.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 16/100, Train Loss: 15603.1952, Val Loss: 9581.9590\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 99.02 99.48\n",
      "(0.05, 0.10)   4779 98.39 99.15\n",
      "(0.10, 0.20)   5050 97.69 98.70\n",
      "(0.20, 0.30)   3298 96.91 98.17\n",
      "(0.30, 0.40)   2780 96.60 97.95\n",
      "(0.40, 0.50)   2567 96.21 97.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 17/100, Train Loss: 15165.1680, Val Loss: 9284.5576\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 99.05 99.47\n",
      "(0.05, 0.10)   4779 98.44 99.16\n",
      "(0.10, 0.20)   5050 97.76 98.69\n",
      "(0.20, 0.30)   3298 96.97 98.22\n",
      "(0.30, 0.40)   2780 96.67 97.93\n",
      "(0.40, 0.50)   2567 96.29 97.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 18/100, Train Loss: 14419.7921, Val Loss: 8083.5811\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 99.07 99.51\n",
      "(0.05, 0.10)   4779 98.48 99.22\n",
      "(0.10, 0.20)   5050 97.80 98.83\n",
      "(0.20, 0.30)   3298 97.01 98.29\n",
      "(0.30, 0.40)   2780 96.73 98.09\n",
      "(0.40, 0.50)   2567 96.34 97.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 19/100, Train Loss: 13963.5369, Val Loss: 7206.7354\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 99.09 99.52\n",
      "(0.05, 0.10)   4779 98.52 99.26\n",
      "(0.10, 0.20)   5050 97.85 98.89\n",
      "(0.20, 0.30)   3298 97.08 98.40\n",
      "(0.30, 0.40)   2780 96.80 98.18\n",
      "(0.40, 0.50)   2567 96.41 97.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 20/100, Train Loss: 13413.9857, Val Loss: 7821.5342\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 99.11 99.52\n",
      "(0.05, 0.10)   4779 98.55 99.24\n",
      "(0.10, 0.20)   5050 97.90 98.84\n",
      "(0.20, 0.30)   3298 97.13 98.31\n",
      "(0.30, 0.40)   2780 96.85 98.08\n",
      "(0.40, 0.50)   2567 96.47 97.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 21/100, Train Loss: 13381.3997, Val Loss: 8025.4541\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 99.13 99.54\n",
      "(0.05, 0.10)   4779 98.58 99.27\n",
      "(0.10, 0.20)   5050 97.92 98.85\n",
      "(0.20, 0.30)   3298 97.17 98.29\n",
      "(0.30, 0.40)   2780 96.90 98.10\n",
      "(0.40, 0.50)   2567 96.51 97.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 22/100, Train Loss: 12789.5822, Val Loss: 6645.5029\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 99.16 99.54\n",
      "(0.05, 0.10)   4779 98.62 99.28\n",
      "(0.10, 0.20)   5050 97.98 98.93\n",
      "(0.20, 0.30)   3298 97.23 98.44\n",
      "(0.30, 0.40)   2780 96.96 98.27\n",
      "(0.40, 0.50)   2567 96.57 97.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 23/100, Train Loss: 12242.0272, Val Loss: 6123.1865\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 99.17 99.57\n",
      "(0.05, 0.10)   4779 98.65 99.35\n",
      "(0.10, 0.20)   5050 98.02 98.96\n",
      "(0.20, 0.30)   3298 97.28 98.46\n",
      "(0.30, 0.40)   2780 97.02 98.33\n",
      "(0.40, 0.50)   2567 96.63 98.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 24/100, Train Loss: 12050.1508, Val Loss: 6237.2910\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 99.18 99.56\n",
      "(0.05, 0.10)   4779 98.66 99.33\n",
      "(0.10, 0.20)   5050 98.02 98.97\n",
      "(0.20, 0.30)   3298 97.28 98.44\n",
      "(0.30, 0.40)   2780 97.02 98.29\n",
      "(0.40, 0.50)   2567 96.64 97.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 25/100, Train Loss: 11809.0660, Val Loss: 6344.9863\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 99.20 99.58\n",
      "(0.05, 0.10)   4779 98.69 99.33\n",
      "(0.10, 0.20)   5050 98.08 98.92\n",
      "(0.20, 0.30)   3298 97.36 98.44\n",
      "(0.30, 0.40)   2780 97.07 98.17\n",
      "(0.40, 0.50)   2567 96.69 97.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 26/100, Train Loss: 11235.6499, Val Loss: 6181.8115\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 99.21 99.57\n",
      "(0.05, 0.10)   4779 98.73 99.36\n",
      "(0.10, 0.20)   5050 98.11 98.95\n",
      "(0.20, 0.30)   3298 97.37 98.48\n",
      "(0.30, 0.40)   2780 97.10 98.32\n",
      "(0.40, 0.50)   2567 96.72 98.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 27/100, Train Loss: 11181.1267, Val Loss: 5242.9062\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 99.22 99.59\n",
      "(0.05, 0.10)   4779 98.73 99.39\n",
      "(0.10, 0.20)   5050 98.12 99.01\n",
      "(0.20, 0.30)   3298 97.40 98.56\n",
      "(0.30, 0.40)   2780 97.14 98.41\n",
      "(0.40, 0.50)   2567 96.75 98.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 28/100, Train Loss: 10712.0984, Val Loss: 6546.7021\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 99.24 99.59\n",
      "(0.05, 0.10)   4779 98.76 99.34\n",
      "(0.10, 0.20)   5050 98.15 98.93\n",
      "(0.20, 0.30)   3298 97.45 98.47\n",
      "(0.30, 0.40)   2780 97.18 98.03\n",
      "(0.40, 0.50)   2567 96.81 97.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 29/100, Train Loss: 10533.4459, Val Loss: 4959.9629\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 99.24 99.61\n",
      "(0.05, 0.10)   4779 98.77 99.41\n",
      "(0.10, 0.20)   5050 98.16 99.02\n",
      "(0.20, 0.30)   3298 97.46 98.59\n",
      "(0.30, 0.40)   2780 97.20 98.47\n",
      "(0.40, 0.50)   2567 96.82 98.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 30/100, Train Loss: 10291.4135, Val Loss: 5100.6670\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 99.26 99.60\n",
      "(0.05, 0.10)   4779 98.81 99.42\n",
      "(0.10, 0.20)   5050 98.19 99.02\n",
      "(0.20, 0.30)   3298 97.49 98.54\n",
      "(0.30, 0.40)   2780 97.23 98.39\n",
      "(0.40, 0.50)   2567 96.87 98.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 31/100, Train Loss: 10173.2601, Val Loss: 4763.7861\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 99.26 99.62\n",
      "(0.05, 0.10)   4779 98.82 99.43\n",
      "(0.10, 0.20)   5050 98.22 99.06\n",
      "(0.20, 0.30)   3298 97.52 98.60\n",
      "(0.30, 0.40)   2780 97.25 98.49\n",
      "(0.40, 0.50)   2567 96.90 98.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 32/100, Train Loss: 9731.0915, Val Loss: 4742.6670\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 99.28 99.62\n",
      "(0.05, 0.10)   4779 98.84 99.43\n",
      "(0.10, 0.20)   5050 98.25 99.05\n",
      "(0.20, 0.30)   3298 97.55 98.59\n",
      "(0.30, 0.40)   2780 97.30 98.47\n",
      "(0.40, 0.50)   2567 96.92 98.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 33/100, Train Loss: 9604.0909, Val Loss: 4961.6631\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 99.29 99.63\n",
      "(0.05, 0.10)   4779 98.86 99.43\n",
      "(0.10, 0.20)   5050 98.26 99.03\n",
      "(0.20, 0.30)   3298 97.56 98.56\n",
      "(0.30, 0.40)   2780 97.30 98.46\n",
      "(0.40, 0.50)   2567 96.94 98.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 34/100, Train Loss: 9495.9392, Val Loss: 4559.7490\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 99.29 99.62\n",
      "(0.05, 0.10)   4779 98.86 99.43\n",
      "(0.10, 0.20)   5050 98.27 99.06\n",
      "(0.20, 0.30)   3298 97.57 98.62\n",
      "(0.30, 0.40)   2780 97.31 98.44\n",
      "(0.40, 0.50)   2567 96.96 98.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 35/100, Train Loss: 9214.6357, Val Loss: 3584.4541\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 99.30 99.64\n",
      "(0.05, 0.10)   4779 98.89 99.46\n",
      "(0.10, 0.20)   5050 98.29 99.13\n",
      "(0.20, 0.30)   3298 97.61 98.71\n",
      "(0.30, 0.40)   2780 97.35 98.59\n",
      "(0.40, 0.50)   2567 96.98 98.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 36/100, Train Loss: 8947.7171, Val Loss: 3566.9326\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 99.31 99.65\n",
      "(0.05, 0.10)   4779 98.90 99.49\n",
      "(0.10, 0.20)   5050 98.31 99.14\n",
      "(0.20, 0.30)   3298 97.63 98.73\n",
      "(0.30, 0.40)   2780 97.37 98.62\n",
      "(0.40, 0.50)   2567 97.02 98.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 37/100, Train Loss: 9062.1537, Val Loss: 4325.5508\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 99.31 99.64\n",
      "(0.05, 0.10)   4779 98.90 99.47\n",
      "(0.10, 0.20)   5050 98.31 99.10\n",
      "(0.20, 0.30)   3298 97.64 98.63\n",
      "(0.30, 0.40)   2780 97.38 98.51\n",
      "(0.40, 0.50)   2567 97.02 98.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 38/100, Train Loss: 8496.0528, Val Loss: 3450.7480\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 99.33 99.66\n",
      "(0.05, 0.10)   4779 98.93 99.49\n",
      "(0.10, 0.20)   5050 98.35 99.14\n",
      "(0.20, 0.30)   3298 97.66 98.75\n",
      "(0.30, 0.40)   2780 97.42 98.61\n",
      "(0.40, 0.50)   2567 97.06 98.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 39/100, Train Loss: 8656.4756, Val Loss: 3880.2598\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 99.33 99.65\n",
      "(0.05, 0.10)   4779 98.94 99.47\n",
      "(0.10, 0.20)   5050 98.34 99.10\n",
      "(0.20, 0.30)   3298 97.68 98.67\n",
      "(0.30, 0.40)   2780 97.42 98.58\n",
      "(0.40, 0.50)   2567 97.07 98.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 40/100, Train Loss: 8259.8019, Val Loss: 3101.6758\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 99.34 99.66\n",
      "(0.05, 0.10)   4779 98.94 99.51\n",
      "(0.10, 0.20)   5050 98.36 99.14\n",
      "(0.20, 0.30)   3298 97.70 98.76\n",
      "(0.30, 0.40)   2780 97.45 98.66\n",
      "(0.40, 0.50)   2567 97.10 98.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 41/100, Train Loss: 8220.9376, Val Loss: 3085.7295\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 99.34 99.67\n",
      "(0.05, 0.10)   4779 98.95 99.50\n",
      "(0.10, 0.20)   5050 98.36 99.16\n",
      "(0.20, 0.30)   3298 97.70 98.77\n",
      "(0.30, 0.40)   2780 97.44 98.67\n",
      "(0.40, 0.50)   2567 97.09 98.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 42/100, Train Loss: 8101.3931, Val Loss: 3261.7529\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 99.35 99.66\n",
      "(0.05, 0.10)   4779 98.96 99.51\n",
      "(0.10, 0.20)   5050 98.38 99.14\n",
      "(0.20, 0.30)   3298 97.72 98.73\n",
      "(0.30, 0.40)   2780 97.48 98.66\n",
      "(0.40, 0.50)   2567 97.12 98.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 43/100, Train Loss: 7978.3091, Val Loss: 3350.4756\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 99.36 99.67\n",
      "(0.05, 0.10)   4779 98.98 99.52\n",
      "(0.10, 0.20)   5050 98.39 99.14\n",
      "(0.20, 0.30)   3298 97.75 98.71\n",
      "(0.30, 0.40)   2780 97.49 98.62\n",
      "(0.40, 0.50)   2567 97.13 98.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 44/100, Train Loss: 7916.7523, Val Loss: 2706.3184\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 99.36 99.67\n",
      "(0.05, 0.10)   4779 98.98 99.52\n",
      "(0.10, 0.20)   5050 98.41 99.18\n",
      "(0.20, 0.30)   3298 97.75 98.78\n",
      "(0.30, 0.40)   2780 97.51 98.72\n",
      "(0.40, 0.50)   2567 97.15 98.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 45/100, Train Loss: 7555.9114, Val Loss: 2736.0225\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 99.37 99.68\n",
      "(0.05, 0.10)   4779 98.99 99.52\n",
      "(0.10, 0.20)   5050 98.42 99.17\n",
      "(0.20, 0.30)   3298 97.77 98.80\n",
      "(0.30, 0.40)   2780 97.53 98.72\n",
      "(0.40, 0.50)   2567 97.17 98.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 46/100, Train Loss: 7398.5595, Val Loss: 2660.6279\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 99.38 99.68\n",
      "(0.05, 0.10)   4779 99.01 99.53\n",
      "(0.10, 0.20)   5050 98.44 99.19\n",
      "(0.20, 0.30)   3298 97.79 98.79\n",
      "(0.30, 0.40)   2780 97.55 98.74\n",
      "(0.40, 0.50)   2567 97.20 98.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 47/100, Train Loss: 7427.5929, Val Loss: 2595.7012\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 99.38 99.69\n",
      "(0.05, 0.10)   4779 99.01 99.55\n",
      "(0.10, 0.20)   5050 98.44 99.20\n",
      "(0.20, 0.30)   3298 97.80 98.81\n",
      "(0.30, 0.40)   2780 97.55 98.74\n",
      "(0.40, 0.50)   2567 97.21 98.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 48/100, Train Loss: 7420.5187, Val Loss: 2486.5625\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 99.38 99.68\n",
      "(0.05, 0.10)   4779 99.02 99.54\n",
      "(0.10, 0.20)   5050 98.44 99.20\n",
      "(0.20, 0.30)   3298 97.79 98.83\n",
      "(0.30, 0.40)   2780 97.55 98.75\n",
      "(0.40, 0.50)   2567 97.20 98.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 49/100, Train Loss: 7127.0136, Val Loss: 2333.5713\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 99.39 99.69\n",
      "(0.05, 0.10)   4779 99.03 99.55\n",
      "(0.10, 0.20)   5050 98.45 99.21\n",
      "(0.20, 0.30)   3298 97.83 98.83\n",
      "(0.30, 0.40)   2780 97.58 98.75\n",
      "(0.40, 0.50)   2567 97.23 98.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 50/100, Train Loss: 7054.8447, Val Loss: 2646.6006\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 99.40 99.68\n",
      "(0.05, 0.10)   4779 99.04 99.50\n",
      "(0.10, 0.20)   5050 98.47 99.16\n",
      "(0.20, 0.30)   3298 97.84 98.79\n",
      "(0.30, 0.40)   2780 97.60 98.72\n",
      "(0.40, 0.50)   2567 97.24 98.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 51/100, Train Loss: 6928.7379, Val Loss: 2096.1152\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 99.40 99.70\n",
      "(0.05, 0.10)   4779 99.04 99.54\n",
      "(0.10, 0.20)   5050 98.47 99.23\n",
      "(0.20, 0.30)   3298 97.85 98.84\n",
      "(0.30, 0.40)   2780 97.59 98.82\n",
      "(0.40, 0.50)   2567 97.25 98.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 52/100, Train Loss: 6932.0478, Val Loss: 2114.2158\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 99.40 99.70\n",
      "(0.05, 0.10)   4779 99.05 99.56\n",
      "(0.10, 0.20)   5050 98.48 99.23\n",
      "(0.20, 0.30)   3298 97.86 98.87\n",
      "(0.30, 0.40)   2780 97.60 98.79\n",
      "(0.40, 0.50)   2567 97.28 98.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 53/100, Train Loss: 6796.3306, Val Loss: 2113.4053\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 99.41 99.70\n",
      "(0.05, 0.10)   4779 99.06 99.55\n",
      "(0.10, 0.20)   5050 98.49 99.23\n",
      "(0.20, 0.30)   3298 97.86 98.84\n",
      "(0.30, 0.40)   2780 97.62 98.79\n",
      "(0.40, 0.50)   2567 97.27 98.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 54/100, Train Loss: 6819.6903, Val Loss: 2063.3594\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 99.41 99.70\n",
      "(0.05, 0.10)   4779 99.06 99.55\n",
      "(0.10, 0.20)   5050 98.50 99.22\n",
      "(0.20, 0.30)   3298 97.89 98.87\n",
      "(0.30, 0.40)   2780 97.63 98.80\n",
      "(0.40, 0.50)   2567 97.29 98.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 55/100, Train Loss: 6708.5415, Val Loss: 2073.2188\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 99.41 99.71\n",
      "(0.05, 0.10)   4779 99.06 99.56\n",
      "(0.10, 0.20)   5050 98.49 99.22\n",
      "(0.20, 0.30)   3298 97.89 98.85\n",
      "(0.30, 0.40)   2780 97.64 98.77\n",
      "(0.40, 0.50)   2567 97.29 98.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 56/100, Train Loss: 6327.2150, Val Loss: 1893.7109\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 99.42 99.69\n",
      "(0.05, 0.10)   4779 99.08 99.56\n",
      "(0.10, 0.20)   5050 98.51 99.25\n",
      "(0.20, 0.30)   3298 97.90 98.86\n",
      "(0.30, 0.40)   2780 97.66 98.83\n",
      "(0.40, 0.50)   2567 97.32 98.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 57/100, Train Loss: 6489.6673, Val Loss: 1856.9844\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 99.43 99.70\n",
      "(0.05, 0.10)   4779 99.09 99.57\n",
      "(0.10, 0.20)   5050 98.53 99.25\n",
      "(0.20, 0.30)   3298 97.91 98.85\n",
      "(0.30, 0.40)   2780 97.67 98.84\n",
      "(0.40, 0.50)   2567 97.34 98.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 58/100, Train Loss: 6436.8849, Val Loss: 1605.8320\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 99.43 99.71\n",
      "(0.05, 0.10)   4779 99.08 99.57\n",
      "(0.10, 0.20)   5050 98.52 99.27\n",
      "(0.20, 0.30)   3298 97.90 98.90\n",
      "(0.30, 0.40)   2780 97.66 98.82\n",
      "(0.40, 0.50)   2567 97.33 98.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 59/100, Train Loss: 6303.6614, Val Loss: 1619.9365\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 99.43 99.71\n",
      "(0.05, 0.10)   4779 99.10 99.57\n",
      "(0.10, 0.20)   5050 98.54 99.26\n",
      "(0.20, 0.30)   3298 97.93 98.90\n",
      "(0.30, 0.40)   2780 97.69 98.83\n",
      "(0.40, 0.50)   2567 97.35 98.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 60/100, Train Loss: 6186.5854, Val Loss: 1664.3086\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 99.44 99.71\n",
      "(0.05, 0.10)   4779 99.10 99.57\n",
      "(0.10, 0.20)   5050 98.54 99.25\n",
      "(0.20, 0.30)   3298 97.93 98.88\n",
      "(0.30, 0.40)   2780 97.69 98.84\n",
      "(0.40, 0.50)   2567 97.34 98.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 61/100, Train Loss: 5839.4346, Val Loss: 1576.4668\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 99.44 99.72\n",
      "(0.05, 0.10)   4779 99.11 99.57\n",
      "(0.10, 0.20)   5050 98.56 99.27\n",
      "(0.20, 0.30)   3298 97.95 98.91\n",
      "(0.30, 0.40)   2780 97.72 98.84\n",
      "(0.40, 0.50)   2567 97.38 98.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 62/100, Train Loss: 5936.9354, Val Loss: 1486.6484\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 99.44 99.72\n",
      "(0.05, 0.10)   4779 99.11 99.59\n",
      "(0.10, 0.20)   5050 98.56 99.28\n",
      "(0.20, 0.30)   3298 97.94 98.90\n",
      "(0.30, 0.40)   2780 97.71 98.86\n",
      "(0.40, 0.50)   2567 97.38 98.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 63/100, Train Loss: 5881.2808, Val Loss: 1278.0244\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 99.45 99.73\n",
      "(0.05, 0.10)   4779 99.11 99.59\n",
      "(0.10, 0.20)   5050 98.56 99.27\n",
      "(0.20, 0.30)   3298 97.96 98.93\n",
      "(0.30, 0.40)   2780 97.72 98.89\n",
      "(0.40, 0.50)   2567 97.38 98.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 64/100, Train Loss: 5663.1754, Val Loss: 1259.4062\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 99.45 99.72\n",
      "(0.05, 0.10)   4779 99.13 99.59\n",
      "(0.10, 0.20)   5050 98.58 99.30\n",
      "(0.20, 0.30)   3298 97.99 98.92\n",
      "(0.30, 0.40)   2780 97.75 98.87\n",
      "(0.40, 0.50)   2567 97.41 98.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 65/100, Train Loss: 5912.9227, Val Loss: 1290.9678\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 99.46 99.72\n",
      "(0.05, 0.10)   4779 99.13 99.59\n",
      "(0.10, 0.20)   5050 98.58 99.29\n",
      "(0.20, 0.30)   3298 97.97 98.92\n",
      "(0.30, 0.40)   2780 97.73 98.89\n",
      "(0.40, 0.50)   2567 97.40 98.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 66/100, Train Loss: 5839.1770, Val Loss: 1318.3145\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 99.45 99.71\n",
      "(0.05, 0.10)   4779 99.13 99.58\n",
      "(0.10, 0.20)   5050 98.57 99.29\n",
      "(0.20, 0.30)   3298 97.97 98.91\n",
      "(0.30, 0.40)   2780 97.74 98.91\n",
      "(0.40, 0.50)   2567 97.41 98.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 67/100, Train Loss: 5719.5162, Val Loss: 1155.7549\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 99.46 99.73\n",
      "(0.05, 0.10)   4779 99.14 99.58\n",
      "(0.10, 0.20)   5050 98.59 99.30\n",
      "(0.20, 0.30)   3298 97.99 98.94\n",
      "(0.30, 0.40)   2780 97.74 98.91\n",
      "(0.40, 0.50)   2567 97.41 98.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 68/100, Train Loss: 5443.9092, Val Loss: 1082.8545\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 99.46 99.73\n",
      "(0.05, 0.10)   4779 99.13 99.59\n",
      "(0.10, 0.20)   5050 98.59 99.30\n",
      "(0.20, 0.30)   3298 97.99 98.95\n",
      "(0.30, 0.40)   2780 97.77 98.93\n",
      "(0.40, 0.50)   2567 97.42 98.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 69/100, Train Loss: 5377.4412, Val Loss: 1138.8125\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 99.47 99.73\n",
      "(0.05, 0.10)   4779 99.16 99.59\n",
      "(0.10, 0.20)   5050 98.61 99.28\n",
      "(0.20, 0.30)   3298 98.01 98.94\n",
      "(0.30, 0.40)   2780 97.78 98.92\n",
      "(0.40, 0.50)   2567 97.44 98.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 70/100, Train Loss: 5430.2726, Val Loss: 1174.3896\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 99.47 99.72\n",
      "(0.05, 0.10)   4779 99.16 99.60\n",
      "(0.10, 0.20)   5050 98.61 99.30\n",
      "(0.20, 0.30)   3298 98.03 98.97\n",
      "(0.30, 0.40)   2780 97.78 98.94\n",
      "(0.40, 0.50)   2567 97.45 98.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 71/100, Train Loss: 5668.0222, Val Loss: 1140.6230\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 99.47 99.73\n",
      "(0.05, 0.10)   4779 99.15 99.59\n",
      "(0.10, 0.20)   5050 98.59 99.30\n",
      "(0.20, 0.30)   3298 98.01 98.95\n",
      "(0.30, 0.40)   2780 97.76 98.90\n",
      "(0.40, 0.50)   2567 97.43 98.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 72/100, Train Loss: 5152.3154, Val Loss: 1125.0586\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 99.48 99.72\n",
      "(0.05, 0.10)   4779 99.16 99.61\n",
      "(0.10, 0.20)   5050 98.62 99.30\n",
      "(0.20, 0.30)   3298 98.03 98.93\n",
      "(0.30, 0.40)   2780 97.78 98.95\n",
      "(0.40, 0.50)   2567 97.45 98.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 73/100, Train Loss: 4257.8220, Val Loss: 421.6689\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 99.52 99.75\n",
      "(0.05, 0.10)   4779 99.23 99.62\n",
      "(0.10, 0.20)   5050 98.71 99.34\n",
      "(0.20, 0.30)   3298 98.15 99.01\n",
      "(0.30, 0.40)   2780 97.91 98.99\n",
      "(0.40, 0.50)   2567 97.59 98.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 74/100, Train Loss: 4150.2847, Val Loss: 275.6475\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 99.52 99.76\n",
      "(0.05, 0.10)   4779 99.24 99.63\n",
      "(0.10, 0.20)   5050 98.71 99.36\n",
      "(0.20, 0.30)   3298 98.16 99.02\n",
      "(0.30, 0.40)   2780 97.93 98.99\n",
      "(0.40, 0.50)   2567 97.60 98.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 75/100, Train Loss: 4000.4453, Val Loss: 202.3994\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 99.53 99.76\n",
      "(0.05, 0.10)   4779 99.25 99.65\n",
      "(0.10, 0.20)   5050 98.73 99.37\n",
      "(0.20, 0.30)   3298 98.18 99.05\n",
      "(0.30, 0.40)   2780 97.94 98.98\n",
      "(0.40, 0.50)   2567 97.62 98.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 76/100, Train Loss: 4076.4901, Val Loss: 202.3701\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 99.53 99.76\n",
      "(0.05, 0.10)   4779 99.26 99.64\n",
      "(0.10, 0.20)   5050 98.74 99.35\n",
      "(0.20, 0.30)   3298 98.19 99.05\n",
      "(0.30, 0.40)   2780 97.95 99.01\n",
      "(0.40, 0.50)   2567 97.63 98.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 77/100, Train Loss: 4010.2069, Val Loss: 151.6885\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 99.54 99.77\n",
      "(0.05, 0.10)   4779 99.26 99.65\n",
      "(0.10, 0.20)   5050 98.75 99.36\n",
      "(0.20, 0.30)   3298 98.21 99.05\n",
      "(0.30, 0.40)   2780 97.97 99.03\n",
      "(0.40, 0.50)   2567 97.64 98.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 78/100, Train Loss: 3455.2377, Val Loss: 153.3281\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 99.54 99.76\n",
      "(0.05, 0.10)   4779 99.27 99.66\n",
      "(0.10, 0.20)   5050 98.74 99.37\n",
      "(0.20, 0.30)   3298 98.20 99.06\n",
      "(0.30, 0.40)   2780 97.97 99.00\n",
      "(0.40, 0.50)   2567 97.64 98.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 79/100, Train Loss: 3670.4154, Val Loss: 126.6855\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 99.54 99.76\n",
      "(0.05, 0.10)   4779 99.26 99.63\n",
      "(0.10, 0.20)   5050 98.75 99.37\n",
      "(0.20, 0.30)   3298 98.20 99.07\n",
      "(0.30, 0.40)   2780 97.98 99.02\n",
      "(0.40, 0.50)   2567 97.65 98.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 80/100, Train Loss: 3793.2300, Val Loss: 143.6943\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 99.54 99.76\n",
      "(0.05, 0.10)   4779 99.26 99.64\n",
      "(0.10, 0.20)   5050 98.74 99.36\n",
      "(0.20, 0.30)   3298 98.20 99.07\n",
      "(0.30, 0.40)   2780 97.96 99.03\n",
      "(0.40, 0.50)   2567 97.63 98.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 81/100, Train Loss: 3876.7051, Val Loss: 104.2090\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 99.55 99.75\n",
      "(0.05, 0.10)   4779 99.27 99.63\n",
      "(0.10, 0.20)   5050 98.75 99.36\n",
      "(0.20, 0.30)   3298 98.21 99.05\n",
      "(0.30, 0.40)   2780 97.98 99.03\n",
      "(0.40, 0.50)   2567 97.66 98.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 82/100, Train Loss: 3502.7708, Val Loss: 111.7861\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 99.55 99.76\n",
      "(0.05, 0.10)   4779 99.28 99.63\n",
      "(0.10, 0.20)   5050 98.76 99.37\n",
      "(0.20, 0.30)   3298 98.24 99.08\n",
      "(0.30, 0.40)   2780 97.98 99.04\n",
      "(0.40, 0.50)   2567 97.67 98.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 83/100, Train Loss: 3785.3475, Val Loss: -60.3027\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 99.54 99.77\n",
      "(0.05, 0.10)   4779 99.27 99.65\n",
      "(0.10, 0.20)   5050 98.75 99.38\n",
      "(0.20, 0.30)   3298 98.21 99.10\n",
      "(0.30, 0.40)   2780 97.99 99.03\n",
      "(0.40, 0.50)   2567 97.67 98.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 84/100, Train Loss: 3557.2252, Val Loss: -72.9277\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 99.55 99.78\n",
      "(0.05, 0.10)   4779 99.27 99.66\n",
      "(0.10, 0.20)   5050 98.77 99.39\n",
      "(0.20, 0.30)   3298 98.23 99.10\n",
      "(0.30, 0.40)   2780 97.99 99.04\n",
      "(0.40, 0.50)   2567 97.67 98.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 85/100, Train Loss: 3547.0044, Val Loss: -100.4521\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 99.56 99.77\n",
      "(0.05, 0.10)   4779 99.28 99.65\n",
      "(0.10, 0.20)   5050 98.77 99.38\n",
      "(0.20, 0.30)   3298 98.23 99.10\n",
      "(0.30, 0.40)   2780 98.00 99.05\n",
      "(0.40, 0.50)   2567 97.69 98.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 86/100, Train Loss: 3712.5487, Val Loss: -62.0811\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 99.55 99.77\n",
      "(0.05, 0.10)   4779 99.28 99.64\n",
      "(0.10, 0.20)   5050 98.76 99.40\n",
      "(0.20, 0.30)   3298 98.23 99.09\n",
      "(0.30, 0.40)   2780 97.99 99.06\n",
      "(0.40, 0.50)   2567 97.67 98.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 87/100, Train Loss: 3494.6185, Val Loss: -91.4180\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 99.55 99.76\n",
      "(0.05, 0.10)   4779 99.28 99.65\n",
      "(0.10, 0.20)   5050 98.76 99.38\n",
      "(0.20, 0.30)   3298 98.23 99.08\n",
      "(0.30, 0.40)   2780 98.00 99.06\n",
      "(0.40, 0.50)   2567 97.68 98.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 88/100, Train Loss: 3422.9738, Val Loss: -90.5186\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 99.56 99.77\n",
      "(0.05, 0.10)   4779 99.29 99.66\n",
      "(0.10, 0.20)   5050 98.77 99.38\n",
      "(0.20, 0.30)   3298 98.23 99.10\n",
      "(0.30, 0.40)   2780 98.01 99.06\n",
      "(0.40, 0.50)   2567 97.69 98.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 89/100, Train Loss: 3768.8570, Val Loss: -211.8574\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 99.56 99.77\n",
      "(0.05, 0.10)   4779 99.28 99.65\n",
      "(0.10, 0.20)   5050 98.77 99.40\n",
      "(0.20, 0.30)   3298 98.23 99.11\n",
      "(0.30, 0.40)   2780 98.00 99.06\n",
      "(0.40, 0.50)   2567 97.68 98.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 90/100, Train Loss: 3118.6634, Val Loss: -162.3486\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 99.56 99.77\n",
      "(0.05, 0.10)   4779 99.28 99.66\n",
      "(0.10, 0.20)   5050 98.77 99.39\n",
      "(0.20, 0.30)   3298 98.23 99.11\n",
      "(0.30, 0.40)   2780 98.00 99.07\n",
      "(0.40, 0.50)   2567 97.69 98.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 91/100, Train Loss: 3369.7257, Val Loss: -156.2432\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 99.56 99.76\n",
      "(0.05, 0.10)   4779 99.29 99.64\n",
      "(0.10, 0.20)   5050 98.78 99.38\n",
      "(0.20, 0.30)   3298 98.24 99.09\n",
      "(0.30, 0.40)   2780 98.02 99.07\n",
      "(0.40, 0.50)   2567 97.70 98.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 92/100, Train Loss: 3238.5517, Val Loss: -52.1768\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 99.56 99.76\n",
      "(0.05, 0.10)   4779 99.29 99.63\n",
      "(0.10, 0.20)   5050 98.79 99.38\n",
      "(0.20, 0.30)   3298 98.26 99.10\n",
      "(0.30, 0.40)   2780 98.02 99.07\n",
      "(0.40, 0.50)   2567 97.69 98.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 93/100, Train Loss: 3289.3541, Val Loss: -269.7568\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 99.56 99.77\n",
      "(0.05, 0.10)   4779 99.29 99.67\n",
      "(0.10, 0.20)   5050 98.79 99.40\n",
      "(0.20, 0.30)   3298 98.26 99.12\n",
      "(0.30, 0.40)   2780 98.02 99.06\n",
      "(0.40, 0.50)   2567 97.72 98.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 94/100, Train Loss: 3237.1860, Val Loss: -185.4941\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 99.57 99.77\n",
      "(0.05, 0.10)   4779 99.30 99.65\n",
      "(0.10, 0.20)   5050 98.79 99.39\n",
      "(0.20, 0.30)   3298 98.25 99.12\n",
      "(0.30, 0.40)   2780 98.02 99.08\n",
      "(0.40, 0.50)   2567 97.71 98.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 95/100, Train Loss: 3156.1706, Val Loss: -220.2246\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 99.56 99.76\n",
      "(0.05, 0.10)   4779 99.29 99.65\n",
      "(0.10, 0.20)   5050 98.79 99.40\n",
      "(0.20, 0.30)   3298 98.26 99.10\n",
      "(0.30, 0.40)   2780 98.03 99.07\n",
      "(0.40, 0.50)   2567 97.71 98.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 96/100, Train Loss: 3183.8362, Val Loss: -250.4766\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 99.57 99.77\n",
      "(0.05, 0.10)   4779 99.30 99.66\n",
      "(0.10, 0.20)   5050 98.79 99.40\n",
      "(0.20, 0.30)   3298 98.27 99.10\n",
      "(0.30, 0.40)   2780 98.03 99.08\n",
      "(0.40, 0.50)   2567 97.72 98.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 97/100, Train Loss: 3204.6829, Val Loss: -390.9805\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 99.57 99.78\n",
      "(0.05, 0.10)   4779 99.30 99.66\n",
      "(0.10, 0.20)   5050 98.79 99.41\n",
      "(0.20, 0.30)   3298 98.27 99.11\n",
      "(0.30, 0.40)   2780 98.04 99.09\n",
      "(0.40, 0.50)   2567 97.73 98.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 98/100, Train Loss: 3319.7594, Val Loss: -273.1973\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 99.57 99.76\n",
      "(0.05, 0.10)   4779 99.30 99.65\n",
      "(0.10, 0.20)   5050 98.80 99.41\n",
      "(0.20, 0.30)   3298 98.27 99.14\n",
      "(0.30, 0.40)   2780 98.03 99.07\n",
      "(0.40, 0.50)   2567 97.73 98.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 99/100, Train Loss: 3075.7796, Val Loss: -317.3301\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 99.57 99.77\n",
      "(0.05, 0.10)   4779 99.30 99.65\n",
      "(0.10, 0.20)   5050 98.79 99.41\n",
      "(0.20, 0.30)   3298 98.25 99.12\n",
      "(0.30, 0.40)   2780 98.03 99.08\n",
      "(0.40, 0.50)   2567 97.70 98.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2, Epoch 100/100, Train Loss: 3094.1580, Val Loss: -349.4004\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)  15300 99.57 99.78\n",
      "(0.05, 0.10)   4779 99.31 99.66\n",
      "(0.10, 0.20)   5050 98.80 99.40\n",
      "(0.20, 0.30)   3298 98.26 99.16\n",
      "(0.30, 0.40)   2780 98.04 99.07\n",
      "(0.40, 0.50)   2567 97.74 98.91\n"
     ]
    }
   ],
   "source": [
    "for w in range(len(break_points) - 1):\n",
    "    if chunks_done[w]:\n",
    "        print(f\"Skipping chunk {w + 1}/{len(break_points) - 1} due to previous training.\")\n",
    "        continue\n",
    "    if args.which_chunk != -1 and w + 1 != args.which_chunk:\n",
    "        print(f\"Skipping chunk {w + 1}/{len(break_points) - 1} due to your request using --which-chunk.\")\n",
    "        continue\n",
    "\n",
    "    print(f\"Training on chunk {w + 1}/{len(break_points) - 1}\")\n",
    "\n",
    "    # Calculate chunk boundaries\n",
    "    final_start_pos = max(0, break_points[w] - 2 * args.co)\n",
    "    final_end_pos = min(dr.VARIANT_COUNT, break_points[w + 1] + 2 * args.co)\n",
    "    offset_before = break_points[w] - final_start_pos\n",
    "    offset_after = final_end_pos - break_points[w + 1]\n",
    "\n",
    "    # Get data for this chunk\n",
    "    ref_set = dr.get_ref_set(final_start_pos, final_end_pos).astype(np.int32)\n",
    "    print(f\"Data shape: {ref_set.shape}\")\n",
    "\n",
    "    # Remove duplicates from training\n",
    "    ref_set_train = remove_similar_rows(ref_set[x_train_indices])\n",
    "    ref_set_val = ref_set[x_valid_indices]\n",
    "\n",
    "    # MAF bins counts\n",
    "    valid_slice = slice(offset_before,\n",
    "                        ref_set_train.shape[1] - offset_after)\n",
    "    chunk_maf, chunk_bin_cnt = precompute_maf(\n",
    "        ref_set_train[:, valid_slice], \n",
    "        mask_int=-1\n",
    "    )\n",
    "    chunk_maf = torch.from_numpy(chunk_maf).to(device)          # (L_chunk,)\n",
    "    if args.verbose:\n",
    "        print('Chunk MAF-bin counts:', chunk_bin_cnt)\n",
    "\n",
    "    # Create targets (same as input for reconstruction)\n",
    "    target_train = ref_set_train[:, offset_before:ref_set_train.shape[1] - offset_after]\n",
    "    target_val = ref_set_val[:, offset_before:ref_set_val.shape[1] - offset_after]\n",
    "\n",
    "    # Create datasets\n",
    "    train_dataset = GenomicDataset(\n",
    "        ref_set_train, target_train, dr.SEQ_DEPTH,\n",
    "        offset_before, offset_after, training=True,\n",
    "        masking_rates=(args.min_mr, args.max_mr)\n",
    "    )\n",
    "\n",
    "    val_dataset = GenomicDataset(\n",
    "        ref_set_val, target_val, dr.SEQ_DEPTH,\n",
    "        offset_before, offset_after, training=False,\n",
    "        masking_rates=(args.min_mr, args.max_mr)\n",
    "    )\n",
    "\n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=args.batch_size_per_gpu,\n",
    "                                shuffle=True, num_workers=4, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=args.batch_size_per_gpu,\n",
    "                            shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "    # Create model\n",
    "    seq_len = ref_set.shape[1]\n",
    "    model = create_model(args, seq_len, dr.SEQ_DEPTH)\n",
    "    model.offset_before = offset_before\n",
    "    model.offset_after = offset_after\n",
    "    model.to(device)\n",
    "\n",
    "    # Loss and optimizer\n",
    "    criterion = ImputationLoss(use_r2=getattr(args, 'use_r2', True),use_focal=getattr(args, 'use_focal', True))\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
    "    # optimizer = Lamb(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
    "    \n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.5, patience=3, min_lr=1e-7\n",
    "    )\n",
    "\n",
    "    # Training loop\n",
    "    best_loss = float('inf')\n",
    "    patience = args.earlystop_patience\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(args.epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_logits, train_gts, train_mask = [], [], []\n",
    "\n",
    "        train_pbar = tqdm(train_loader, desc=f'Epoch {epoch + 1}/{args.epochs}', leave=False)\n",
    "        for batch_idx, (data, target) in enumerate(train_pbar):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss, logs = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            train_pbar.set_postfix({'loss': loss.item()})\n",
    "\n",
    "            # === 收集训练结果 ===\n",
    "            mask = data[..., -1].bool()         # 只关心被 mask 的位点\n",
    "            train_logits.append(output.detach())\n",
    "            train_gts.append(target.detach())\n",
    "            train_mask.append(mask)\n",
    "\n",
    "        # 训练集 MAF-acc\n",
    "        train_logits = torch.cat(train_logits, dim=0)\n",
    "        train_gts    = torch.cat(train_gts,    dim=0)\n",
    "        train_mask   = torch.cat(train_mask,   dim=0)\n",
    "        # 只保留有效位点（去掉 offset  padding）\n",
    "        if model.offset_before > 0 or model.offset_after > 0:\n",
    "            train_mask   = train_mask  [:, model.offset_before : train_mask.shape[1]  -model.offset_after]\n",
    "        train_maf_accs = imputation_maf_accuracy_epoch(train_logits, train_gts, chunk_maf, mask=train_mask)\n",
    "\n",
    "        # ----------- 验证循环同理 ------------\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_logits, val_gts = [], []\n",
    "        with torch.no_grad():\n",
    "            for data, target in val_loader:\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                output = model(data)\n",
    "                loss, logs = criterion(output, target)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                mask = data[..., -1].bool()\n",
    "                val_logits.append(output)\n",
    "                val_gts.append(target)\n",
    "\n",
    "        val_logits = torch.cat(val_logits, dim=0)\n",
    "        val_gts    = torch.cat(val_gts,    dim=0)\n",
    "        val_maf_accs = imputation_maf_accuracy_epoch(\n",
    "            val_logits, val_gts, chunk_maf,  mask=None,)\n",
    "\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        avg_val_loss   = val_loss   / len(val_loader)\n",
    "\n",
    "        if args.verbose >= 1:\n",
    "            avg_train_loss = train_loss / len(train_loader)\n",
    "            avg_val_loss   = val_loss   / len(val_loader)\n",
    "            print(f'Chunk {w + 1}, Epoch {epoch + 1}/{args.epochs}, '\n",
    "                  f'Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}')\n",
    "\n",
    "            # 用 DataFrame 打印 MAF-bin 结果\n",
    "            maf_df = pd.DataFrame({\n",
    "                'MAF_bin': ['(0.00, 0.05)', '(0.05, 0.10)', '(0.10, 0.20)',\n",
    "                            '(0.20, 0.30)', '(0.30, 0.40)', '(0.40, 0.50)'],\n",
    "                'Counts':  [f\"{c}\" for c in chunk_bin_cnt],\n",
    "                'Train':   [f\"{acc:.2f}\" for acc in train_maf_accs],\n",
    "                'Val':     [f\"{acc:.2f}\" for acc in val_maf_accs]\n",
    "            })\n",
    "            print(maf_df.to_string(index=False))\n",
    "\n",
    "        scheduler.step(avg_val_loss)\n",
    "\n",
    "        # Early stopping\n",
    "        if avg_val_loss < best_loss:\n",
    "            best_loss = avg_val_loss\n",
    "            patience_counter = 0\n",
    "            # Save best model\n",
    "            import os\n",
    "            os.makedirs(f'{args.save_dir}/models', exist_ok=True)\n",
    "            torch.save(model.state_dict(), f'{args.save_dir}/models/w_{w}.pth')\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                if args.verbose >= 1:\n",
    "                    print('Early stopping triggered')\n",
    "                break\n",
    "\n",
    "    # Mark chunk as done\n",
    "    chunks_done[w] = True\n",
    "    save_chunk_status(args.save_dir, chunks_done)\n",
    "\n",
    "    # Clean up\n",
    "    del ref_set, train_dataset, val_dataset, train_loader, val_loader, model\n",
    "    torch.cuda.empty_cache() if torch.cuda.is_available() else None"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
