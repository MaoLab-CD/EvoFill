{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b60ccf3a",
   "metadata": {},
   "source": [
    "ver0: 多 chunk modules 独立权重\n",
    "\n",
    "ver0.1: 加样本特征标签（演化坐标）\n",
    "\n",
    "ver3: chunk-wise 稀疏激活"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4bb00d",
   "metadata": {},
   "source": [
    "## Dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "757312f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os; os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" # 设置GPU\n",
    "from cyvcf2 import VCF\n",
    "import scipy.sparse as sp\n",
    "import shutil\n",
    "from typing import Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from mamba_ssm import Mamba2\n",
    "from mamba_ssm.modules.mamba2_simple import Mamba2Simple as Mamba2Block # 原Mamba2Block"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975df815",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5e956fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenotypeEncoder:\n",
    "    def __init__(self,\n",
    "                 save_dir: str,\n",
    "                 vcf_path: str,\n",
    "                 ref_extra: Optional[str] = None,\n",
    "                 phased: bool = True,\n",
    "                 gts012: bool = False):\n",
    "        self.vcf_path    = vcf_path\n",
    "        self.ref_extra   = ref_extra\n",
    "        self.phased      = phased if ref_extra is None else False # 是否把样本拆成单倍型\n",
    "        self.gts012      = gts012\n",
    "        # 其余成员先占位\n",
    "        self.n_samples   = 0\n",
    "        self.n_variants  = 0\n",
    "        self.sample_ids  = []   # 后面读 VCF 时填充\n",
    "        self.variant_ids = []\n",
    "\n",
    "        self.X_gt        = None   # 最终返回的张量\n",
    "        self.X_extra     = None   # extra 信息\n",
    "        self.seq_depth   = None\n",
    "\n",
    "        # 1) 读 VCF\n",
    "        self.X_gt = self.load_gt()\n",
    "        # 2) 读 extra\n",
    "        self.X_extra = self.load_extra() if self.ref_extra else None\n",
    "\n",
    "    def encode_gt(self, rec, n_samples, phase=False, gts012=True):\n",
    "        \"\"\"\n",
    "        return:\n",
    "            phase=False  -> (n_samples,)          剂量或基因型\n",
    "            phase=True   -> (2*n_samples,)        单倍型\n",
    "\n",
    "        encoding rule:\n",
    "            gts012=True  -> 0/1/2/3  （3=missing）\n",
    "            gts012=False -> 0/1/2/3/…/-1  （0=REF, 1+=ALT, -1=missing）\n",
    "        \"\"\"\n",
    "        n = n_samples\n",
    "\n",
    "        # ---------- 1. 单倍型模式 ----------\n",
    "        if phase:\n",
    "            out = np.empty(2 * n, dtype=np.int8)\n",
    "            for i, gt in enumerate(rec.genotypes):\n",
    "                a1, a2, _phased = gt\n",
    "                # 缺失\n",
    "                if a1 is None:\n",
    "                    out[2*i]   = 3 if gts012 else -1\n",
    "                else:\n",
    "                    if gts012:                      # 压缩成 0/1/2\n",
    "                        out[2*i] = 0 if a1 == 0 else (2 if a1 >= 2 else 1)\n",
    "                    else:                           # 原值保留\n",
    "                        out[2*i] = a1\n",
    "\n",
    "                if a2 is None:\n",
    "                    out[2*i+1] = 3 if gts012 else -1\n",
    "                else:\n",
    "                    if gts012:\n",
    "                        out[2*i+1] = 0 if a2 == 0 else (2 if a2 >= 2 else 1)\n",
    "                    else:\n",
    "                        out[2*i+1] = a2\n",
    "            return out\n",
    "\n",
    "        # ---------- 2. 剂量模式 ----------\n",
    "        else:\n",
    "            out = np.empty(n, dtype=np.int8)\n",
    "            for i, gt in enumerate(rec.genotypes):\n",
    "                a1, a2, _phased = gt\n",
    "                # 缺失\n",
    "                if a1 is None or a2 is None:\n",
    "                    out[i] = 3 if gts012 else -1\n",
    "                else:\n",
    "                    if gts012:\n",
    "                        # 0/1/2 剂量\n",
    "                        out[i] = (1 if a1 > 0 else 0) + (1 if a2 > 0 else 0)\n",
    "                    else:\n",
    "                        # 多等位剂量：把 ALT 编号直接相加\n",
    "                        out[i] = (0 if a1 == 0 else a1) + (0 if a2 == 0 else a2)\n",
    "            return out\n",
    "\n",
    "    def load_extra(self) -> Optional[np.ndarray]:\n",
    "        try:\n",
    "            df = pd.read_csv(self.ref_extra, sep='\\t', index_col=0)\n",
    "            df = df.loc[self.sample_ids]          # 保证与 VCF 样本顺序一致\n",
    "            print(f\"[DATA] Extra dims: {df.shape}\")\n",
    "            return df.values.astype(np.float32)\n",
    "        except Exception as e:\n",
    "            print(f\"[DATA] Extra features skipped: {e}\")\n",
    "            return None\n",
    "\n",
    "    def load_gt(self):\n",
    "        self.save_dir = \"/mnt/qmtang/EvoFill/data/251023_chr22\"\n",
    "        interval = 10000\n",
    "\n",
    "        cols, data, indptr = [], [], [0]\n",
    "\n",
    "        vcf = VCF(self.vcf_path, gts012 = self.gts012)\n",
    "        self.sample_ids = vcf.samples\n",
    "        self.n_samples = len(self.sample_ids)\n",
    "        self.n_variants = 0\n",
    "\n",
    "        for rec in vcf:\n",
    "            vec = self.encode_gt(rec, self.n_samples, phase=self.phased, gts012=self.gts012)\n",
    "            nz_idx = np.flatnonzero(vec)\n",
    "            cols.extend(nz_idx)\n",
    "            data.extend(vec[nz_idx])\n",
    "            indptr.append(indptr[-1] + len(nz_idx))\n",
    "\n",
    "            self.n_variants += 1\n",
    "            self.variant_ids.append(f\"{rec.CHROM}:{rec.POS}_{rec.REF}/{','.join(rec.ALT)}\")\n",
    "            if self.n_variants % interval == 0:\n",
    "                print(f'\\r[DATA] 已编码 {self.n_variants:,} 个位点', end='', flush=True)\n",
    "\n",
    "        print(f'\\r[DATA] 总计 {self.n_variants:,} 个位点  ', flush=True)\n",
    "        vcf.close()\n",
    "\n",
    "        # 根据 phase_mode 决定行数\n",
    "        n_rows = 2 * self.n_samples if self.phased else self.n_samples\n",
    "        M = sp.csc_matrix((data, cols, indptr),\n",
    "                        shape=(n_rows,self.n_variants),\n",
    "                        dtype=np.int8)\n",
    "\n",
    "        print(f'[DATA] 位点矩阵 = {M.shape}，稀疏度 = {M.nnz / (M.shape[0] * M.shape[1]):.2%}')\n",
    "        if self.gts012:\n",
    "            self.seq_depth = M.data.max()+1\n",
    "        else:\n",
    "            M.data[M.data == -1] = M.data.max() + 1\n",
    "            self.seq_depth = M.data.max() + 1\n",
    "        print(f'[DATA] gt alleles = [0 - {M.data.max()}], seq_depth = {self.seq_depth} ({M.data.max()} = 缺失)')\n",
    "\n",
    "        os.makedirs(self.save_dir, exist_ok=True)          # 1. 不存在就创建\n",
    "\n",
    "        # 2. 保存稀疏矩阵\n",
    "        sp.save_npz(os.path.join(self.save_dir, \"gt_matrix.npz\"), M)\n",
    "\n",
    "        # 3. 保存样本列表（顺序与矩阵行对应）\n",
    "        with open(os.path.join(self.save_dir, \"gt_samples.txt\"), \"w\") as f:\n",
    "            if self.phased:                      # 单倍型模式：写成 sample_A / sample_B\n",
    "                for s in self.sample_ids:\n",
    "                    f.write(f\"{s}_A\\n{s}_B\\n\")\n",
    "            else:                               # 剂量模式\n",
    "                for s in self.sample_ids:\n",
    "                    f.write(f\"{s}\\n\")\n",
    "\n",
    "        # 4. 保存变异位点 ID（chr:pos/ref/alt）\n",
    "        with open(os.path.join(self.save_dir, \"gt_variants.txt\"), \"w\") as f:\n",
    "            for vid in self.variant_ids:\n",
    "                f.write(vid + \"\\n\")\n",
    "\n",
    "        print(f\"[DATA] 结果已写入 {self.save_dir}\")\n",
    "        return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d851db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DATA] 总计 99,314 个位点  \n",
      "[DATA] gt matrix = (2404, 99314)，稀疏度 = 28.10%\n",
      "[DATA] gt alleles = [0 - 2], seq_depth = 4 (including missing)\n",
      "[DATA] 结果已写入 /mnt/qmtang/EvoFill/data/251023_chr22\n",
      "[DATA] Extra dims: (2404, 26)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Column sparse matrix of dtype 'int8'\n",
       "\twith 67095358 stored elements and shape (2404, 99314)>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_enc = GenotypeEncoder(\n",
    "    save_dir='/mnt/qmtang/EvoFill/data/251024_ver3_chr22_mini',\n",
    "    vcf_path='/home/qmtang/GitHub/STICI-HPC/data/training_sets/ALL.chr22.training.samples.100k.any.type.0.01.maf.variants.vcf.gz',\n",
    "    ref_extra='/mnt/qmtang/EvoFill/data/251020_ver01_chr22/pop_wasserstein.tsv',\n",
    "    phased= True,\n",
    "    gts012= False)\n",
    "\n",
    "print(gt_enc.n_samples, gt_enc.n_variants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a04e5ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DATA] 总计 1,103,547 个位点  \n",
      "[DATA] 位点矩阵 = (5008, 1103547)，稀疏度 = 3.71%\n",
      "[DATA] gt alleles = [0 - 8], seq_depth = 9 (8 = 缺失)\n",
      "[DATA] 结果已写入 /mnt/qmtang/EvoFill/data/251023_chr22\n",
      "2504 1103547\n"
     ]
    }
   ],
   "source": [
    "gt_enc = GenotypeEncoder(\n",
    "    save_dir='/mnt/qmtang/EvoFill/data/251023_chr22',\n",
    "    vcf_path='/mnt/NAS/Omics/DNA/1kGP/vcf/ALL.chr22.phase3_shapeit2_mvncall_integrated_v5b.20130502.genotypes.vcf.gz',\n",
    "    ref_extra=None,\n",
    "    phased= True,\n",
    "    gts012= False)\n",
    "\n",
    "print(gt_enc.n_samples, gt_enc.n_variants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb96506",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenomicDataset(Dataset):\n",
    "    \"\"\"Dataset class for genomic data with masking for training\"\"\"\n",
    "\n",
    "    def __init__(self, x_gts, x_extra=None, seq_depth=4,\n",
    "                 mask=True, masking_rates=(0.5, 0.99)):\n",
    "        self.gts = x_gts\n",
    "        self.x_extra = x_extra\n",
    "        self.seq_depth = seq_depth\n",
    "        self.mask = mask\n",
    "        self.masking_rates = masking_rates\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.gts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x       = self.gts[idx].copy()\n",
    "        y       = self.gts[idx]\n",
    "        if self.x_extra is not None:\n",
    "            x_extra = self.x_extra[idx]\n",
    "        else:\n",
    "            x_extra = None\n",
    "\n",
    "        if self.mask:\n",
    "            # Apply masking\n",
    "            seq_len = len(x)\n",
    "            masking_rate = np.random.uniform(*self.masking_rates)\n",
    "            mask_size = int(seq_len * masking_rate)\n",
    "            mask_indices = np.random.choice(seq_len, mask_size, replace=False)\n",
    "            x[mask_indices] = self.seq_depth - 1  # Missing value token\n",
    "\n",
    "        # Convert to one-hot\n",
    "        x_onehot = np.eye(self.seq_depth)[x]\n",
    "        y_onehot = np.eye(self.seq_depth - 1)[y]\n",
    "\n",
    "        return torch.FloatTensor(x_onehot),torch.FloatTensor(x_extra), torch.FloatTensor(y_onehot)\n",
    "\n",
    "class ImputationDataset(Dataset):\n",
    "    \"\"\"Dataset for imputation (no masking needed)\"\"\"\n",
    "\n",
    "    def __init__(self, data, seq_depth):\n",
    "        self.data = data\n",
    "        self.seq_depth = seq_depth\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data[idx]\n",
    "        # Convert to one-hot without masking\n",
    "        x_onehot = np.eye(self.seq_depth)[x]\n",
    "        return torch.FloatTensor(x_onehot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c86e007",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac21e2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenoEmbedding(nn.Module):\n",
    "    \"\"\"Genomic embedding layer with positional encoding\"\"\"\n",
    "\n",
    "    def __init__(self, n_alleles, n_snps, d_model):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.n_alleles = n_alleles\n",
    "        self.n_snps = n_snps\n",
    "\n",
    "        # Allele embedding\n",
    "        self.allele_embedding = nn.Parameter(torch.randn(n_alleles, d_model))\n",
    "\n",
    "        # Positional embedding\n",
    "        self.position_embedding = nn.Embedding(n_snps, d_model)\n",
    "\n",
    "        # Initialize parameters\n",
    "        nn.init.xavier_uniform_(self.allele_embedding)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, seq_len, n_alleles) - one-hot encoded\n",
    "        _, seq_len, _ = x.shape\n",
    "\n",
    "        # Allele embedding\n",
    "        embedded = torch.einsum('bsn,nd->bsd', x, self.allele_embedding)\n",
    "\n",
    "        # Positional embedding\n",
    "        positions = torch.arange(seq_len, device=x.device)\n",
    "        pos_emb = self.position_embedding(positions).unsqueeze(0)\n",
    "\n",
    "        return embedded + pos_emb\n",
    "\n",
    "class BiMambaBlock(nn.Module):\n",
    "    \"\"\"Bidirectional Mamba block for genomic sequence processing\"\"\"\n",
    "\n",
    "    def __init__(self, d_model, d_state=16, d_conv=4, expand=2):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "\n",
    "        # Forward and backward Mamba blocks\n",
    "        self.mamba_forward = Mamba2(\n",
    "            d_model=d_model,\n",
    "            d_state=d_state,\n",
    "            d_conv=d_conv,\n",
    "            expand=expand\n",
    "        )\n",
    "\n",
    "        self.mamba_backward = Mamba2(\n",
    "            d_model=d_model,\n",
    "            d_state=d_state,\n",
    "            d_conv=d_conv,\n",
    "            expand=expand\n",
    "        )\n",
    "\n",
    "        # Layer normalization\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "\n",
    "        # FFN\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(d_model * 2, d_model * 4),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(d_model * 4, d_model),\n",
    "            nn.GELU()\n",
    "        )\n",
    "\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, seq_len, d_model)\n",
    "        residual = x\n",
    "\n",
    "        # Bidirectional processing\n",
    "        x_norm = self.norm1(x)\n",
    "\n",
    "        # Forward direction\n",
    "        forward_out = self.mamba_forward(x_norm)\n",
    "\n",
    "        # Backward direction (flip sequence)\n",
    "        x_backward = torch.flip(x_norm, dims=[1])\n",
    "        backward_out = self.mamba_backward(x_backward)\n",
    "        backward_out = torch.flip(backward_out, dims=[1])\n",
    "\n",
    "        # Concatenate bidirectional outputs\n",
    "        bi_out = torch.cat([forward_out, backward_out], dim=-1)\n",
    "\n",
    "        # FFN\n",
    "        ffn_out = self.ffn(bi_out)\n",
    "        ffn_out = self.dropout(ffn_out)\n",
    "\n",
    "        # Residual connection\n",
    "        out = self.norm2(residual + ffn_out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    \"\"\"Convolutional block for local pattern extraction\"\"\"\n",
    "\n",
    "    def __init__(self, d_model):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "\n",
    "        self.conv1 = nn.Conv1d(d_model, d_model, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(d_model, d_model, kernel_size=5, padding=2)\n",
    "        self.conv3 = nn.Conv1d(d_model, d_model, kernel_size=7, padding=3)\n",
    "\n",
    "        self.conv_large1 = nn.Conv1d(d_model, d_model, kernel_size=7, padding=3)\n",
    "        self.conv_large2 = nn.Conv1d(d_model, d_model, kernel_size=15, padding=7)\n",
    "\n",
    "        self.conv_final = nn.Conv1d(d_model, d_model, kernel_size=3, padding=1)\n",
    "        self.conv_reduce = nn.Conv1d(d_model, d_model, kernel_size=1)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(d_model)\n",
    "        self.bn2 = nn.BatchNorm1d(d_model)\n",
    "\n",
    "        self.gelu = nn.GELU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, seq_len, d_model)\n",
    "        x = x.transpose(1, 2)  # (batch, d_model, seq_len)\n",
    "\n",
    "        xa = self.gelu(self.conv1(x))\n",
    "\n",
    "        xb = self.gelu(self.conv2(xa))\n",
    "        xb = self.gelu(self.conv3(xb))\n",
    "\n",
    "        xc = self.gelu(self.conv_large1(xa))\n",
    "        xc = self.gelu(self.conv_large2(xc))\n",
    "\n",
    "        xa = xb + xc\n",
    "        xa = self.gelu(self.conv_final(xa))\n",
    "        xa = self.bn1(xa)\n",
    "        xa = self.gelu(self.conv_reduce(xa))\n",
    "        xa = self.bn2(xa)\n",
    "        xa = self.gelu(xa)\n",
    "\n",
    "        return xa.transpose(1, 2)  # (batch, seq_len, d_model)\n",
    "\n",
    "class ExtraEmbedding(nn.Module):\n",
    "    \"\"\"\n",
    "    输入:  (B, L)        L == extra_dim\n",
    "    输出: (B, L, d_model)\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        d_model: int,\n",
    "        d_state: int = 64,\n",
    "        d_conv: int  = 4,\n",
    "        expand: int  = 2,\n",
    "        headdim: int = 128,\n",
    "        ngroups: int = 1,\n",
    "        dropout: float = 0.1,\n",
    "        **mamba_kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.d_model   = d_model\n",
    "\n",
    "        # 1. 把 (B, L) 的 1-d 标量升到 d_model\n",
    "        self.in_proj = nn.Linear(1, d_model, bias=False)\n",
    "\n",
    "        # 2. 官方 Mamba2Simple：把 L 当序列长度，建模 L↔L\n",
    "        self.mamba = Mamba2Block(\n",
    "            d_model=d_model,\n",
    "            d_state=d_state,\n",
    "            d_conv=d_conv,\n",
    "            expand=expand,\n",
    "            headdim=headdim,\n",
    "            ngroups=ngroups,\n",
    "            **mamba_kwargs\n",
    "        )\n",
    "\n",
    "        # 3. Norm\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        \"\"\"\n",
    "        x: (B, L)  连续值或离散索引\n",
    "        \"\"\"\n",
    "        # (B, L) -> (B, L, 1) -> (B, L, d_model)\n",
    "        h = self.in_proj(x.unsqueeze(-1).float())   # 1-d 投影\n",
    "\n",
    "        h = self.norm(h)\n",
    "\n",
    "        # Mamba2Simple 要求输入 (B, L, d_model) 即可\n",
    "        out = self.mamba(h)                           # SSD 全局建模\n",
    "        return out\n",
    "\n",
    "class StackMambaBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        d_model,\n",
    "        d_state=64,\n",
    "        d_conv=4,\n",
    "        expand=2,\n",
    "        headdim=128,\n",
    "        ngroups=1,\n",
    "        chunk_size=256,\n",
    "        dropout=0.0,\n",
    "        d_embed_dropout=0.0,\n",
    "        device=None,\n",
    "        dtype=None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "\n",
    "        # 距离矩阵嵌入\n",
    "        self.extra_embed = ExtraEmbedding(d_model=d_model, dropout=d_embed_dropout)\n",
    "\n",
    "        # 原归一化\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "\n",
    "        # SSD 核心\n",
    "        self.ssd = Mamba2Block(\n",
    "            d_model=d_model,\n",
    "            d_state=d_state,\n",
    "            d_conv=d_conv,\n",
    "            expand=expand,\n",
    "            headdim=headdim,\n",
    "            ngroups=ngroups,\n",
    "            chunk_size=chunk_size,\n",
    "            use_mem_eff_path=True,\n",
    "            device=device,\n",
    "            dtype=dtype,\n",
    "        )\n",
    "\n",
    "        # FFN\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model // 2),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_model // 2, d_model),\n",
    "        )\n",
    "\n",
    "    def forward(self, local_repr, global_repr, x_extra=None,\n",
    "                start_offset=0, end_offset=0):\n",
    "        \"\"\"\n",
    "        local_repr: (B, L, D)\n",
    "        global_repr: (B, G, D)\n",
    "        x_extra: 可选，(B,E) \n",
    "        \"\"\"\n",
    "        local_norm  = self.norm1(local_repr)\n",
    "        global_norm = self.norm2(global_repr)\n",
    "\n",
    "        # 1. 构造输入序列\n",
    "        tokens = []\n",
    "        if x_extra is not None:\n",
    "            extra_token = self.extra_embed(x_extra)        # (B,E,D)\n",
    "            tokens.append(extra_token)\n",
    "        tokens.append(global_norm)\n",
    "        tokens.append(local_norm)\n",
    "        x = torch.cat(tokens, dim=1)               # [B, (E)+G+L, D]\n",
    "\n",
    "        # 2. SSD 扫描\n",
    "        x = self.ssd(x)                            # [B, (E)+G+L, D]\n",
    "\n",
    "        # 3. 只取 local 部分\n",
    "        local_len = local_norm.shape[1]\n",
    "        x = x[:, -local_len:, :]                   # [B, L, D]\n",
    "\n",
    "        # 4. pad 回原始长度\n",
    "        if start_offset or end_offset:\n",
    "            x = F.pad(x, (0, 0, start_offset, end_offset))\n",
    "\n",
    "        # 5. 残差 + FFN\n",
    "        x = x + local_norm\n",
    "        x = self.norm3(x)\n",
    "        x = self.ffn(x) + x\n",
    "        return x\n",
    "\n",
    "class ChunkModule(nn.Module):\n",
    "    \"\"\"Single chunk processing module with BiMamba\"\"\"\n",
    "\n",
    "    def __init__(self, d_model, dropout_rate=0.2):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "\n",
    "        # BiMamba block\n",
    "        self.bimamba_block = BiMambaBlock(d_model)\n",
    "\n",
    "        # Convolutional blocks\n",
    "        self.conv_block1 = ConvBlock(d_model)\n",
    "        self.conv_block2 = ConvBlock(d_model)\n",
    "        self.conv_block3 = ConvBlock(d_model)\n",
    "        self.conv_block4 = ConvBlock(d_model)\n",
    "\n",
    "        # Cross attention\n",
    "        # self.cross_attention = CrossAttentionLayer(d_model, n_heads)\n",
    "        self.cross_attention = StackMambaBlock(\n",
    "            d_model=d_model,\n",
    "            d_state=64,\n",
    "            d_conv=4,\n",
    "            expand=2,\n",
    "            headdim=128,\n",
    "            ngroups=1,\n",
    "            chunk_size=256,\n",
    "        )\n",
    "\n",
    "        # Additional layers\n",
    "        self.dense = nn.Linear(d_model, d_model)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.gelu = nn.GELU()\n",
    "\n",
    "    def forward(self, x, x_extra=None):\n",
    "        # BiMamba processing\n",
    "        xa0 = self.bimamba_block(x)\n",
    "\n",
    "        # First conv block\n",
    "        xa = self.conv_block1(xa0)\n",
    "        xa_skip = self.conv_block2(xa)\n",
    "\n",
    "        # Dense layer\n",
    "        xa = self.gelu(self.dense(xa))\n",
    "        xa = self.conv_block3(xa)\n",
    "\n",
    "        # Cross attention\n",
    "        xa = self.cross_attention(xa, xa0, x_extra)\n",
    "        xa = self.dropout(xa)\n",
    "\n",
    "        # Final conv block\n",
    "        xa = self.conv_block4(xa)\n",
    "\n",
    "        # Concatenate with skip connection\n",
    "        xa = torch.cat([xa_skip, xa], dim=-1)\n",
    "\n",
    "        return xa\n",
    "\n",
    "class LongRangeModule(nn.Module):\n",
    "    \"\"\"\n",
    "        total_sites   : 序列最大长度（决定 Embedding 词表大小）\n",
    "        d_model   : 输入特征维\n",
    "        chunk_size: 距离阈值\n",
    "        cos_cutoff: 余弦相似度绝对值阈值\n",
    "        d_emb     : embedding 维，默认 d_model//2\n",
    "    \"\"\"\n",
    "    def __init__(self, total_sites, d_model, chunk_size=128, cos_cutoff=0.8, d_emb=None):\n",
    "        super().__init__()\n",
    "        self.total_sites = total_sites\n",
    "        self.d_model = d_model\n",
    "        self.chunk_size = chunk_size\n",
    "        self.cos_cutoff = cos_cutoff\n",
    "        self.d_emb = d_emb or (d_model // 2)\n",
    "\n",
    "        # 两个稀疏梯度 的 Embedding\n",
    "        self.emb_i = nn.Embedding(self.total_sites, self.d_emb, sparse=True)\n",
    "        self.emb_j = nn.Embedding(self.total_sites, self.d_emb, sparse=True)\n",
    "\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        \"\"\"\n",
    "        x    : (B, L, d_model)\n",
    "        mask : (L,)  0/1 或 True/False\n",
    "        return: 同 shape 的 x_out\n",
    "        \"\"\"\n",
    "        # 1. 有效位点\n",
    "        idx = torch.where(mask == 1)[0]          # (N_valid,)\n",
    "        N_valid = idx.size(0)\n",
    "        if N_valid == 0:\n",
    "            return x\n",
    "\n",
    "        # 2. 距离矩阵 & 是否有 far j\n",
    "        dist = torch.abs(idx[:, None] - idx[None, :])          # (N_valid, N_valid)\n",
    "        far_mask = dist > self.chunk_size\n",
    "        if far_mask.sum() == 0:           # 一个 far j 都没有直接返回\n",
    "            return x \n",
    "\n",
    "        emb_i_w = self.emb_i(idx)\n",
    "        emb_j_w = self.emb_j(idx)\n",
    "        cos_sim = torch.abs(F.cosine_similarity(emb_i_w.unsqueeze(1),\n",
    "                                                emb_j_w.unsqueeze(0), dim=-1))\n",
    "\n",
    "        # 4. 过滤\n",
    "        valid_j_mask = far_mask & (cos_sim > self.cos_cutoff)\n",
    "\n",
    "        # 5. 加权更新\n",
    "        x_out = x.clone()\n",
    "        for row, i_global in enumerate(idx):\n",
    "            j_local_mask = valid_j_mask[row]\n",
    "            num_j = j_local_mask.sum()\n",
    "            if num_j == 0:\n",
    "                continue\n",
    "            j_local = torch.where(j_local_mask)[0]\n",
    "            j_global = idx[j_local]\n",
    "            weights = cos_sim[row, j_local] / num_j\n",
    "            xj_weighted = (x[:, j_global] * weights.view(1, -1, 1)).sum(dim=1)\n",
    "            x_out[:, i_global] = (x[:, i_global] + xj_weighted) / 2\n",
    "        return x_out\n",
    "\n",
    "class GlobalOut(nn.Module):\n",
    "    def __init__(self,\n",
    "                 d_model: int,\n",
    "                 n_alleles: int,\n",
    "                 total_sites: int,\n",
    "                 chunk_size: int,\n",
    "                 cos_cutoff: float = 0.8):\n",
    "        super().__init__()\n",
    "        self.proj_in = nn.Linear(2 * d_model, d_model//2)\n",
    "        self.long_range = LongRangeModule(\n",
    "                total_sites=total_sites,\n",
    "                d_model=d_model//2,\n",
    "                chunk_size=chunk_size,\n",
    "                cos_cutoff=cos_cutoff\n",
    "            )\n",
    "        self.proj_out = nn.Linear(d_model//2, n_alleles - 1)\n",
    "\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        x = self.proj_in(x)                       # (B, L, d_model)\n",
    "        x = self.long_range(x, mask)              # + 稀疏长程信号\n",
    "        x = self.proj_out(x)                      # (B, L, n_alleles-1)\n",
    "        x = torch.where(mask.unsqueeze(0).unsqueeze(-1).bool(),\n",
    "                        x, torch.tensor(-float('inf'), device=x.device))\n",
    "        return F.softmax(x, dim=-1)\n",
    "\n",
    "class EvoFill(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        d_model: int,\n",
    "        n_alleles: int,\n",
    "        total_sites: int,\n",
    "        chunk_size: int = 8192,\n",
    "        chunk_overlap: int = 64,\n",
    "        dropout_rate: float = 0.1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.n_alleles = n_alleles\n",
    "        self.total_sites = total_sites\n",
    "        self.chunk_size = chunk_size\n",
    "        self.chunk_overlap = chunk_overlap\n",
    "\n",
    "        # 1. chunk 边界\n",
    "        stride = chunk_size - chunk_overlap\n",
    "        starts = [i * stride for i in range((total_sites - 1) // stride + 1)]\n",
    "        ends = [min(s + chunk_size, total_sites) for s in starts]\n",
    "        self.register_buffer(\"starts\", torch.tensor(starts, dtype=torch.long))\n",
    "        self.register_buffer(\"ends\", torch.tensor(ends, dtype=torch.long))\n",
    "        self.n_chunks = len(starts)\n",
    "\n",
    "        # 2. 每 chunk 一份嵌入 & 处理模块（常驻 GPU，但训练时只激活一个）\n",
    "        self.chunk_embeds = nn.ModuleList(\n",
    "            GenoEmbedding(n_alleles, e - s, d_model) for s, e in zip(starts, ends)\n",
    "        )\n",
    "        self.chunk_modules = nn.ModuleList(\n",
    "            ChunkModule(d_model, dropout_rate) for s, e in zip(starts, ends)\n",
    "        )\n",
    "\n",
    "        # 3. 全局输出层（始终 GPU）\n",
    "        self.global_out = GlobalOut(d_model, n_alleles, total_sites, chunk_size)\n",
    "\n",
    "        # 4. chunk 掩码表  (n_chunks, L)\n",
    "        masks = torch.stack(\n",
    "            [torch.arange(total_sites).ge(s) & torch.arange(total_sites).lt(e)\n",
    "             for s, e in zip(starts, ends)]\n",
    "        ).float()\n",
    "        self.register_buffer(\"chunk_masks\", masks)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, chunk_id: int,\n",
    "                x_extra: Optional[torch.Tensor] = None):\n",
    "        \"\"\"\n",
    "        x:       (B, len, n_alleles)  对应chunk部分的序列 one-hot\n",
    "        chunk_id: 0..n_chunks-1\n",
    "        x_extra:  (B, extra_dim) or None\n",
    "        return:   (B, len, n_alleles-1)  对应chunk部分的softmax 概率\n",
    "        \"\"\"\n",
    "        B, _ , _ = x.shape\n",
    "        device = x.device\n",
    "        s, e = self.starts[chunk_id].item(), self.ends[chunk_id].item()\n",
    "        mask = self.chunk_masks[chunk_id]          # (L,)  当前 chunk 覆盖区\n",
    "\n",
    "        # 1. 确保输入 x 的形状与对应 chunk 吻合\n",
    "        assert x.shape[1] == e-s\n",
    "\n",
    "        # 2. 当前 chunk 嵌入 & 处理\n",
    "        z = self.chunk_embeds[chunk_id](x)   # (B, len, d_model)\n",
    "        z = self.chunk_modules[chunk_id](z, x_extra)  # (B, len, 2*d_model)\n",
    "\n",
    "        # 3. 拼回全长度，其余 nan\n",
    "        z_full = torch.full((B, self.total_sites, 2 * self.d_model), float('nan'), device=device)\n",
    "        z_full[:, s:e] = z                        # (B, L, 2*d_model)\n",
    "\n",
    "        # 4. 全局卷积只激活带状区\n",
    "        out = self.global_out(z_full, mask)       # (B, L, n_alleles-1)\n",
    "        \n",
    "        # 5. 只返回对应chunk的logits\n",
    "        return out[:, torch.where(mask)[0]]    # (B, len, n_alleles-1)\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def infer(self, x: torch.Tensor,\n",
    "              x_extra: Optional[torch.Tensor] = None) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        推理接口：遍历全部 chunk，重叠区特征取平均，再统一过全局卷积\n",
    "        x:       (B, L, n_alleles)\n",
    "        x_extra: (B, extra_dim)\n",
    "        return:  (B, L, n_alleles-1)  softmax 概率\n",
    "        \"\"\"\n",
    "        B, L, _ = x.shape\n",
    "        device = x.device\n",
    "        d_out = 2 * self.d_model          # z 通道数\n",
    "\n",
    "        # 累加器\n",
    "        z_sum = torch.zeros(B, d_out, L, device=device)   # (B, 2*d_model, L)\n",
    "        z_cnt = torch.zeros(1, 1, L, device=device)        # (1, 1, L)\n",
    "\n",
    "        # 1. 遍历所有 chunk，拼回全长度并累加\n",
    "        for cid in range(self.n_chunks):\n",
    "            mask = self.chunk_masks[cid]          # (L,)  0/1\n",
    "            idx  = torch.where(mask)[0]           # 当前 chunk 位点\n",
    "            s, e = self.starts[cid].item(), self.ends[cid].item()\n",
    "\n",
    "            # 与 forward 完全相同：chunk -> z\n",
    "            x_slice = x[:, s:e]\n",
    "            z = self.chunk_embeds[cid](x_slice)\n",
    "            z = self.chunk_modules[cid](z, x_extra)        # (B, len, 2*d_model)\n",
    "            z = z.transpose(1, 2)                          # (B, 2*d_model, len)\n",
    "\n",
    "            # 写回全长度 & 累加\n",
    "            z_sum[..., idx] += z[..., idx - s]             # 局部→全局对齐\n",
    "            z_cnt[..., idx] += 1\n",
    "\n",
    "        # 2. 重叠区平均\n",
    "        z_full = z_sum / z_cnt.clamp_min(1.0)              # (B, 2*d_model, L)\n",
    "\n",
    "        # 3. 统一过全局卷积一次\n",
    "        #    global_out 需要 mask：全 1 即可（所有位点都有效）\n",
    "        full_mask = torch.ones(L, dtype=torch.float, device=device)\n",
    "        return self.global_out(z_full, full_mask)          # (B, L, n_alleles-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f053a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train: torch.Size([4, 12345, 3])\n",
      "x_extra: torch.Size([4, 10])\n",
      "y_train: torch.Size([4, 12345, 2])\n",
      "\n",
      "model chunks: 4\n",
      "\n",
      "\n",
      "x_train: torch.Size([4, 12345, 3])\n",
      "x_extra: torch.Size([4, 10])\n",
      "pred: torch.Size([4, 12345, 2])\n",
      "pred_band: torch.Size([4, 4096, 2])\n",
      "y_band: torch.Size([4, 4096, 2])\n",
      "chunk 0/3 | epoch 1/3 | loss 1.3536\n",
      "\n",
      "x_train: torch.Size([4, 12345, 3])\n",
      "x_extra: torch.Size([4, 10])\n",
      "pred: torch.Size([4, 12345, 2])\n",
      "pred_band: torch.Size([4, 4096, 2])\n",
      "y_band: torch.Size([4, 4096, 2])\n",
      "chunk 0/3 | epoch 2/3 | loss 1.2774\n",
      "\n",
      "x_train: torch.Size([4, 12345, 3])\n",
      "x_extra: torch.Size([4, 10])\n",
      "pred: torch.Size([4, 12345, 2])\n",
      "pred_band: torch.Size([4, 4096, 2])\n",
      "y_band: torch.Size([4, 4096, 2])\n",
      "chunk 0/3 | epoch 3/3 | loss 1.2199\n",
      "\n",
      "x_train: torch.Size([4, 12345, 3])\n",
      "x_extra: torch.Size([4, 10])\n",
      "pred: torch.Size([4, 12345, 2])\n",
      "pred_band: torch.Size([4, 4096, 2])\n",
      "y_band: torch.Size([4, 4096, 2])\n",
      "chunk 1/3 | epoch 1/3 | loss 1.3241\n",
      "\n",
      "x_train: torch.Size([4, 12345, 3])\n",
      "x_extra: torch.Size([4, 10])\n",
      "pred: torch.Size([4, 12345, 2])\n",
      "pred_band: torch.Size([4, 4096, 2])\n",
      "y_band: torch.Size([4, 4096, 2])\n",
      "chunk 1/3 | epoch 2/3 | loss 1.2441\n",
      "\n",
      "x_train: torch.Size([4, 12345, 3])\n",
      "x_extra: torch.Size([4, 10])\n",
      "pred: torch.Size([4, 12345, 2])\n",
      "pred_band: torch.Size([4, 4096, 2])\n",
      "y_band: torch.Size([4, 4096, 2])\n",
      "chunk 1/3 | epoch 3/3 | loss 1.1981\n",
      "\n",
      "x_train: torch.Size([4, 12345, 3])\n",
      "x_extra: torch.Size([4, 10])\n",
      "pred: torch.Size([4, 12345, 2])\n",
      "pred_band: torch.Size([4, 4096, 2])\n",
      "y_band: torch.Size([4, 4096, 2])\n",
      "chunk 2/3 | epoch 1/3 | loss 1.3014\n",
      "\n",
      "x_train: torch.Size([4, 12345, 3])\n",
      "x_extra: torch.Size([4, 10])\n",
      "pred: torch.Size([4, 12345, 2])\n",
      "pred_band: torch.Size([4, 4096, 2])\n",
      "y_band: torch.Size([4, 4096, 2])\n",
      "chunk 2/3 | epoch 2/3 | loss 1.2271\n",
      "\n",
      "x_train: torch.Size([4, 12345, 3])\n",
      "x_extra: torch.Size([4, 10])\n",
      "pred: torch.Size([4, 12345, 2])\n",
      "pred_band: torch.Size([4, 4096, 2])\n",
      "y_band: torch.Size([4, 4096, 2])\n",
      "chunk 2/3 | epoch 3/3 | loss 1.1826\n",
      "\n",
      "x_train: torch.Size([4, 12345, 3])\n",
      "x_extra: torch.Size([4, 10])\n",
      "pred: torch.Size([4, 12345, 2])\n",
      "pred_band: torch.Size([4, 249, 2])\n",
      "y_band: torch.Size([4, 249, 2])\n",
      "chunk 3/3 | epoch 1/3 | loss 1.2414\n",
      "\n",
      "x_train: torch.Size([4, 12345, 3])\n",
      "x_extra: torch.Size([4, 10])\n",
      "pred: torch.Size([4, 12345, 2])\n",
      "pred_band: torch.Size([4, 249, 2])\n",
      "y_band: torch.Size([4, 249, 2])\n",
      "chunk 3/3 | epoch 2/3 | loss 1.0831\n",
      "\n",
      "x_train: torch.Size([4, 12345, 3])\n",
      "x_extra: torch.Size([4, 10])\n",
      "pred: torch.Size([4, 12345, 2])\n",
      "pred_band: torch.Size([4, 249, 2])\n",
      "y_band: torch.Size([4, 249, 2])\n",
      "chunk 3/3 | epoch 3/3 | loss 1.0537\n"
     ]
    }
   ],
   "source": [
    "# ---------- 假数据 ----------\n",
    "B, L, A = 4, 12345, 3\n",
    "d_model = 64\n",
    "chunk_size, overlap = 4096, 64\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "x_train = torch.zeros(B, L, A, device=device)\n",
    "allele = torch.randint(0, A, (B, L), device=device)\n",
    "x_train.scatter_(2, allele.unsqueeze(-1), 1)\n",
    "x_extra = torch.randn(B, 10, device=device)\n",
    "y_train = torch.randn(B, L, A-1, device=device)\n",
    "\n",
    "print(f\"x_train: {x_train.shape}\")\n",
    "print(f\"x_extra: {x_extra.shape}\")\n",
    "print(f\"y_train: {y_train.shape}\")\n",
    "print(\"\")\n",
    "# ---------- 模型 &损失 ----------\n",
    "model = EvoFill(d_model, A, L, chunk_size, overlap).to(device)\n",
    "print(f\"model chunks: {model.n_chunks}\")\n",
    "criterion = nn.MSELoss(reduction='mean')\n",
    "\n",
    "# ---------- 训练循环 ----------\n",
    "epochs_per_chunk = 3\n",
    "for cid in range(model.n_chunks):\n",
    "    mask = model.chunk_masks[cid]\n",
    "    idx = torch.where(mask)[0]\n",
    "    x_band = x_train[:,idx]\n",
    "    y_band = y_train[:,idx]\n",
    "    print(f\"x_band: {x_band.shape}\")\n",
    "    print(f\"x_extra: {x_extra.shape}\")\n",
    "    print(f\"y_band: {y_band.shape}\")\n",
    "    opt = torch.optim.AdamW(\n",
    "        list(model.chunk_embeds[cid].parameters()) +\n",
    "        list(model.chunk_modules[cid].parameters()) +\n",
    "        list(model.global_out.parameters()), lr=3e-4)\n",
    "    for epoch in range(epochs_per_chunk):\n",
    "        opt.zero_grad()\n",
    "        pred = model(x_band, cid, x_extra)\n",
    "\n",
    "        loss = criterion(pred, y_band)        # 默认 reduction='mean'\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        print(\"\")\n",
    "\n",
    "        print(f\"pred: {pred.shape}\")\n",
    "        print(f'chunk {cid}/{model.n_chunks-1} | epoch {epoch+1}/{epochs_per_chunk} | loss {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce8c794",
   "metadata": {},
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6f2206",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImputationLoss(nn.Module):\n",
    "    \"\"\"Custom loss function for genomic imputation\"\"\"\n",
    "\n",
    "    def __init__(self, use_r2=True):\n",
    "        super().__init__()\n",
    "        self.use_r2_loss = use_r2\n",
    "        self.ce_loss = nn.CrossEntropyLoss(reduction='sum')\n",
    "        self.kl_loss = nn.KLDivLoss(reduction='sum')\n",
    "\n",
    "    def calculate_minimac_r2(self, pred_alt_allele_probs, gt_alt_af):\n",
    "        \"\"\"Calculate Minimac-style RÂ² metric\"\"\"\n",
    "        mask = torch.logical_or(torch.eq(gt_alt_af, 0.0), torch.eq(gt_alt_af, 1.0))\n",
    "        gt_alt_af = torch.where(mask, 0.5, gt_alt_af)\n",
    "        denom = gt_alt_af * (1.0 - gt_alt_af)\n",
    "        denom = torch.where(denom < 0.01, 0.01, denom)\n",
    "        r2 = torch.mean(torch.square(pred_alt_allele_probs - gt_alt_af), dim=0) / denom\n",
    "        r2 = torch.where(mask, torch.zeros_like(r2), r2)\n",
    "        return r2\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        y_true = y_true.float()\n",
    "\n",
    "        # Convert to proper format for losses\n",
    "        y_true_ce = torch.argmax(y_true, dim=-1)  # For CrossEntropy\n",
    "        y_pred_log = torch.log(y_pred + 1e-8)  # For KL divergence\n",
    "\n",
    "        # Basic losses\n",
    "        ce_loss = self.ce_loss(y_pred.view(-1, y_pred.size(-1)), y_true_ce.view(-1))\n",
    "        kl_loss = self.kl_loss(y_pred_log.view(-1, y_pred.size(-1)),\n",
    "                               y_true.view(-1, y_true.size(-1)))\n",
    "\n",
    "        total_loss = ce_loss + kl_loss\n",
    "\n",
    "        if self.use_r2_loss:\n",
    "            batch_size = y_true.size(0)\n",
    "            group_size = 4\n",
    "            num_full_groups = batch_size // group_size\n",
    "\n",
    "            if num_full_groups > 0:\n",
    "                y_true_grouped = y_true[:num_full_groups * group_size].view(\n",
    "                    num_full_groups, group_size, *y_true.shape[1:])\n",
    "                y_pred_grouped = y_pred[:num_full_groups * group_size].view(\n",
    "                    num_full_groups, group_size, *y_pred.shape[1:])\n",
    "\n",
    "                r2_loss = 0.0\n",
    "                for i in range(num_full_groups):\n",
    "                    gt_alt_af = torch.count_nonzero(\n",
    "                        torch.argmax(y_true_grouped[i], dim=-1), dim=0\n",
    "                    ).float() / group_size\n",
    "\n",
    "                    pred_alt_allele_probs = torch.sum(y_pred_grouped[i][:, :, 1:], dim=-1)\n",
    "                    r2_loss += -torch.sum(self.calculate_minimac_r2(\n",
    "                        pred_alt_allele_probs, gt_alt_af)) * group_size\n",
    "\n",
    "                total_loss += r2_loss\n",
    "\n",
    "        return total_loss, None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d0ff63",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c6b0e7",
   "metadata": {},
   "source": [
    "工具函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb648d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_directories(save_dir, models_dir=\"models\", outputs=\"out\") -> None:\n",
    "    \"\"\"Create necessary directories\"\"\"\n",
    "    for dd in [save_dir, f\"{save_dir}/{models_dir}\", f\"{save_dir}/{outputs}\"]:\n",
    "        if not os.path.exists(dd):\n",
    "            os.makedirs(dd)\n",
    "\n",
    "def clear_dir(path) -> None:\n",
    "    \"\"\"Clear directory if it exists\"\"\"\n",
    "    if os.path.exists(path):\n",
    "        shutil.rmtree(path)\n",
    "\n",
    "MAF_BINS = [(0.00, 0.05), (0.05, 0.10), (0.10, 0.20),\n",
    "            (0.20, 0.30), (0.30, 0.40), (0.40, 0.50)]\n",
    "\n",
    "def precompute_maf(gts_np, mask_int=-1):\n",
    "    \"\"\"\n",
    "    gts_np: (N, L)  int64\n",
    "    return:\n",
    "        maf: (L,) float32\n",
    "        bin_cnt: list[int] 长度 6，对应 6 个 bin 的位点数量\n",
    "    \"\"\"\n",
    "    L = gts_np.shape[1]\n",
    "    maf = np.zeros(L, dtype=np.float32)\n",
    "    bin_cnt = [0] * 6\n",
    "\n",
    "    for l in range(L):\n",
    "        alleles = gts_np[:, l]\n",
    "        alleles = alleles[alleles != mask_int]   # 去掉缺失\n",
    "        if alleles.size == 0:\n",
    "            maf[l] = 0.0\n",
    "            continue\n",
    "\n",
    "        uniq, cnt = np.unique(alleles, return_counts=True)\n",
    "        total = cnt.sum()\n",
    "        freq = cnt / total\n",
    "        freq[::-1].sort()\n",
    "        maf_val = freq[1] if len(freq) > 1 else 0.0\n",
    "        maf[l] = maf_val\n",
    "\n",
    "        # 统计 bin\n",
    "        for i, (lo, hi) in enumerate(MAF_BINS):\n",
    "            if lo <= maf_val < hi:\n",
    "                bin_cnt[i] += 1\n",
    "                break\n",
    "\n",
    "    return maf, bin_cnt\n",
    "\n",
    "def imputation_maf_accuracy_epoch(all_logits, all_gts, global_maf, mask=None):\n",
    "    \"\"\"\n",
    "    all_logits: (N, L, C)\n",
    "    all_gts:    (N, L, C) one-hot\n",
    "    global_maf: (L,)\n",
    "    mask:       (N, L) 或 None\n",
    "    return:     list[float] 长度 6\n",
    "    \"\"\"\n",
    "    # 1. 预测 vs 真实\n",
    "    all_gts = all_gts.argmax(dim=-1)      # (N, L)\n",
    "    preds   = all_logits.argmax(dim=-1)   # (N, L)\n",
    "\n",
    "    # 2. 如果没有外部 mask，就默认全 1\n",
    "    if mask is None:\n",
    "        mask = torch.ones_like(all_gts, dtype=torch.bool)   # (N, L)\n",
    "    correct = (preds == all_gts) & mask                   # (N, L)\n",
    "\n",
    "    # 3. MAF 条件 -> (1, L) 再广播到 (N, L)\n",
    "    maf = global_maf.unsqueeze(0)                         # (1, L)\n",
    "\n",
    "    # 4. 分 bin 计算\n",
    "    accs = []\n",
    "    for lo, hi in MAF_BINS:\n",
    "        maf_bin = mask & (maf >= lo) & (maf < hi)                # (1, L)\n",
    "        n_cor = (correct & maf_bin).sum()\n",
    "        n_tot = maf_bin.sum()\n",
    "        accs.append(100*(n_cor / n_tot).item() if n_tot > 0 else 0.0)\n",
    "    return accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d21fb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "work_dir      = '/home/qmtang/mnt_qmtang/EvoFill/data/251023_ver3_chr22'\n",
    "val_n_samples = 128\n",
    "max_mr             = 0.7\n",
    "min_mr             = 0.3\n",
    "batch_size_per_gpu = 8\n",
    "\n",
    "# Setup device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Create directories\n",
    "create_directories(work_dir)\n",
    "\n",
    "gt_enc = GenotypeEncoder(\n",
    "    save_dir='/mnt/qmtang/EvoFill/data/251024_ver3_chr22_mini',\n",
    "    vcf_path='/home/qmtang/GitHub/STICI-HPC/data/training_sets/ALL.chr22.training.samples.100k.any.type.0.01.maf.variants.vcf.gz',\n",
    "    ref_extra='/mnt/qmtang/EvoFill/data/251020_ver01_chr22/pop_wasserstein.tsv',\n",
    "    phased= True,\n",
    "    gts012= False)\n",
    "\n",
    "print(gt_enc.n_samples, 'samples,', gt_enc.n_variants, 'variants,', gt_enc.seq_depth, 'alleles.')\n",
    "\n",
    "x_train_indices, x_valid_indices = train_test_split(\n",
    "    range(gt_enc.n_samples),\n",
    "    test_size=val_n_samples,\n",
    "    random_state=3047,\n",
    "    shuffle=True\n",
    ")\n",
    "print(f\"{len(x_train_indices)} samples in train\")\n",
    "print(f\"{len(x_valid_indices)} samples in val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097171d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model[hg19_chr22] chunks=7\n"
     ]
    }
   ],
   "source": [
    "model_name  = 'hg19_chr22'\n",
    "total_sites = gt_enc.n_variants\n",
    "alleles     = gt_enc.seq_depth\n",
    "chunk_size  = 65536\n",
    "overlap     = 4096\n",
    "d_model     = 128\n",
    "\n",
    "model = EvoFill(d_model, alleles, total_sites, chunk_size, overlap).to(device)\n",
    "print(f\"model[{model_name}] chunks={model.n_chunks}\")\n",
    "\n",
    "criterion = ImputationLoss(use_r2=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38bc4f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Chunk 1 STAT ===\n",
      "     MAF_bin Counts\n",
      "(0.00, 0.05)   4427\n",
      "(0.05, 0.10)   2598\n",
      "(0.10, 0.20)   3011\n",
      "(0.20, 0.30)   2460\n",
      "(0.30, 0.40)   3132\n",
      "(0.40, 0.50)    756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/7, Epoch 1/100, Train Loss: 67618.2556, Val Loss: 53165.0034\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)   4427 96.02 98.28\n",
      "(0.05, 0.10)   2598 92.08 96.84\n",
      "(0.10, 0.20)   3011 86.17 94.59\n",
      "(0.20, 0.30)   2460 78.25 91.95\n",
      "(0.30, 0.40)   3132 76.56 91.51\n",
      "(0.40, 0.50)    756 71.95 89.33\n",
      "  --> updated hg19_chr22_chunk0.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/7, Epoch 2/100, Train Loss: 49651.8990, Val Loss: 48643.8154\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)   4427 96.78 98.32\n",
      "(0.05, 0.10)   2598 93.99 97.11\n",
      "(0.10, 0.20)   3011 90.27 95.45\n",
      "(0.20, 0.30)   2460 85.51 93.09\n",
      "(0.30, 0.40)   3132 84.92 92.67\n",
      "(0.40, 0.50)    756 80.80 90.55\n",
      "  --> updated hg19_chr22_chunk0.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/7, Epoch 3/100, Train Loss: 45129.7220, Val Loss: 44591.2644\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)   4427 96.99 98.45\n",
      "(0.05, 0.10)   2598 94.67 97.41\n",
      "(0.10, 0.20)   3011 91.76 95.94\n",
      "(0.20, 0.30)   2460 87.76 93.92\n",
      "(0.30, 0.40)   3132 87.36 93.88\n",
      "(0.40, 0.50)    756 83.60 91.70\n",
      "  --> updated hg19_chr22_chunk0.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/7, Epoch 4/100, Train Loss: 42414.9077, Val Loss: 41514.3794\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)   4427 97.14 98.48\n",
      "(0.05, 0.10)   2598 95.16 97.58\n",
      "(0.10, 0.20)   3011 92.63 96.26\n",
      "(0.20, 0.30)   2460 89.01 94.49\n",
      "(0.30, 0.40)   3132 88.70 94.38\n",
      "(0.40, 0.50)    756 85.15 92.80\n",
      "  --> updated hg19_chr22_chunk0.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/7, Epoch 5/100, Train Loss: 40632.2416, Val Loss: 40514.8638\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)   4427 97.26 98.58\n",
      "(0.05, 0.10)   2598 95.43 97.80\n",
      "(0.10, 0.20)   3011 93.17 96.72\n",
      "(0.20, 0.30)   2460 89.84 94.84\n",
      "(0.30, 0.40)   3132 89.54 94.53\n",
      "(0.40, 0.50)    756 86.22 92.88\n",
      "  --> updated hg19_chr22_chunk0.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/7, Epoch 6/100, Train Loss: 38844.3344, Val Loss: 41107.4380\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)   4427 97.38 98.42\n",
      "(0.05, 0.10)   2598 95.70 97.55\n",
      "(0.10, 0.20)   3011 93.64 96.46\n",
      "(0.20, 0.30)   2460 90.52 94.58\n",
      "(0.30, 0.40)   3132 90.30 94.57\n",
      "(0.40, 0.50)    756 87.09 92.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/7, Epoch 7/100, Train Loss: 37977.2959, Val Loss: 36902.1831\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)   4427 97.41 98.69\n",
      "(0.05, 0.10)   2598 95.81 97.96\n",
      "(0.10, 0.20)   3011 93.93 97.04\n",
      "(0.20, 0.30)   2460 90.98 95.62\n",
      "(0.30, 0.40)   3132 90.72 95.48\n",
      "(0.40, 0.50)    756 87.73 94.08\n",
      "  --> updated hg19_chr22_chunk0.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/7, Epoch 8/100, Train Loss: 37059.0523, Val Loss: 36709.6687\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)   4427 97.49 98.59\n",
      "(0.05, 0.10)   2598 96.00 97.86\n",
      "(0.10, 0.20)   3011 94.23 97.08\n",
      "(0.20, 0.30)   2460 91.34 95.65\n",
      "(0.30, 0.40)   3132 91.16 95.63\n",
      "(0.40, 0.50)    756 88.31 94.30\n",
      "  --> updated hg19_chr22_chunk0.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/7, Epoch 9/100, Train Loss: 36451.4998, Val Loss: 36397.6926\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)   4427 97.53 98.61\n",
      "(0.05, 0.10)   2598 96.12 97.85\n",
      "(0.10, 0.20)   3011 94.46 97.09\n",
      "(0.20, 0.30)   2460 91.68 95.66\n",
      "(0.30, 0.40)   3132 91.42 95.60\n",
      "(0.40, 0.50)    756 88.60 94.08\n",
      "  --> updated hg19_chr22_chunk0.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/7, Epoch 10/100, Train Loss: 35908.5264, Val Loss: 37215.7029\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)   4427 97.57 98.73\n",
      "(0.05, 0.10)   2598 96.25 98.11\n",
      "(0.10, 0.20)   3011 94.63 97.29\n",
      "(0.20, 0.30)   2460 91.90 95.51\n",
      "(0.30, 0.40)   3132 91.67 95.18\n",
      "(0.40, 0.50)    756 88.87 93.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/7, Epoch 11/100, Train Loss: 35058.2274, Val Loss: 36138.2747\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)   4427 97.63 98.70\n",
      "(0.05, 0.10)   2598 96.37 98.02\n",
      "(0.10, 0.20)   3011 94.85 97.19\n",
      "(0.20, 0.30)   2460 92.16 95.73\n",
      "(0.30, 0.40)   3132 91.92 95.61\n",
      "(0.40, 0.50)    756 89.22 94.16\n",
      "  --> updated hg19_chr22_chunk0.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/7, Epoch 12/100, Train Loss: 34097.8942, Val Loss: 35301.5845\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)   4427 97.70 98.74\n",
      "(0.05, 0.10)   2598 96.53 98.18\n",
      "(0.10, 0.20)   3011 95.07 97.46\n",
      "(0.20, 0.30)   2460 92.45 96.02\n",
      "(0.30, 0.40)   3132 92.24 95.85\n",
      "(0.40, 0.50)    756 89.55 94.39\n",
      "  --> updated hg19_chr22_chunk0.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/7, Epoch 13/100, Train Loss: 34020.8935, Val Loss: 36738.9705\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)   4427 97.72 98.53\n",
      "(0.05, 0.10)   2598 96.58 97.78\n",
      "(0.10, 0.20)   3011 95.15 96.85\n",
      "(0.20, 0.30)   2460 92.61 95.59\n",
      "(0.30, 0.40)   3132 92.37 95.49\n",
      "(0.40, 0.50)    756 89.73 94.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/7, Epoch 14/100, Train Loss: 33391.5159, Val Loss: 33542.2427\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)   4427 97.75 98.79\n",
      "(0.05, 0.10)   2598 96.67 98.20\n",
      "(0.10, 0.20)   3011 95.33 97.54\n",
      "(0.20, 0.30)   2460 92.80 96.25\n",
      "(0.30, 0.40)   3132 92.57 96.10\n",
      "(0.40, 0.50)    756 90.00 94.92\n",
      "  --> updated hg19_chr22_chunk0.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/7, Epoch 15/100, Train Loss: 33555.1070, Val Loss: 34762.1387\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)   4427 97.78 98.69\n",
      "(0.05, 0.10)   2598 96.69 98.13\n",
      "(0.10, 0.20)   3011 95.38 97.48\n",
      "(0.20, 0.30)   2460 92.82 96.03\n",
      "(0.30, 0.40)   3132 92.59 95.88\n",
      "(0.40, 0.50)    756 89.99 94.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/7, Epoch 16/100, Train Loss: 32965.8106, Val Loss: 32834.5178\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)   4427 97.79 98.84\n",
      "(0.05, 0.10)   2598 96.79 98.38\n",
      "(0.10, 0.20)   3011 95.49 97.71\n",
      "(0.20, 0.30)   2460 92.99 96.45\n",
      "(0.30, 0.40)   3132 92.79 96.38\n",
      "(0.40, 0.50)    756 90.20 95.10\n",
      "  --> updated hg19_chr22_chunk0.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/7, Epoch 17/100, Train Loss: 32673.8635, Val Loss: 33551.9792\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)   4427 97.83 98.79\n",
      "(0.05, 0.10)   2598 96.82 98.36\n",
      "(0.10, 0.20)   3011 95.59 97.72\n",
      "(0.20, 0.30)   2460 93.09 96.34\n",
      "(0.30, 0.40)   3132 92.87 96.17\n",
      "(0.40, 0.50)    756 90.23 94.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/7, Epoch 18/100, Train Loss: 32535.2306, Val Loss: 33134.3237\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)   4427 97.86 98.70\n",
      "(0.05, 0.10)   2598 96.89 98.13\n",
      "(0.10, 0.20)   3011 95.61 97.50\n",
      "(0.20, 0.30)   2460 93.16 96.35\n",
      "(0.30, 0.40)   3132 92.93 96.20\n",
      "(0.40, 0.50)    756 90.39 94.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/7, Epoch 19/100, Train Loss: 32537.5521, Val Loss: 31918.0554\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)   4427 97.86 98.91\n",
      "(0.05, 0.10)   2598 96.90 98.43\n",
      "(0.10, 0.20)   3011 95.65 97.86\n",
      "(0.20, 0.30)   2460 93.24 96.54\n",
      "(0.30, 0.40)   3132 93.00 96.44\n",
      "(0.40, 0.50)    756 90.47 95.14\n",
      "  --> updated hg19_chr22_chunk0.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/7, Epoch 20/100, Train Loss: 32051.4818, Val Loss: 32012.1780\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)   4427 97.88 98.89\n",
      "(0.05, 0.10)   2598 96.95 98.42\n",
      "(0.10, 0.20)   3011 95.73 97.79\n",
      "(0.20, 0.30)   2460 93.31 96.52\n",
      "(0.30, 0.40)   3132 93.05 96.46\n",
      "(0.40, 0.50)    756 90.56 95.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/7, Epoch 21/100, Train Loss: 31346.3132, Val Loss: 32103.2646\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)   4427 97.93 98.84\n",
      "(0.05, 0.10)   2598 97.04 98.35\n",
      "(0.10, 0.20)   3011 95.85 97.74\n",
      "(0.20, 0.30)   2460 93.45 96.54\n",
      "(0.30, 0.40)   3132 93.23 96.48\n",
      "(0.40, 0.50)    756 90.74 95.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/7, Epoch 22/100, Train Loss: 31322.2982, Val Loss: 32519.8120\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)   4427 97.96 98.89\n",
      "(0.05, 0.10)   2598 97.10 98.41\n",
      "(0.10, 0.20)   3011 95.90 97.80\n",
      "(0.20, 0.30)   2460 93.54 96.43\n",
      "(0.30, 0.40)   3132 93.36 96.32\n",
      "(0.40, 0.50)    756 90.88 94.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/7, Epoch 23/100, Train Loss: 31340.3900, Val Loss: 31747.6533\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)   4427 97.99 98.93\n",
      "(0.05, 0.10)   2598 97.15 98.50\n",
      "(0.10, 0.20)   3011 95.97 97.88\n",
      "(0.20, 0.30)   2460 93.58 96.69\n",
      "(0.30, 0.40)   3132 93.42 96.44\n",
      "(0.40, 0.50)    756 90.94 95.10\n",
      "  --> updated hg19_chr22_chunk0.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/7, Epoch 24/100, Train Loss: 31075.3055, Val Loss: 30945.6965\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)   4427 98.00 98.94\n",
      "(0.05, 0.10)   2598 97.16 98.53\n",
      "(0.10, 0.20)   3011 96.00 97.89\n",
      "(0.20, 0.30)   2460 93.65 96.72\n",
      "(0.30, 0.40)   3132 93.47 96.69\n",
      "(0.40, 0.50)    756 90.94 95.40\n",
      "  --> updated hg19_chr22_chunk0.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/7, Epoch 25/100, Train Loss: 31065.5087, Val Loss: 31794.3696\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)   4427 97.99 98.90\n",
      "(0.05, 0.10)   2598 97.16 98.40\n",
      "(0.10, 0.20)   3011 96.04 97.79\n",
      "(0.20, 0.30)   2460 93.67 96.45\n",
      "(0.30, 0.40)   3132 93.48 96.39\n",
      "(0.40, 0.50)    756 90.99 95.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/7, Epoch 26/100, Train Loss: 30666.7435, Val Loss: 31248.1863\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)   4427 98.04 98.88\n",
      "(0.05, 0.10)   2598 97.23 98.48\n",
      "(0.10, 0.20)   3011 96.12 97.87\n",
      "(0.20, 0.30)   2460 93.80 96.67\n",
      "(0.30, 0.40)   3132 93.59 96.54\n",
      "(0.40, 0.50)    756 91.15 95.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/7, Epoch 27/100, Train Loss: 30646.9043, Val Loss: 31202.0081\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)   4427 98.05 98.93\n",
      "(0.05, 0.10)   2598 97.27 98.55\n",
      "(0.10, 0.20)   3011 96.16 97.95\n",
      "(0.20, 0.30)   2460 93.84 96.74\n",
      "(0.30, 0.40)   3132 93.65 96.66\n",
      "(0.40, 0.50)    756 91.15 95.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/7, Epoch 28/100, Train Loss: 30686.0120, Val Loss: 30916.3350\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)   4427 98.03 98.91\n",
      "(0.05, 0.10)   2598 97.27 98.47\n",
      "(0.10, 0.20)   3011 96.14 97.96\n",
      "(0.20, 0.30)   2460 93.85 96.70\n",
      "(0.30, 0.40)   3132 93.63 96.60\n",
      "(0.40, 0.50)    756 91.17 95.40\n",
      "  --> updated hg19_chr22_chunk0.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/7, Epoch 29/100, Train Loss: 30170.8684, Val Loss: 31611.9001\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)   4427 98.09 98.90\n",
      "(0.05, 0.10)   2598 97.33 98.42\n",
      "(0.10, 0.20)   3011 96.21 97.84\n",
      "(0.20, 0.30)   2460 93.92 96.57\n",
      "(0.30, 0.40)   3132 93.73 96.43\n",
      "(0.40, 0.50)    756 91.32 95.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/7, Epoch 30/100, Train Loss: 30295.2628, Val Loss: 29615.0149\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)   4427 98.12 99.04\n",
      "(0.05, 0.10)   2598 97.38 98.67\n",
      "(0.10, 0.20)   3011 96.25 98.15\n",
      "(0.20, 0.30)   2460 93.97 97.01\n",
      "(0.30, 0.40)   3132 93.78 96.94\n",
      "(0.40, 0.50)    756 91.31 95.68\n",
      "  --> updated hg19_chr22_chunk0.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/7, Epoch 31/100, Train Loss: 29995.3658, Val Loss: 29912.1619\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)   4427 98.15 98.98\n",
      "(0.05, 0.10)   2598 97.39 98.63\n",
      "(0.10, 0.20)   3011 96.29 98.09\n",
      "(0.20, 0.30)   2460 94.01 96.86\n",
      "(0.30, 0.40)   3132 93.84 96.83\n",
      "(0.40, 0.50)    756 91.43 95.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/7, Epoch 32/100, Train Loss: 29834.5134, Val Loss: 30606.4775\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)   4427 98.15 99.04\n",
      "(0.05, 0.10)   2598 97.44 98.65\n",
      "(0.10, 0.20)   3011 96.31 98.11\n",
      "(0.20, 0.30)   2460 94.07 96.88\n",
      "(0.30, 0.40)   3132 93.90 96.67\n",
      "(0.40, 0.50)    756 91.48 95.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/7, Epoch 33/100, Train Loss: 29532.9486, Val Loss: 29903.0730\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)   4427 98.16 99.01\n",
      "(0.05, 0.10)   2598 97.48 98.63\n",
      "(0.10, 0.20)   3011 96.35 98.11\n",
      "(0.20, 0.30)   2460 94.12 96.92\n",
      "(0.30, 0.40)   3132 93.94 96.87\n",
      "(0.40, 0.50)    756 91.51 95.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/7, Epoch 34/100, Train Loss: 29513.2648, Val Loss: 30918.5757\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)   4427 98.20 98.93\n",
      "(0.05, 0.10)   2598 97.50 98.54\n",
      "(0.10, 0.20)   3011 96.40 97.95\n",
      "(0.20, 0.30)   2460 94.17 96.68\n",
      "(0.30, 0.40)   3132 93.98 96.63\n",
      "(0.40, 0.50)    756 91.59 95.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/7, Epoch 35/100, Train Loss: 28499.0482, Val Loss: 28951.9624\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)   4427 98.31 99.05\n",
      "(0.05, 0.10)   2598 97.70 98.77\n",
      "(0.10, 0.20)   3011 96.64 98.22\n",
      "(0.20, 0.30)   2460 94.58 97.11\n",
      "(0.30, 0.40)   3132 94.41 97.00\n",
      "(0.40, 0.50)    756 92.05 95.80\n",
      "  --> updated hg19_chr22_chunk0.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/7, Epoch 36/100, Train Loss: 28546.1047, Val Loss: 28876.0408\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)   4427 98.33 99.09\n",
      "(0.05, 0.10)   2598 97.71 98.78\n",
      "(0.10, 0.20)   3011 96.69 98.24\n",
      "(0.20, 0.30)   2460 94.58 97.14\n",
      "(0.30, 0.40)   3132 94.43 97.03\n",
      "(0.40, 0.50)    756 92.10 95.68\n",
      "  --> updated hg19_chr22_chunk0.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/7, Epoch 37/100, Train Loss: 28163.5161, Val Loss: 28918.3027\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)   4427 98.37 99.06\n",
      "(0.05, 0.10)   2598 97.78 98.76\n",
      "(0.10, 0.20)   3011 96.76 98.26\n",
      "(0.20, 0.30)   2460 94.69 97.05\n",
      "(0.30, 0.40)   3132 94.56 97.01\n",
      "(0.40, 0.50)    756 92.28 95.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/7, Epoch 38/100, Train Loss: 28294.2665, Val Loss: 28281.3203\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)   4427 98.38 99.12\n",
      "(0.05, 0.10)   2598 97.80 98.81\n",
      "(0.10, 0.20)   3011 96.74 98.29\n",
      "(0.20, 0.30)   2460 94.66 97.26\n",
      "(0.30, 0.40)   3132 94.54 97.16\n",
      "(0.40, 0.50)    756 92.26 95.99\n",
      "  --> updated hg19_chr22_chunk0.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/7, Epoch 39/100, Train Loss: 28223.2701, Val Loss: 27591.3950\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)   4427 98.38 99.19\n",
      "(0.05, 0.10)   2598 97.81 98.86\n",
      "(0.10, 0.20)   3011 96.75 98.39\n",
      "(0.20, 0.30)   2460 94.71 97.31\n",
      "(0.30, 0.40)   3132 94.58 97.33\n",
      "(0.40, 0.50)    756 92.24 96.13\n",
      "  --> updated hg19_chr22_chunk0.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/7, Epoch 40/100, Train Loss: 27960.1902, Val Loss: 28568.0654\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)   4427 98.40 99.09\n",
      "(0.05, 0.10)   2598 97.82 98.76\n",
      "(0.10, 0.20)   3011 96.77 98.23\n",
      "(0.20, 0.30)   2460 94.72 97.17\n",
      "(0.30, 0.40)   3132 94.60 97.12\n",
      "(0.40, 0.50)    756 92.32 95.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/7, Epoch 41/100, Train Loss: 28126.1007, Val Loss: 27822.9087\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)   4427 98.39 99.14\n",
      "(0.05, 0.10)   2598 97.82 98.86\n",
      "(0.10, 0.20)   3011 96.78 98.36\n",
      "(0.20, 0.30)   2460 94.72 97.31\n",
      "(0.30, 0.40)   3132 94.58 97.32\n",
      "(0.40, 0.50)    756 92.31 96.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/7, Epoch 42/100, Train Loss: 27857.1578, Val Loss: 28358.2510\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)   4427 98.41 99.12\n",
      "(0.05, 0.10)   2598 97.85 98.82\n",
      "(0.10, 0.20)   3011 96.80 98.30\n",
      "(0.20, 0.30)   2460 94.81 97.21\n",
      "(0.30, 0.40)   3132 94.64 97.17\n",
      "(0.40, 0.50)    756 92.37 95.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/7, Epoch 43/100, Train Loss: 27831.2923, Val Loss: 27793.9089\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)   4427 98.43 99.14\n",
      "(0.05, 0.10)   2598 97.86 98.84\n",
      "(0.10, 0.20)   3011 96.82 98.38\n",
      "(0.20, 0.30)   2460 94.79 97.35\n",
      "(0.30, 0.40)   3132 94.65 97.30\n",
      "(0.40, 0.50)    756 92.37 96.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/7, Epoch 44/100, Train Loss: 27537.3535, Val Loss: 28134.6240\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)   4427 98.49 99.11\n",
      "(0.05, 0.10)   2598 97.96 98.85\n",
      "(0.10, 0.20)   3011 96.93 98.32\n",
      "(0.20, 0.30)   2460 94.96 97.27\n",
      "(0.30, 0.40)   3132 94.84 97.20\n",
      "(0.40, 0.50)    756 92.61 95.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/7, Epoch 45/100, Train Loss: 27235.0241, Val Loss: 27088.9617\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)   4427 98.51 99.19\n",
      "(0.05, 0.10)   2598 98.01 98.95\n",
      "(0.10, 0.20)   3011 97.01 98.45\n",
      "(0.20, 0.30)   2460 95.05 97.53\n",
      "(0.30, 0.40)   3132 94.93 97.43\n",
      "(0.40, 0.50)    756 92.68 96.29\n",
      "  --> updated hg19_chr22_chunk0.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/7, Epoch 46/100, Train Loss: 27246.8969, Val Loss: 28086.5127\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)   4427 98.52 99.13\n",
      "(0.05, 0.10)   2598 98.00 98.83\n",
      "(0.10, 0.20)   3011 97.01 98.36\n",
      "(0.20, 0.30)   2460 95.05 97.24\n",
      "(0.30, 0.40)   3132 94.93 97.23\n",
      "(0.40, 0.50)    756 92.69 96.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/7, Epoch 47/100, Train Loss: 27382.0169, Val Loss: 27174.5803\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)   4427 98.53 99.21\n",
      "(0.05, 0.10)   2598 98.02 98.94\n",
      "(0.10, 0.20)   3011 97.01 98.46\n",
      "(0.20, 0.30)   2460 95.05 97.50\n",
      "(0.30, 0.40)   3132 94.94 97.42\n",
      "(0.40, 0.50)    756 92.71 96.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/7, Epoch 48/100, Train Loss: 27290.9461, Val Loss: 27644.9390\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)   4427 98.52 99.15\n",
      "(0.05, 0.10)   2598 98.02 98.92\n",
      "(0.10, 0.20)   3011 97.02 98.39\n",
      "(0.20, 0.30)   2460 95.08 97.37\n",
      "(0.30, 0.40)   3132 94.93 97.30\n",
      "(0.40, 0.50)    756 92.74 96.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/7, Epoch 49/100, Train Loss: 27252.2110, Val Loss: 27291.0588\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)   4427 98.51 99.20\n",
      "(0.05, 0.10)   2598 98.00 98.93\n",
      "(0.10, 0.20)   3011 97.02 98.43\n",
      "(0.20, 0.30)   2460 95.03 97.41\n",
      "(0.30, 0.40)   3132 94.93 97.36\n",
      "(0.40, 0.50)    756 92.75 96.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/7, Epoch 50/100, Train Loss: 27089.4823, Val Loss: 26658.6794\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)   4427 98.55 99.26\n",
      "(0.05, 0.10)   2598 98.07 99.00\n",
      "(0.10, 0.20)   3011 97.08 98.52\n",
      "(0.20, 0.30)   2460 95.16 97.51\n",
      "(0.30, 0.40)   3132 95.03 97.47\n",
      "(0.40, 0.50)    756 92.83 96.33\n",
      "  --> updated hg19_chr22_chunk0.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/7, Epoch 51/100, Train Loss: 26738.8923, Val Loss: 27913.2075\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)   4427 98.60 99.15\n",
      "(0.05, 0.10)   2598 98.11 98.89\n",
      "(0.10, 0.20)   3011 97.12 98.33\n",
      "(0.20, 0.30)   2460 95.24 97.24\n",
      "(0.30, 0.40)   3132 95.12 97.22\n",
      "(0.40, 0.50)    756 92.94 96.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/7, Epoch 52/100, Train Loss: 26873.1979, Val Loss: 26841.7009\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)   4427 98.57 99.22\n",
      "(0.05, 0.10)   2598 98.11 98.99\n",
      "(0.10, 0.20)   3011 97.13 98.50\n",
      "(0.20, 0.30)   2460 95.25 97.48\n",
      "(0.30, 0.40)   3132 95.12 97.49\n",
      "(0.40, 0.50)    756 92.93 96.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/7, Epoch 53/100, Train Loss: 26738.0207, Val Loss: 26660.1152\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)   4427 98.61 99.20\n",
      "(0.05, 0.10)   2598 98.14 98.97\n",
      "(0.10, 0.20)   3011 97.14 98.53\n",
      "(0.20, 0.30)   2460 95.26 97.55\n",
      "(0.30, 0.40)   3132 95.13 97.50\n",
      "(0.40, 0.50)    756 92.96 96.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/7, Epoch 54/100, Train Loss: 26888.9819, Val Loss: 26798.7788\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)   4427 98.61 99.22\n",
      "(0.05, 0.10)   2598 98.12 98.98\n",
      "(0.10, 0.20)   3011 97.14 98.49\n",
      "(0.20, 0.30)   2460 95.27 97.56\n",
      "(0.30, 0.40)   3132 95.14 97.48\n",
      "(0.40, 0.50)    756 92.95 96.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/7, Epoch 55/100, Train Loss: 26785.7917, Val Loss: 26685.4629\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)   4427 98.61 99.24\n",
      "(0.05, 0.10)   2598 98.14 99.01\n",
      "(0.10, 0.20)   3011 97.15 98.55\n",
      "(0.20, 0.30)   2460 95.25 97.54\n",
      "(0.30, 0.40)   3132 95.15 97.48\n",
      "(0.40, 0.50)    756 92.98 96.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/7, Epoch 56/100, Train Loss: 26673.3350, Val Loss: 26652.5403\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)   4427 98.62 99.26\n",
      "(0.05, 0.10)   2598 98.14 99.01\n",
      "(0.10, 0.20)   3011 97.18 98.49\n",
      "(0.20, 0.30)   2460 95.30 97.50\n",
      "(0.30, 0.40)   3132 95.18 97.51\n",
      "(0.40, 0.50)    756 93.02 96.42\n",
      "  --> updated hg19_chr22_chunk0.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/7, Epoch 57/100, Train Loss: 26337.6363, Val Loss: 26866.5115\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)   4427 98.63 99.19\n",
      "(0.05, 0.10)   2598 98.17 98.96\n",
      "(0.10, 0.20)   3011 97.19 98.47\n",
      "(0.20, 0.30)   2460 95.32 97.55\n",
      "(0.30, 0.40)   3132 95.21 97.50\n",
      "(0.40, 0.50)    756 93.06 96.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/7, Epoch 58/100, Train Loss: 26395.4459, Val Loss: 26881.9001\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)   4427 98.65 99.26\n",
      "(0.05, 0.10)   2598 98.20 98.98\n",
      "(0.10, 0.20)   3011 97.21 98.47\n",
      "(0.20, 0.30)   2460 95.37 97.51\n",
      "(0.30, 0.40)   3132 95.25 97.43\n",
      "(0.40, 0.50)    756 93.10 96.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/7, Epoch 59/100, Train Loss: 26517.7646, Val Loss: 26594.4312\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)   4427 98.64 99.28\n",
      "(0.05, 0.10)   2598 98.20 99.02\n",
      "(0.10, 0.20)   3011 97.22 98.50\n",
      "(0.20, 0.30)   2460 95.37 97.53\n",
      "(0.30, 0.40)   3132 95.26 97.48\n",
      "(0.40, 0.50)    756 93.08 96.26\n",
      "  --> updated hg19_chr22_chunk0.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/7, Epoch 60/100, Train Loss: 26466.6212, Val Loss: 26923.2698\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)   4427 98.64 99.22\n",
      "(0.05, 0.10)   2598 98.20 98.99\n",
      "(0.10, 0.20)   3011 97.21 98.46\n",
      "(0.20, 0.30)   2460 95.35 97.50\n",
      "(0.30, 0.40)   3132 95.23 97.45\n",
      "(0.40, 0.50)    756 93.07 96.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/7, Epoch 61/100, Train Loss: 26496.6832, Val Loss: 26293.4482\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)   4427 98.63 99.24\n",
      "(0.05, 0.10)   2598 98.18 99.02\n",
      "(0.10, 0.20)   3011 97.20 98.59\n",
      "(0.20, 0.30)   2460 95.34 97.59\n",
      "(0.30, 0.40)   3132 95.23 97.61\n",
      "(0.40, 0.50)    756 93.07 96.53\n",
      "  --> updated hg19_chr22_chunk0.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/7, Epoch 62/100, Train Loss: 26485.2509, Val Loss: 26685.5393\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)   4427 98.64 99.23\n",
      "(0.05, 0.10)   2598 98.18 98.99\n",
      "(0.10, 0.20)   3011 97.20 98.52\n",
      "(0.20, 0.30)   2460 95.35 97.56\n",
      "(0.30, 0.40)   3132 95.23 97.46\n",
      "(0.40, 0.50)    756 93.07 96.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/7, Epoch 63/100, Train Loss: 26565.8941, Val Loss: 26552.0071\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)   4427 98.64 99.24\n",
      "(0.05, 0.10)   2598 98.18 99.03\n",
      "(0.10, 0.20)   3011 97.22 98.51\n",
      "(0.20, 0.30)   2460 95.36 97.56\n",
      "(0.30, 0.40)   3132 95.25 97.49\n",
      "(0.40, 0.50)    756 93.10 96.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/7, Epoch 64/100, Train Loss: 26435.7651, Val Loss: 26964.0107\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)   4427 98.63 99.20\n",
      "(0.05, 0.10)   2598 98.18 98.95\n",
      "(0.10, 0.20)   3011 97.20 98.47\n",
      "(0.20, 0.30)   2460 95.35 97.45\n",
      "(0.30, 0.40)   3132 95.21 97.44\n",
      "(0.40, 0.50)    756 93.05 96.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/7, Epoch 65/100, Train Loss: 26228.8341, Val Loss: 27653.3293\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)   4427 98.65 99.15\n",
      "(0.05, 0.10)   2598 98.20 98.94\n",
      "(0.10, 0.20)   3011 97.23 98.41\n",
      "(0.20, 0.30)   2460 95.39 97.28\n",
      "(0.30, 0.40)   3132 95.28 97.24\n",
      "(0.40, 0.50)    756 93.12 96.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/7, Epoch 66/100, Train Loss: 26124.3559, Val Loss: 26754.9080\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)   4427 98.65 99.22\n",
      "(0.05, 0.10)   2598 98.21 98.98\n",
      "(0.10, 0.20)   3011 97.24 98.54\n",
      "(0.20, 0.30)   2460 95.37 97.52\n",
      "(0.30, 0.40)   3132 95.26 97.43\n",
      "(0.40, 0.50)    756 93.14 96.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/7, Epoch 67/100, Train Loss: 26428.5944, Val Loss: 26440.5212\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)   4427 98.67 99.25\n",
      "(0.05, 0.10)   2598 98.21 99.00\n",
      "(0.10, 0.20)   3011 97.23 98.54\n",
      "(0.20, 0.30)   2460 95.40 97.57\n",
      "(0.30, 0.40)   3132 95.28 97.56\n",
      "(0.40, 0.50)    756 93.17 96.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/7, Epoch 68/100, Train Loss: 26344.9654, Val Loss: 27083.2000\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)   4427 98.66 99.21\n",
      "(0.05, 0.10)   2598 98.21 98.95\n",
      "(0.10, 0.20)   3011 97.23 98.45\n",
      "(0.20, 0.30)   2460 95.40 97.41\n",
      "(0.30, 0.40)   3132 95.29 97.47\n",
      "(0.40, 0.50)    756 93.14 96.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/7, Epoch 69/100, Train Loss: 26223.4657, Val Loss: 27198.1580\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)   4427 98.69 99.19\n",
      "(0.05, 0.10)   2598 98.25 98.92\n",
      "(0.10, 0.20)   3011 97.28 98.45\n",
      "(0.20, 0.30)   2460 95.45 97.41\n",
      "(0.30, 0.40)   3132 95.34 97.38\n",
      "(0.40, 0.50)    756 93.19 96.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/7, Epoch 70/100, Train Loss: 26303.1813, Val Loss: 26787.3787\n",
      "     MAF_bin Counts Train   Val\n",
      "(0.00, 0.05)   4427 98.66 99.25\n",
      "(0.05, 0.10)   2598 98.23 99.02\n",
      "(0.10, 0.20)   3011 97.25 98.50\n",
      "(0.20, 0.30)   2460 95.41 97.49\n",
      "(0.30, 0.40)   3132 95.33 97.47\n",
      "(0.40, 0.50)    756 93.17 96.32\n",
      "Early stopping triggered\n",
      "=== Chunk 2 STAT ===\n",
      "     MAF_bin Counts\n",
      "(0.00, 0.05)   4318\n",
      "(0.05, 0.10)   2967\n",
      "(0.10, 0.20)   2900\n",
      "(0.20, 0.30)   2408\n",
      "(0.30, 0.40)   2797\n",
      "(0.40, 0.50)    994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[10], line 41\u001b[0m\n",
      "\u001b[1;32m     38\u001b[0m x, x_extra, target \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(device), x_extra\u001b[38;5;241m.\u001b[39mto(device), target\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[1;32m     40\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "\u001b[0;32m---> 41\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_extra\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# pred = model(x, cid, None)\u001b[39;00m\n",
      "\u001b[1;32m     44\u001b[0m idx       \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mwhere(chunk_mask)[\u001b[38;5;241m0\u001b[39m]          \u001b[38;5;66;03m# (n_active,)\u001b[39;00m\n",
      "\n",
      "File \u001b[0;32m~/miniconda3/envs/mamba/lib/python3.10/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n",
      "\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/miniconda3/envs/mamba/lib/python3.10/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n",
      "\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n",
      "\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n",
      "\u001b[1;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n",
      "\u001b[1;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n",
      "\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "\n",
      "Cell \u001b[0;32mIn[4], line 464\u001b[0m, in \u001b[0;36mEvoFill.forward\u001b[0;34m(self, x, chunk_id, x_extra)\u001b[0m\n",
      "\u001b[1;32m    461\u001b[0m z_full \u001b[38;5;241m=\u001b[39m z_full\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)            \u001b[38;5;66;03m# (B, 2*d_model, L)\u001b[39;00m\n",
      "\u001b[1;32m    463\u001b[0m \u001b[38;5;66;03m# 4. 全局卷积只激活带状区\u001b[39;00m\n",
      "\u001b[0;32m--> 464\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglobal_out\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz_full\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/miniconda3/envs/mamba/lib/python3.10/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n",
      "\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/miniconda3/envs/mamba/lib/python3.10/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n",
      "\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n",
      "\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n",
      "\u001b[1;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n",
      "\u001b[1;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n",
      "\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "\n",
      "Cell \u001b[0;32mIn[4], line 388\u001b[0m, in \u001b[0;36mGlobalOut.forward\u001b[0;34m(self, x, mask)\u001b[0m\n",
      "\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, mask):\n",
      "\u001b[1;32m    387\u001b[0m     \u001b[38;5;66;03m# mask: (L,)  0/1  当前 chunk 要激活的位点\u001b[39;00m\n",
      "\u001b[0;32m--> 388\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfinal_conv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;32m    389\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_conv(x, mask)        \u001b[38;5;66;03m# (B, n_alleles-1, L)\u001b[39;00m\n",
      "\u001b[1;32m    390\u001b[0m     \u001b[38;5;66;03m# 无效区填 -inf\u001b[39;00m\n",
      "\n",
      "File \u001b[0;32m~/miniconda3/envs/mamba/lib/python3.10/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n",
      "\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/miniconda3/envs/mamba/lib/python3.10/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n",
      "\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n",
      "\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n",
      "\u001b[1;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n",
      "\u001b[1;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n",
      "\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "\n",
      "Cell \u001b[0;32mIn[4], line 376\u001b[0m, in \u001b[0;36mSparseGlobalConv.forward\u001b[0;34m(self, x, mask)\u001b[0m\n",
      "\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, mask):\n",
      "\u001b[0;32m--> 376\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mBandConv1d\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    377\u001b[0m \u001b[43m                            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/miniconda3/envs/mamba/lib/python3.10/site-packages/torch/autograd/function.py:576\u001b[0m, in \u001b[0;36mFunction.apply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m    573\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n",
      "\u001b[1;32m    574\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n",
      "\u001b[1;32m    575\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n",
      "\u001b[0;32m--> 576\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n",
      "\u001b[1;32m    578\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_setup_ctx_defined:\n",
      "\u001b[1;32m    579\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n",
      "\u001b[1;32m    580\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;32m    581\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;32m    582\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;32m    583\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/main/notes/extending.func.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;32m    584\u001b[0m     )\n",
      "\n",
      "Cell \u001b[0;32mIn[4], line 338\u001b[0m, in \u001b[0;36mBandConv1d.forward\u001b[0;34m(ctx, x, weight, bias, mask, kernel, pad)\u001b[0m\n",
      "\u001b[1;32m    336\u001b[0m L \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[1;32m    337\u001b[0m \u001b[38;5;66;03m# 1. 把有效区抽出来（连续内存）\u001b[39;00m\n",
      "\u001b[0;32m--> 338\u001b[0m idx \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;32m    339\u001b[0m x_band \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, idx]                      \u001b[38;5;66;03m# (B, C, len_band)\u001b[39;00m\n",
      "\u001b[1;32m    340\u001b[0m \u001b[38;5;66;03m# 2. 标准 conv1d\u001b[39;00m\n",
      "\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "max_epochs_per_chunk = 100\n",
    "lr                 = 0.001\n",
    "weight_decay       = 1e-5\n",
    "earlystop_patience = 9\n",
    "verbose            = True\n",
    "\n",
    "for cid in range(model.n_chunks):\n",
    "    chunk_mask = model.chunk_masks[cid].cpu()\n",
    "\n",
    "    train_dataset = GenomicDataset(\n",
    "        train_gt, train_extra, dr.seq_depth,\n",
    "        mask=True, masking_rates=(min_mr, max_mr)\n",
    "    )\n",
    "    val_dataset = GenomicDataset(\n",
    "        val_gt, val_extra, dr.seq_depth,\n",
    "        mask=True, masking_rates=(min_mr, max_mr)\n",
    "    )\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size_per_gpu,\n",
    "                        shuffle=True, num_workers=4, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size_per_gpu,\n",
    "                        shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "    chunk_maf, chunk_bin_cnt = precompute_maf(X_gt[:, torch.where(chunk_mask)[0]],  mask_int=dr.seq_depth)\n",
    "    chunk_maf = torch.from_numpy(chunk_maf).to(device)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"=== Chunk {cid + 1} STAT ===\")\n",
    "        maf_df = pd.DataFrame({\n",
    "            'MAF_bin': ['(0.00, 0.05)', '(0.05, 0.10)', '(0.10, 0.20)',\n",
    "                        '(0.20, 0.30)', '(0.30, 0.40)', '(0.40, 0.50)'],\n",
    "            'Counts':  [f\"{c}\" for c in chunk_bin_cnt],\n",
    "        })\n",
    "        print(maf_df.to_string(index=False))\n",
    "\n",
    "    optimizer = AdamW(list(model.chunk_embeds[cid].parameters()) +\n",
    "                      list(model.chunk_modules[cid].parameters()) +\n",
    "                      list(model.global_out.parameters()), \n",
    "                      lr=lr, weight_decay=weight_decay)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, min_lr=1e-7)\n",
    "    best_loss = float('inf')\n",
    "    patience = earlystop_patience\n",
    "    patience_counter = 0\n",
    "    \n",
    "    for epoch in range(max_epochs_per_chunk):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_logits, train_gts, train_mask = [], [], []\n",
    "\n",
    "        train_pbar = tqdm(train_loader, desc=f'Chunk {cid + 1}/{model.n_chunks}, Epoch {epoch + 1}/{max_epochs_per_chunk}', leave=False)\n",
    "        for batch_idx, (x, x_extra, target) in enumerate(train_pbar):\n",
    "            x, x_extra, target = x.to(device), x_extra.to(device), target.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(x, cid, x_extra)\n",
    "            # pred = model(x, cid, None)\n",
    "\n",
    "            idx       = torch.where(chunk_mask)[0]          # (n_active,)\n",
    "            pred_band = pred[:, idx]                  # (B, n_active, n_alleles-1)\n",
    "            y_band    = target[:, idx]               # (B, n_active, n_alleles-1)\n",
    "\n",
    "            loss, logs = criterion(pred_band, y_band)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            train_pbar.set_postfix({'loss': loss.item()})\n",
    "\n",
    "            # === 收集训练结果 ===\n",
    "            miss_mask = x[:, idx][..., -1].bool()         # 只关心被 mask 的位点\n",
    "            train_logits.append(pred_band.detach())\n",
    "            train_gts.append(y_band.detach())\n",
    "            train_mask.append(miss_mask)\n",
    "\n",
    "        # 训练集 MAF-acc\n",
    "        train_logits = torch.cat(train_logits, dim=0)\n",
    "        train_gts    = torch.cat(train_gts,    dim=0)\n",
    "        train_mask   = torch.cat(train_mask,   dim=0)\n",
    "        train_maf_accs = imputation_maf_accuracy_epoch(train_logits, train_gts, chunk_maf, mask=train_mask)\n",
    "\n",
    "        # ----------- 验证循环同理 ------------\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_logits, val_gts = [], []\n",
    "        with torch.no_grad():\n",
    "            for x, x_extra, target in val_loader:\n",
    "                x, x_extra, target = x.to(device), x_extra.to(device), target.to(device)\n",
    "                pred = model(x, cid, x_extra)\n",
    "                # pred = model(x, cid, None)\n",
    "\n",
    "                idx       = torch.where(chunk_mask)[0]          # (n_active,)\n",
    "                pred_band = pred[:, idx]                  # (B, n_active, n_alleles-1)\n",
    "                y_band    = target[:, idx]               # (B, n_active, n_alleles-1)\n",
    "\n",
    "                loss, logs = criterion(pred_band, y_band)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                val_logits.append(pred_band)\n",
    "                val_gts.append(y_band)\n",
    "\n",
    "        val_logits = torch.cat(val_logits, dim=0)\n",
    "        val_gts    = torch.cat(val_gts,    dim=0)\n",
    "        val_maf_accs = imputation_maf_accuracy_epoch(\n",
    "            val_logits, val_gts, chunk_maf,  mask=None,) # 计算所有位点\n",
    "\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        avg_val_loss   = val_loss   / len(val_loader)\n",
    "\n",
    "        scheduler.step(avg_val_loss)\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "\n",
    "        print(f'Chunk {cid + 1}/{model.n_chunks}, '\n",
    "            f'Epoch {epoch + 1}/{max_epochs_per_chunk}, '\n",
    "            f'Train Loss: {avg_train_loss:.1f}, '\n",
    "            f'Val Loss: {avg_val_loss:.1f}, '\n",
    "            f'LR: {current_lr:.2e}')\n",
    "\n",
    "        # 用 DataFrame 打印 MAF-bin 结果\n",
    "        if verbose:\n",
    "            maf_df = pd.DataFrame({\n",
    "                'MAF_bin': ['(0.00, 0.05)', '(0.05, 0.10)', '(0.10, 0.20)',\n",
    "                            '(0.20, 0.30)', '(0.30, 0.40)', '(0.40, 0.50)'],\n",
    "                'Counts':  [f\"{c}\" for c in chunk_bin_cnt],\n",
    "                'Train':   [f\"{acc:.2f}\" for acc in train_maf_accs],\n",
    "                'Val':     [f\"{acc:.2f}\" for acc in val_maf_accs]\n",
    "            })\n",
    "            print(maf_df.to_string(index=False))\n",
    "\n",
    "        # Early stopping\n",
    "        if avg_val_loss < best_loss:\n",
    "            best_loss = avg_val_loss\n",
    "            patience_counter = 0\n",
    "            # 只存当前 chunk 专家 + 全局层\n",
    "            ckpt = {\n",
    "                'chunk_id': cid,\n",
    "                'chunk_embed_state': model.chunk_embeds[cid].state_dict(),\n",
    "                'chunk_module_state': model.chunk_modules[cid].state_dict(),\n",
    "                'global_out_state': model.global_out.state_dict(),\n",
    "                'best_val_loss': best_loss,\n",
    "            }\n",
    "            torch.save(ckpt, f'{work_dir}/models/{model_name}_chunk{cid}.pth')\n",
    "            print(f'  --> updated {model_name}_chunk{cid}.pth')\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= earlystop_patience:\n",
    "                print('Early stopping triggered')\n",
    "                break\n",
    "\n",
    "    del optimizer, scheduler\n",
    "    torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "\n",
    "# ---------------- 全部 chunk 训练完成 -> 保存最终完整模型 ----------------\n",
    "final_ckpt = {\n",
    "    'model_state': model.state_dict(),\n",
    "    'n_chunks': model.n_chunks,\n",
    "    'chunk_size': model.chunk_size,\n",
    "    'chunk_overlap': model.chunk_overlap,\n",
    "}\n",
    "torch.save(final_ckpt, f'{work_dir}/models/{model_name}_final.pth')\n",
    "print(f'==> Final model saved to {work_dir}/models/{model_name}_final.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93349a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- 1. 必须与训练时完全一致 ----------\n",
    "d_model       = 64\n",
    "n_alleles     = 3\n",
    "total_sites   = 12345\n",
    "chunk_size    = 4096\n",
    "chunk_overlap = 64\n",
    "device        = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# 重建模型\n",
    "model = EvoFill(\n",
    "    d_model=d_model,\n",
    "    n_alleles=n_alleles,\n",
    "    total_sites=total_sites,\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap\n",
    ").to(device)\n",
    "\n",
    "# ---------- 2. 加载最终权重 ----------\n",
    "ckpt = torch.load('exp1/models/final_model.pth', map_location=device)\n",
    "model.load_state_dict(ckpt['model_state'])\n",
    "\n",
    "# ---------- 3. 切换推理模式 ----------\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    pred = model(x, chunk_id=0, x_extra=x_extra)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
