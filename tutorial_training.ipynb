{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "928e399c",
   "metadata": {},
   "source": [
    "# EvoFill training tutorial\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed77817",
   "metadata": {},
   "source": [
    "## 0. Dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23548ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python ver:   3.10.19 | packaged by conda-forge | (main, Oct 13 2025, 14:08:27) [GCC 14.3.0]\n",
      "Pytorch ver:  2.8.0+cu129\n",
      "Mamba ver:    2.2.5\n",
      "GPU in use:   NVIDIA H100 PCIe\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\" # select the GPU to use, if need\n",
    "\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import mamba_ssm\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Using Device: cuda\")\n",
    "else:\n",
    "    raise RuntimeError(\"CUDA is not available. EvoFill is based on mamba2 and must run on GPU.\")\n",
    "\n",
    "print('Python ver:  ', sys.version)\n",
    "print('Pytorch ver: ', torch.__version__)\n",
    "print('Mamba ver:   ', mamba_ssm.__version__)\n",
    "print('GPU in use:  ', torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "\n",
    "# os.chdir('/mnt/qmtang/EvoFill/')\n",
    "from src.data import GenotypeEncoder, ImputationDataset\n",
    "from src.model import EvoFill\n",
    "from src.utils import setup_workdir, precompute_maf, metrics_by_maf_with95ci, print_maf_stat_df_with95ci\n",
    "from src.tensor2vcf import make_imputed_vcfgz_from_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7064af",
   "metadata": {},
   "source": [
    "## 1. Encoding all vcfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c4b1516",
   "metadata": {},
   "outputs": [],
   "source": [
    "work_dir = Path('/mnt/qmtang/EvoFill_data/20251230_chr22/')\n",
    "os.chdir(work_dir)\n",
    "setup_workdir(work_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a0a57f",
   "metadata": {},
   "source": [
    "### 1.1 1kGP cohorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d332f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_enc = GenotypeEncoder(phased = False, gts012 = False, save2disk = True, save_dir = Path(work_dir / \"train\"))\n",
    "gt_enc = gt_enc.encode_new(vcf_path   = \"data/major_pops_train.vcf.gz\" ,\n",
    "                           evo_mat    = \"data/evo_mat_major_pops_train.tsv\")\n",
    "\n",
    "print(f\"[DATA] {gt_enc.n_samples:,} Samples\")\n",
    "print(f\"[DATA] {gt_enc.n_variants:,} Variants Sites\")\n",
    "print(f\"[DATA] {gt_enc.seq_depth} seq_depth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff71b241",
   "metadata": {},
   "source": [
    "### 1.2 1240k-panel cohorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258362bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_enc_aug = GenotypeEncoder(phased=False, gts012=False, save2disk = True, save_dir = Path(work_dir / \"augment\"))\n",
    "gt_enc_aug = gt_enc_aug.encode_ref(\n",
    "        ref_meta_json = work_dir/\"train\"/\"gt_enc_meta.json\",   # 与 Stage1 同构\n",
    "        vcf_path      = \"augment/augment_hg38.chr22.vcf.gz\",\n",
    "        evo_mat       = \"augment/evo_mat_1240k.tsv\",)\n",
    "\n",
    "print(f\"[DATA] {gt_enc_aug.n_samples:,} Samples\")\n",
    "print(f\"[DATA] {gt_enc_aug.n_variants:,} Variants Sites\")\n",
    "print(f\"[DATA] {gt_enc_aug.seq_depth} seq_depth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf94ad6b",
   "metadata": {},
   "source": [
    "Mapping variant sites in 1240K to 1kGP panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecc3581",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from cyvcf2 import VCF\n",
    "\n",
    "ref_vcf_path   = \"data/major_pops_train.vcf.gz\"\n",
    "aDNA_vcf_path = 'augment/augment_hg38.chr22.vcf.gz'\n",
    "\n",
    "# 1. 大 VCF 建索引  fingerprint -> row_index\n",
    "big_index = {}\n",
    "for idx, variant in enumerate(VCF(ref_vcf_path)):\n",
    "    # 用 CHROM:POS:REF:ALT 当 key，和 bcftools 脚本保持一致\n",
    "    key = f'{variant.CHROM}:{variant.POS}:{variant.REF}:{\",\".join(variant.ALT)}'\n",
    "    big_index[key] = idx          # 0-based 行号\n",
    "\n",
    "# 2. 小 VCF 生成 mapping 数组\n",
    "mapping = []\n",
    "for variant in VCF(aDNA_vcf_path):\n",
    "    key = f'{variant.CHROM}:{variant.POS}:{variant.REF}:{\",\".join(variant.ALT)}'\n",
    "    mapping.append(big_index.get(key, -1))\n",
    "\n",
    "mapping = np.array(mapping, dtype=np.int32)\n",
    "print('Variants in 1240k panel:', len(mapping))\n",
    "print('Available in 1kGP panel:', np.sum(mapping != -1))\n",
    "\n",
    "# 保存\n",
    "np.save('augment/sitesmap_1240k.npy', mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e19437",
   "metadata": {},
   "source": [
    "### 1.4 validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1b2e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_enc_imp = GenotypeEncoder(phased=False, gts012=False, save2disk=True, save_dir = Path(work_dir / \"impute_in\"))\n",
    "gt_enc_imp = gt_enc_imp.encode_ref(\n",
    "        ref_meta_json = work_dir/\"train\"/\"gt_enc_meta.json\",   # 与 Stage1 同构\n",
    "        vcf_path      = \"./data/minor_pops_all.mask90p.vcf.gz\" )\n",
    "\n",
    "print(f'[INFER] {gt_enc_imp.n_samples} samples, {gt_enc_imp.n_variants} variants')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe0aebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_enc_imp = GenotypeEncoder(phased=False, gts012=False, save2disk=True, save_dir = Path(work_dir / \"impute_out\"))\n",
    "gt_enc_imp = gt_enc_imp.encode_ref(\n",
    "        ref_meta_json = work_dir/\"train\"/\"gt_enc_meta.json\",   # 与 Stage1 同构\n",
    "        vcf_path      = \"./data/minor_pops_all.vcf.gz\" )\n",
    "\n",
    "print(f'[INFER] {gt_enc_imp.n_samples} samples, {gt_enc_imp.n_variants} variants')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fef1699",
   "metadata": {},
   "source": [
    "## 2. Training with multi-GPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93b6242",
   "metadata": {},
   "source": [
    "### 2.1 training stage 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc9d973",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /mnt/qmtang/EvoFill/\n",
    "\n",
    "nohup env OMP_NUM_THREADS=8 accelerate launch --config_file ds_zero3.yaml pre_training_ds.py > logs/chr22_260104.log 2>&1 &\n",
    "\n",
    "tail -f logs/chr22_260104.log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79db71c0",
   "metadata": {},
   "source": [
    "### 2.2 training stage 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02a9d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /mnt/qmtang/EvoFill/\n",
    "\n",
    "nohup env OMP_NUM_THREADS=8 accelerate launch --config_file ds_zero3.yaml hybrid_training_ds.py > logs/chr22_260104.log 2>&1 &\n",
    "\n",
    "tail -f logs/chr22_260104.log\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ea5d12",
   "metadata": {},
   "source": [
    "### 2.3 Merge weight files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc9ff6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /mnt/qmtang/EvoFill_data/20251204_chr22/models/checkpoint-stage1/\n",
    "python zero_to_fp32.py . ./"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b718f797",
   "metadata": {},
   "source": [
    "## 3. Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4034fdcb",
   "metadata": {},
   "source": [
    "### 3.1 Load the trained model\n",
    "\n",
    "Choose a path where including `<work_dir>/model` and have trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4c2e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "work_dir = Path('/mnt/qmtang/EvoFill_data/20251230_chr22')\n",
    "os.chdir(work_dir)\n",
    "print(f\"Work Dir: {work_dir}\")\n",
    "\n",
    "# ---- 1. 加载模型 ----\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "json_path = f\"{work_dir}/models/model_meta.json\"\n",
    "meta = json.load(open(json_path))\n",
    "model = EvoFill(\n",
    "    n_alleles=int(meta[\"alleles\"]),\n",
    "    total_sites=int(meta[\"total_sites\"]),\n",
    "    chunk_size=int(meta[\"chunk_size\"]),\n",
    "    chunk_overlap=int(meta[\"overlap\"]),\n",
    "    d_model=int(meta[\"d_model\"]),\n",
    "    d_state=int(meta[\"d_state\"]),\n",
    "    headdim=int(meta[\"headdim\"]),\n",
    "    bimamba_layers=int(meta[\"bimamba_layers\"]),\n",
    "    stack_mamba_layers=int(meta[\"stack_mamba_layers\"])\n",
    ").to(device)\n",
    "\n",
    "\n",
    "state_dict = torch.load(\"/mnt/qmtang/EvoFill_data/20251230_chr22/models/hg38_chr22_v1.0.bin\", map_location=\"cpu\")\n",
    "# state_dict = torch.load(f\"{work_dir}/models/pytorch_model_stage2.bin\", map_location=\"cpu\")\n",
    "\n",
    "model.load_state_dict(state_dict)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "model.eval()\n",
    "print(f'[INF] Model[{meta[\"model_name\"]}] loaded.')\n",
    "print(f\"[INF] Total params: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809730fd",
   "metadata": {},
   "source": [
    "### 3.2 Inferring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d5223c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_enc_imp = GenotypeEncoder.loadfromdisk(Path(work_dir / \"impute_in\"))\n",
    "out_dir = os.path.join(work_dir, 'impute_out')\n",
    "\n",
    "print(f'[INFER] {gt_enc_imp.n_samples} samples, {gt_enc_imp.n_variants} variants')\n",
    "\n",
    "# ---- 2. 构建推理 Dataset / Loader ----\n",
    "imp_dataset = ImputationDataset(\n",
    "    x_gts_sparse=gt_enc_imp.X_gt,\n",
    "    seq_depth=gt_enc_imp.seq_depth,\n",
    "    indices=None                 # 可传入指定样本索引\n",
    ")\n",
    "imp_dataset.print_missing_stat()          # 查看原始缺失比例\n",
    "\n",
    "def collate_fn(batch):\n",
    "    x_onehot = torch.stack([item[0] for item in batch])\n",
    "    real_idx_list = [item[1] for item in batch]\n",
    "    return x_onehot, real_idx_list   # 无 y\n",
    "\n",
    "imp_loader = torch.utils.data.DataLoader(\n",
    "    imp_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "y_prob = []\n",
    "y_mask = []\n",
    "with torch.no_grad():\n",
    "    for x_onehot, real_idx in tqdm(imp_loader, desc='Imputing'):\n",
    "        x_onehot = x_onehot.to(device)\n",
    "        _, prob, _ = model(x_onehot)\n",
    "        miss_mask = x_onehot[..., -1].bool()\n",
    "        y_prob.append(prob)\n",
    "        y_mask.append(miss_mask)\n",
    "y_prob = torch.cat(y_prob, dim=0).cpu().numpy()\n",
    "y_mask = torch.cat(y_mask, dim=0).cpu().numpy()\n",
    "\n",
    "# 4. 保存\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "np.save(os.path.join(out_dir, 'impute_prob.npy'), y_prob)\n",
    "np.save(os.path.join(out_dir, 'impute_mask.npy'), y_mask)\n",
    "print(f'[INF] The probability matrix has been saved → {out_dir}/impute_prob.npy '\n",
    "      f'with shape = {y_prob.shape} ')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da27d710",
   "metadata": {},
   "source": [
    "### 3.4 Evaluating the imputation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b435b8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_enc_true = GenotypeEncoder.loadfromdisk(Path(work_dir / \"impute_out\"))\n",
    "y_true = gt_enc_true.X_gt.toarray()\n",
    "maf, bin_cnt = precompute_maf(y_true)\n",
    "y_true_oh = np.eye(gt_enc_true.seq_depth - 1)[y_true]\n",
    "bins_metrics   = metrics_by_maf_with95ci(y_prob, y_true_oh, hap_map = gt_enc_true.hap_map, maf_vec = maf, mask=y_mask)\n",
    "print_maf_stat_df_with95ci(bin_cnt,{'val': bins_metrics})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de94e3af",
   "metadata": {},
   "source": [
    "### 3.5 Saving to .vcf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe87385",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROB_NPY = \"/mnt/qmtang/EvoFill_data/20251211_chr22/impute_out2/impute_prob.npy\"\n",
    "MASK_VCF = \"/mnt/qmtang/EvoFill_data/20251211_chr22/data/major_pops_val.mask90p.vcf.gz\"\n",
    "OUT_VCFGZ = \"/home/zqyin/mamba_test/Other_Model_test/chr22_major/Evofill/major_pops_val.imputed.from_prob.vcf.gz\"\n",
    "\n",
    "OUT_VCFGZ_CREATED = make_imputed_vcfgz_from_prob(PROB_NPY, MASK_VCF, OUT_VCFGZ, digits=FLOAT_DIGITS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mamba",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
